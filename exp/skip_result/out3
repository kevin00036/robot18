(0.24300000000005184, array([-1.000000e+00, -1.000000e+00,  1.189783e+03,  1.790000e-01,
       -1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00]), 4, array([  0.   ,   0.   , -15.851,   0.091,   0.   ,   0.   ,   0.   ,
         0.   ,   0.   ,   0.   ,   0.   ,   0.   ,   0.   ,   0.   ]), 1)
((0.236, array([-1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
        2.364685e+03, -3.300000e-01, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00]), array([0., 0., 0.])), (0.24, array([-1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
        2.543573e+03, -3.290000e-01, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00]), array([0., 0., 0.])))
(0.236, array([-1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
        2.364685e+03, -3.300000e-01, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00]), 0, array([0.   , 0.   , 0.   , 0.   , 5.823, 3.129, 0.   , 0.   , 0.   ,
       0.   , 0.   , 0.   , 0.   , 0.   ]))
(0.236, array([-1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
        2.364685e+03, -3.300000e-01, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00]), 0, array([ 0.   ,  0.   ,  0.   ,  0.   , -8.411, -0.011,  0.   ,  0.   ,
        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ]))
(0.24, array([-1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
        2.543573e+03, -3.290000e-01, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00]), 0, array([   0.   ,    0.   ,    0.   ,    0.   , -173.065,    3.128,
          0.   ,    0.   ,    0.   ,    0.   ,    0.   ,    0.   ,
          0.   ,    0.   ]))
(0.24, array([-1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
        2.543573e+03, -3.290000e-01, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00]), 0, array([ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00,
       -1.87299e+02, -1.20000e-02,  0.00000e+00,  0.00000e+00,
        0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00,
        0.00000e+00,  0.00000e+00]))
(0.24, array([-1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
        2.543573e+03, -3.290000e-01, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00]), 0, array([ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00,
       -1.16455e+02, -4.00000e-03,  0.00000e+00,  0.00000e+00,
        0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00,
        0.00000e+00,  0.00000e+00]))
(0.238, array([-1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
        2.370508e+03,  2.799000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00]), 0, array([  0.   ,   0.   ,   0.   ,   0.   , -14.234,  -3.14 ,   0.   ,
         0.   ,   0.   ,   0.   ,   0.   ,   0.   ,   0.   ,   0.   ]))
(0.238, array([-1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
        2.370508e+03,  2.799000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00]), 0, array([ 0.   ,  0.   ,  0.   ,  0.   , 56.61 , -3.132,  0.   ,  0.   ,
        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ]))
(0.238, array([-1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
        2.370508e+03,  2.799000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00]), 0, array([   0.   ,    0.   ,    0.   ,    0.   , -124.866,   -3.133,
          0.   ,    0.   ,    0.   ,    0.   ,    0.   ,    0.   ,
          0.   ,    0.   ]))
(0.236, array([-1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
        2.356274e+03, -3.410000e-01, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00]), 0, array([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0844e+01,
       8.0000e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]))
(0.236, array([-1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
        2.356274e+03, -3.410000e-01, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00]), 0, array([ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00,
       -1.10632e+02,  7.00000e-03,  0.00000e+00,  0.00000e+00,
        0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00,
        0.00000e+00,  0.00000e+00]))
14 1 14

 ===== Epoch 1	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  1.887517    1.9678562
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
 -3.5188213e-01 -1.3316683e-01  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 3 5
train:	 Loss = 1.7457,	 Acc = 0.3087
8217 0.219
16075 0.317
8295 0.371
1066 0.374
185 0.427
18 0.167
0 0.0
0 0.0
0.33725964351183746
0.0
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.5191,	 Acc = 0.4077
1049 0.348
4874 0.422
2304 0.414
235 0.306
6 0.833
0 0.0
0 0.0
0 0.0
0.4160938131823696
0.4160938131823696
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.5771,	 Acc1 = 0.3299,	 Acc2 = 0.3415

 ===== Epoch 2	 =====
[ 3.1648028   1.7968589  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.9363445   3.3426101  -0.42469367 -0.42124885
  2.6145008   1.9944018 ] [-3.8024421e+00 -2.5417027e+00  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -4.1972842e+00 -6.4773922e+00  2.5347492e-03  4.0676598e-03
  4.1535518e-01  2.1499045e-01] 6 2
train:	 Loss = 1.5554,	 Acc = 0.4167
8216 0.263
16075 0.44
8294 0.514
1068 0.498
185 0.459
18 0.222
0 0.0
0 0.0
0.4660686427457098
0.4160938131823696
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.5255,	 Acc = 0.4165
1049 0.364
4874 0.42
2304 0.45
235 0.255
6 0.0
0 0.0
0 0.0
0 0.0
0.42391157837983556
0.42391157837983556
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.6066,	 Acc1 = 0.3258,	 Acc2 = 0.3365

 ===== Epoch 3	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 2 1
train:	 Loss = 1.5204,	 Acc = 0.4329
8215 0.26
16078 0.462
8292 0.536
1068 0.522
185 0.465
18 0.278
0 0.0
0 0.0
0.48828048828048826
0.42391157837983556
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4835,	 Acc = 0.4380
1049 0.376
4874 0.462
2304 0.428
235 0.319
6 0.0
0 0.0
0 0.0
0 0.0
0.4468257177517186
0.4468257177517186
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.5463,	 Acc1 = 0.3584,	 Acc2 = 0.3757

 ===== Epoch 4	 =====
[ 2.292676    2.11775    -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  2.1826472   2.3536432 ] [-0.01896459  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.0007206  -0.00170575] 0 0
train:	 Loss = 1.5020,	 Acc = 0.4423
8216 0.261
16078 0.474
8292 0.547
1067 0.55
185 0.454
18 0.167
0 0.0
0 0.0
0.5004290171606864
0.4468257177517186
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4926,	 Acc = 0.4464
1049 0.379
4874 0.476
2304 0.428
235 0.336
6 0.0
0 0.0
0 0.0
0 0.0
0.45585658444534305
0.45585658444534305
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.5568,	 Acc1 = 0.3561,	 Acc2 = 0.3730

 ===== Epoch 5	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  2.6105072   2.9599617
 -0.3641531  -0.3721681   1.8125422   2.3089285  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211 -0.54880995 -0.15587303
  0.0014167   0.00272805  0.19125845 -0.28688195  0.00253475  0.00406766
 -0.00159979 -0.00170575] 5 5
train:	 Loss = 1.4945,	 Acc = 0.4445
8216 0.261
16077 0.481
8293 0.546
1067 0.535
185 0.416
18 0.167
0 0.0
0 0.0
0.5034321372854914
0.45585658444534305
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4792,	 Acc = 0.4420
1049 0.314
4874 0.473
2304 0.445
235 0.349
6 0.0
0 0.0
0 0.0
0 0.0
0.46016983420946217
0.46016983420946217
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.5414,	 Acc1 = 0.3629,	 Acc2 = 0.3812

 ===== Epoch 6	 =====
[-0.36710912 -0.3811568   1.751988    0.92138624 -0.44130662 -0.36481208
  3.3560917   3.11899    -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  2.4169976e-01  2.9290829e-02
  1.9079351e-03  5.4739986e-04  6.7884290e-01  1.4206982e-01
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 3 2
train:	 Loss = 1.4819,	 Acc = 0.4533
8218 0.263
16077 0.49
8291 0.559
1068 0.549
185 0.47
17 0.176
0 0.0
0 0.0
0.514431702940947
0.46016983420946217
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4230,	 Acc = 0.4829
1049 0.383
4874 0.494
2304 0.516
235 0.357
6 0.833
0 0.0
0 0.0
0 0.0
0.4969672462596037
0.4969672462596037
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4951,	 Acc1 = 0.3782,	 Acc2 = 0.3996

 ===== Epoch 7	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  3.1155696   1.943442
 -0.3641531  -0.3721681   2.7806087   1.158461   -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211 -0.70908237  0.1266929
  0.0014167   0.00272805  0.30649877  0.18964139  0.00253475  0.00406766
 -0.00159979 -0.00170575] 3 2
train:	 Loss = 1.4779,	 Acc = 0.4542
8218 0.257
16079 0.496
8288 0.557
1068 0.554
185 0.432
18 0.278
0 0.0
0 0.0
0.5174740619393089
0.4969672462596037
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4503,	 Acc = 0.4654
1049 0.356
4874 0.5
2304 0.45
235 0.37
6 0.833
0 0.0
0 0.0
0 0.0
0.4809273486992856
0.4969672462596037
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.5146,	 Acc1 = 0.3753,	 Acc2 = 0.3961

 ===== Epoch 8	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  1.0218191   2.7810457  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.32085965e-03  2.41595390e-03  3.61774070e-03  2.40210793e-03
  1.90793513e-03  5.47399861e-04  3.16215664e-01  1.14201464e-01
 -1.26931045e-04  5.04225399e-03  2.53474922e-03  4.06765984e-03
 -1.59978902e-03 -1.70574547e-03] 2 2
train:	 Loss = 1.4595,	 Acc = 0.4594
8216 0.259
16077 0.504
8292 0.559
1068 0.568
185 0.438
18 0.167
0 0.0
0 0.0
0.5237519500780031
0.4969672462596037
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4056,	 Acc = 0.5001
1049 0.372
4874 0.533
2304 0.501
235 0.387
6 0.0
0 0.0
0 0.0
0 0.0
0.518263916969942
0.518263916969942
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4702,	 Acc1 = 0.3978,	 Acc2 = 0.4232

 ===== Epoch 9	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 2 1
train:	 Loss = 1.4544,	 Acc = 0.4612
8219 0.251
16076 0.508
8292 0.563
1066 0.585
185 0.454
18 0.167
0 0.0
0 0.0
0.528493973553848
0.518263916969942
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3933,	 Acc = 0.4996
1049 0.355
4874 0.532
2304 0.518
235 0.306
6 0.0
0 0.0
0 0.0
0 0.0
0.5201509637417442
0.5201509637417442
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4679,	 Acc1 = 0.3943,	 Acc2 = 0.4190

 ===== Epoch 10	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  1.6776164   1.1666257
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.1169944  -0.11550646
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 5 2
train:	 Loss = 1.4443,	 Acc = 0.4664
8217 0.256
16075 0.511
8294 0.569
1067 0.614
185 0.459
18 0.167
0 0.0
0 0.0
0.5336791606536916
0.5201509637417442
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.3985,	 Acc = 0.4975
1049 0.325
4874 0.53
2304 0.527
235 0.306
6 0.0
0 0.0
0 0.0
0 0.0
0.5219032214584176
0.5219032214584176
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4597,	 Acc1 = 0.4132,	 Acc2 = 0.4418

 ===== Epoch 11	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 5 1
train:	 Loss = 1.4400,	 Acc = 0.4644
8217 0.258
16074 0.508
8294 0.568
1068 0.604
185 0.465
18 0.278
0 0.0
0 0.0
0.5305979172354616
0.5219032214584176
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4045,	 Acc = 0.4771
1049 0.306
4874 0.52
2304 0.487
235 0.277
6 0.0
0 0.0
0 0.0
0 0.0
0.5012804960237228
0.5219032214584176
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4685,	 Acc1 = 0.3961,	 Acc2 = 0.4212

 ===== Epoch 12	 =====
[ 2.8851213   2.1152232  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  0.46767673  2.1498444  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [-3.5012336e+00 -2.9135809e+00  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04 -1.6416401e+00 -5.0302968e+00
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 1 6
train:	 Loss = 1.4397,	 Acc = 0.4659
8215 0.256
16079 0.511
8291 0.569
1068 0.602
185 0.481
18 0.167
0 0.0
0 0.0
0.5331305331305332
0.5219032214584176
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3550,	 Acc = 0.5139
1049 0.368
4874 0.535
2304 0.555
235 0.336
6 0.0
0 0.0
0 0.0
0 0.0
0.5345733926405176
0.5345733926405176
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4382,	 Acc1 = 0.4081,	 Acc2 = 0.4356

 ===== Epoch 13	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  1.1622312   1.6460323
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
 -1.5751067e-01  1.9228855e-01  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 1 4
train:	 Loss = 1.4302,	 Acc = 0.4646
8218 0.249
16077 0.51
8290 0.572
1068 0.61
185 0.47
18 0.222
0 0.0
0 0.0
0.533894999609954
0.5345733926405176
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.3738,	 Acc = 0.4935
1049 0.197
4874 0.536
2304 0.556
235 0.332
6 0.0
0 0.0
0 0.0
0 0.0
0.53538212697129
0.53538212697129
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4527,	 Acc1 = 0.3821,	 Acc2 = 0.4381

 ===== Epoch 14	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  1.8729877   1.7503476
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
 -2.3764427e-01  2.3253588e-02  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 3 3
train:	 Loss = 1.4322,	 Acc = 0.4699
8216 0.254
16080 0.516
8291 0.575
1066 0.618
185 0.47
18 0.167
0 0.0
0 0.0
0.5390795631825273
0.53538212697129
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4110,	 Acc = 0.5099
1049 0.368
4874 0.525
2304 0.559
235 0.353
6 0.0
0 0.0
0 0.0
0 0.0
0.529990564766141
0.53538212697129
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4853,	 Acc1 = 0.3724,	 Acc2 = 0.3926

 ===== Epoch 15	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  3.9474182e+00  2.1876822e+00
  5.5795336e+00  7.1068721e+00] 2 2
train:	 Loss = 1.4267,	 Acc = 0.4712
8214 0.256
16080 0.517
8291 0.577
1068 0.612
185 0.465
18 0.222
0 0.0
0 0.0
0.5401684735980032
0.53538212697129
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.3935,	 Acc = 0.4921
1049 0.36
4874 0.534
2304 0.484
235 0.298
6 0.0
0 0.0
0 0.0
0 0.0
0.5107157298827335
0.53538212697129
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4624,	 Acc1 = 0.3947,	 Acc2 = 0.4195

 ===== Epoch 16	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 3 1
train:	 Loss = 1.4346,	 Acc = 0.4640
8218 0.247
16076 0.512
8291 0.569
1068 0.6
185 0.443
18 0.167
0 0.0
0 0.0
0.5336219673921523
0.53538212697129
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3745,	 Acc = 0.5022
1049 0.348
4874 0.537
2304 0.516
235 0.353
6 0.0
0 0.0
0 0.0
0 0.0
0.5240598463404772
0.53538212697129
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4428,	 Acc1 = 0.4017,	 Acc2 = 0.4279

 ===== Epoch 17	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  2.1320221   1.2890297 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -4.0802068e-01 -9.1210693e-02] 1 3
train:	 Loss = 1.4328,	 Acc = 0.4663
8214 0.251
16079 0.513
8292 0.573
1068 0.597
185 0.47
18 0.056
0 0.0
0 0.0
0.5352156618048514
0.53538212697129
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3880,	 Acc = 0.4987
1049 0.335
4874 0.538
2304 0.51
235 0.306
6 0.0
0 0.0
0 0.0
0 0.0
0.5219032214584176
0.53538212697129
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4545,	 Acc1 = 0.4091,	 Acc2 = 0.4369

 ===== Epoch 18	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  2.0702715   1.626057
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  7.4372619e-02 -3.3752257e-01  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 5 5
train:	 Loss = 1.4313,	 Acc = 0.4691
8219 0.25
16076 0.517
8291 0.577
1067 0.603
185 0.465
18 0.111
0 0.0
0 0.0
0.5394156882630573
0.53538212697129
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3831,	 Acc = 0.5046
1049 0.346
4874 0.541
2304 0.513
235 0.379
6 0.0
0 0.0
0 0.0
0 0.0
0.5270252055533091
0.53538212697129
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4646,	 Acc1 = 0.3780,	 Acc2 = 0.3994

 ===== Epoch 19	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   2.0549889   2.013236   -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805  0.52772003  0.02221427  0.00253475  0.00406766
 -0.00159979 -0.00170575] 2 2
train:	 Loss = 1.4274,	 Acc = 0.4669
8216 0.242
16078 0.516
8291 0.579
1068 0.599
185 0.47
18 0.222
0 0.0
0 0.0
0.5390795631825273
0.53538212697129
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.3911,	 Acc = 0.4914
1049 0.316
4874 0.526
2304 0.505
235 0.421
6 0.833
0 0.0
0 0.0
0 0.0
0.5162420811430112
0.53538212697129
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4530,	 Acc1 = 0.4058,	 Acc2 = 0.4329

 ===== Epoch 20	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.6510992   2.1901934
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  7.7816933e-02  6.0323018e-01
 -1.5997890e-03 -1.7057455e-03] 6 6
train:	 Loss = 1.4342,	 Acc = 0.4614
8216 0.241
16074 0.508
8295 0.571
1068 0.605
185 0.47
18 0.278
0 0.0
0 0.0
0.5319422776911077
0.53538212697129
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3860,	 Acc = 0.4688
1049 0.306
4874 0.508
2304 0.47
235 0.349
6 0.833
0 0.0
0 0.0
0 0.0
0.49184526216471225
0.53538212697129
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4542,	 Acc1 = 0.3932,	 Acc2 = 0.4177

 ===== Epoch 21	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 4 1
train:	 Loss = 1.4323,	 Acc = 0.4632
8217 0.234
16080 0.511
8289 0.581
1067 0.596
185 0.47
18 0.167
0 0.0
0 0.0
0.5366823979094348
0.53538212697129
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3951,	 Acc = 0.4733
1049 0.316
4874 0.506
2304 0.488
235 0.362
6 0.0
0 0.0
0 0.0
0 0.0
0.4956193557083165
0.53538212697129
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4648,	 Acc1 = 0.3852,	 Acc2 = 0.4081

 ===== Epoch 22	 =====
[-0.36710912 -0.3811568   2.0552003   1.5835761  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.0395421e-01  1.0995699e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 2 2
train:	 Loss = 1.4291,	 Acc = 0.4643
8213 0.231
16079 0.513
8293 0.583
1068 0.61
185 0.481
18 0.333
0 0.0
0 0.0
0.5389385017353664
0.53538212697129
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4005,	 Acc = 0.4589
1049 0.305
4874 0.502
2304 0.454
235 0.302
6 0.0
0 0.0
0 0.0
0 0.0
0.48065777058902814
0.53538212697129
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4670,	 Acc1 = 0.3961,	 Acc2 = 0.4212

 ===== Epoch 23	 =====
[ 1.5191048   2.2794585  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [-2.4129200e-01  1.0276403e-01  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 1 1
train:	 Loss = 1.4325,	 Acc = 0.4598
8217 0.222
16077 0.51
8292 0.578
1067 0.605
185 0.508
18 0.222
0 0.0
0 0.0
0.5359023362845665
0.53538212697129
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3764,	 Acc = 0.4901
1049 0.183
4874 0.538
2304 0.54
235 0.387
6 0.0
0 0.0
0 0.0
0 0.0
0.5334950801994878
0.53538212697129
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4541,	 Acc1 = 0.3629,	 Acc2 = 0.4150

 ===== Epoch 24	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 6
train:	 Loss = 1.4279,	 Acc = 0.4632
8214 0.226
16078 0.514
8293 0.583
1068 0.59
185 0.508
18 0.222
0 0.0
0 0.0
0.5392325091646517
0.53538212697129
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3737,	 Acc = 0.4878
1049 0.305
4874 0.527
2304 0.502
235 0.362
6 0.0
0 0.0
0 0.0
0 0.0
0.5136810890955654
0.53538212697129
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4377,	 Acc1 = 0.4087,	 Acc2 = 0.4364

 ===== Epoch 25	 =====
[ 2.8149269   3.2749786  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  2.5942512   3.5283895 ] [-0.04912599  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
  0.01595695  0.00771583] 0 0
train:	 Loss = 1.4268,	 Acc = 0.4637
8217 0.221
16076 0.515
8293 0.585
1067 0.613
185 0.519
18 0.222
0 0.0
0 0.0
0.5415577830648621
0.53538212697129
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3938,	 Acc = 0.4702
1049 0.183
4874 0.531
2304 0.484
235 0.374
6 0.0
0 0.0
0 0.0
0 0.0
0.5108505189378623
0.53538212697129
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4573,	 Acc1 = 0.3613,	 Acc2 = 0.4130

 ===== Epoch 26	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  2.484338    1.4484991
 -0.3641531  -0.3721681   1.6170949   0.8876166  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211 -0.01514289  0.35880065
  0.0014167   0.00272805 -0.11536721  0.57171863  0.00253475  0.00406766
 -0.00159979 -0.00170575] 6 6
train:	 Loss = 1.4259,	 Acc = 0.4622
8219 0.221
16074 0.515
8292 0.581
1068 0.603
185 0.508
18 0.222
0 0.0
0 0.0
0.5396497250068261
0.53538212697129
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3717,	 Acc = 0.4966
1049 0.305
4874 0.522
2304 0.541
235 0.404
6 0.0
0 0.0
0 0.0
0 0.0
0.523655479175091
0.53538212697129
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4468,	 Acc1 = 0.3908,	 Acc2 = 0.4148

 ===== Epoch 27	 =====
[ 2.6052868   2.1859708  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  2.434012    2.400843  ] [-2.8822681e-01  7.4322081e-01  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
  1.3796951e-01  1.1383047e+00] 6 6
train:	 Loss = 1.4268,	 Acc = 0.4632
8216 0.228
16077 0.512
8292 0.584
1068 0.601
185 0.524
18 0.222
0 0.0
0 0.0
0.5384555382215288
0.53538212697129
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3967,	 Acc = 0.4642
1049 0.183
4874 0.513
2304 0.506
235 0.311
6 0.0
0 0.0
0 0.0
0 0.0
0.5039762771262973
0.53538212697129
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4757,	 Acc1 = 0.3485,	 Acc2 = 0.3976

 ===== Epoch 28	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.6279337   1.6834257  -0.40162212 -0.40945497  2.7896502   2.8264713
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04 -8.8683054e-02 -1.0874537e-01
 -1.2693105e-04  5.0422540e-03 -3.7942725e-01 -4.8088226e-03
 -1.5997890e-03 -1.7057455e-03] 3 0
train:	 Loss = 1.4262,	 Acc = 0.4654
8215 0.223
16077 0.518
8293 0.586
1068 0.602
185 0.486
18 0.333
0 0.0
0 0.0
0.543036543036543
0.53538212697129
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.3528,	 Acc = 0.5144
1049 0.305
4874 0.54
2304 0.569
235 0.391
6 0.0
0 0.0
0 0.0
0 0.0
0.5440086264995282
0.5440086264995282
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4322,	 Acc1 = 0.4073,	 Acc2 = 0.4346

 ===== Epoch 29	 =====
[ 0.21771677  1.9838347  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 5.2561577e-02 -2.1894009e-01  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 2 5
train:	 Loss = 1.4218,	 Acc = 0.4661
8218 0.228
16075 0.519
8292 0.583
1068 0.602
185 0.486
18 0.222
0 0.0
0 0.0
0.5425150167719791
0.5440086264995282
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4149,	 Acc = 0.4522
1049 0.305
4874 0.493
2304 0.441
235 0.357
6 0.833
0 0.0
0 0.0
0 0.0
0.47297479444669094
0.5440086264995282
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4753,	 Acc1 = 0.3920,	 Acc2 = 0.4163

 ===== Epoch 30	 =====
[-0.36710912 -0.3811568   2.400741   -4.1425505   2.2591436   0.8914108
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  2.3076403e-01  7.6070213e+00
  8.5454330e-02 -1.7112972e-02  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 2 2
train:	 Loss = 1.4223,	 Acc = 0.4638
8215 0.221
16077 0.517
8293 0.583
1068 0.602
185 0.524
18 0.333
0 0.0
0 0.0
0.5415155415155415
0.5440086264995282
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3967,	 Acc = 0.4837
1049 0.305
4874 0.5
2304 0.541
235 0.383
6 0.833
0 0.0
0 0.0
0 0.0
0.5089634721660601
0.5440086264995282
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4650,	 Acc1 = 0.3819,	 Acc2 = 0.4041

 ===== Epoch 31	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  0.890302    1.286138
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03 -1.5595444e-01 -1.8233845e-01
 -1.5997890e-03 -1.7057455e-03] 2 1
train:	 Loss = 1.4252,	 Acc = 0.4635
8217 0.226
16073 0.511
8295 0.585
1068 0.623
185 0.519
18 0.389
0 0.0
0 0.0
0.539490619758961
0.5440086264995282
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.4067,	 Acc = 0.4521
1049 0.305
4874 0.495
2304 0.444
235 0.302
6 0.0
0 0.0
0 0.0
0 0.0
0.4728400053915622
0.5440086264995282
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4831,	 Acc1 = 0.3852,	 Acc2 = 0.4081

 ===== Epoch 32	 =====
[ 1.7183342   1.1778173  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  2.154034    1.3676957 ] [ 2.8154340e-01  5.3673680e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
  4.2248116e+00  6.4788914e+00  2.5347492e-03  4.0676598e-03
  3.1879580e-01 -1.1127320e-02] 2 0
train:	 Loss = 1.4254,	 Acc = 0.4624
8216 0.224
16078 0.513
8293 0.585
1067 0.591
184 0.478
18 0.333
0 0.0
0 0.0
0.5388065522620905
0.5440086264995282
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.3856,	 Acc = 0.4738
1049 0.305
4874 0.51
2304 0.486
235 0.362
6 0.0
0 0.0
0 0.0
0 0.0
0.49764119153524733
0.5440086264995282
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4607,	 Acc1 = 0.3881,	 Acc2 = 0.4115

 ===== Epoch 33	 =====
[ 1.4938446   0.8341861  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  2.0699522   1.0215652 ] [ 1.0974011e+00  2.7689743e-01  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -3.6062020e-01  4.3639746e-01] 6 2
train:	 Loss = 1.4223,	 Acc = 0.4649
8219 0.223
16076 0.518
8291 0.584
1067 0.595
185 0.497
18 0.389
0 0.0
0 0.0
0.5423801536841284
0.5440086264995282
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3984,	 Acc = 0.4802
1049 0.305
4874 0.517
2304 0.497
235 0.357
6 0.0
0 0.0
0 0.0
0 0.0
0.5049198005121984
0.5440086264995282
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4639,	 Acc1 = 0.3959,	 Acc2 = 0.4210

 ===== Epoch 34	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  2.0178928   2.023343
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  4.6237435e-02  1.8471983e-01  1.4166982e-03  2.7280508e-03
  2.6381788e+00  2.1987667e+00  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 6 4
train:	 Loss = 1.4273,	 Acc = 0.4638
8215 0.226
16078 0.514
8292 0.581
1068 0.62
185 0.486
18 0.278
0 0.0
0 0.0
0.54007254007254
0.5440086264995282
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3616,	 Acc = 0.5190
1049 0.305
4874 0.541
2304 0.583
235 0.404
6 0.0
0 0.0
0 0.0
0 0.0
0.5492653996495485
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4360,	 Acc1 = 0.4054,	 Acc2 = 0.4324

 ===== Epoch 35	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 5 1
train:	 Loss = 1.4227,	 Acc = 0.4649
8214 0.222
16078 0.517
8293 0.585
1068 0.604
185 0.503
18 0.278
0 0.0
0 0.0
0.5426253802355511
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3731,	 Acc = 0.4798
1049 0.305
4874 0.517
2304 0.494
235 0.353
6 0.0
0 0.0
0 0.0
0 0.0
0.5045154333468123
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4548,	 Acc1 = 0.3922,	 Acc2 = 0.4165

 ===== Epoch 36	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  2.1318278   1.1799425
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.02151506  0.08632635
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 2 2
train:	 Loss = 1.4215,	 Acc = 0.4648
8215 0.222
16077 0.515
8293 0.589
1068 0.605
185 0.492
18 0.333
0 0.0
0 0.0
0.5426465426465427
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.4145,	 Acc = 0.4522
1049 0.305
4874 0.492
2304 0.45
235 0.311
6 0.0
0 0.0
0 0.0
0 0.0
0.47297479444669094
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4851,	 Acc1 = 0.3868,	 Acc2 = 0.4100

 ===== Epoch 37	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  4.9958243e+00  1.2710608e+00
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 1 1
train:	 Loss = 1.4230,	 Acc = 0.4646
8213 0.226
16080 0.516
8293 0.583
1067 0.612
185 0.481
18 0.333
0 0.0
0 0.0
0.5411613305775456
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3730,	 Acc = 0.5009
1049 0.305
4874 0.532
2304 0.538
235 0.383
6 0.0
0 0.0
0 0.0
0 0.0
0.5286426742148538
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4443,	 Acc1 = 0.4046,	 Acc2 = 0.4314

 ===== Epoch 38	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.2831665   2.1042097
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03 -1.5040828e-01 -2.7997977e-01
 -1.5997890e-03 -1.7057455e-03] 3 5
train:	 Loss = 1.4232,	 Acc = 0.4646
8216 0.222
16075 0.516
8294 0.587
1068 0.598
185 0.535
18 0.278
0 0.0
0 0.0
0.5422386895475819
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.3994,	 Acc = 0.4593
1049 0.305
4874 0.489
2304 0.482
235 0.323
6 0.0
0 0.0
0 0.0
0 0.0
0.48106213775441437
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4893,	 Acc1 = 0.3726,	 Acc2 = 0.3929

 ===== Epoch 39	 =====
[ 0.85620123  3.0728426  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [-0.01645498 -0.00643829  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4228,	 Acc = 0.4617
8217 0.223
16076 0.51
8292 0.586
1068 0.604
185 0.481
18 0.389
0 0.0
0 0.0
0.538281524240415
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3912,	 Acc = 0.4942
1049 0.305
4874 0.511
2304 0.555
235 0.404
6 0.0
0 0.0
0 0.0
0 0.0
0.5209596980725165
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4714,	 Acc1 = 0.3916,	 Acc2 = 0.4158

 ===== Epoch 40	 =====
[-0.36710912 -0.3811568   2.7906442  -4.6845484  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  6.9682974e-01 -8.8041767e-02
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 2 2
train:	 Loss = 1.4272,	 Acc = 0.4649
8219 0.223
16076 0.515
8291 0.587
1067 0.617
185 0.486
18 0.389
0 0.0
0 0.0
0.5424191598080899
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.3998,	 Acc = 0.4765
1049 0.305
4874 0.514
2304 0.485
235 0.366
6 0.833
0 0.0
0 0.0
0 0.0
0.500741339803208
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4699,	 Acc1 = 0.3918,	 Acc2 = 0.4160

 ===== Epoch 41	 =====
[-0.36710912 -0.3811568   1.9115313   1.4747229  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.10036466 -0.01226447  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 2 0
train:	 Loss = 1.4249,	 Acc = 0.4609
8216 0.214
16077 0.513
8292 0.584
1068 0.604
185 0.503
18 0.278
0 0.0
0 0.0
0.5399375975039001
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3885,	 Acc = 0.4785
1049 0.305
4874 0.517
2304 0.489
235 0.353
6 0.0
0 0.0
0 0.0
0 0.0
0.5030327537403962
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4578,	 Acc1 = 0.3955,	 Acc2 = 0.4205

 ===== Epoch 42	 =====
[-0.36710912 -0.3811568   2.9200697   2.731069    2.4094014   0.9513366
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  7.0355767e-01  7.5734980e-02
  1.0573092e+00  1.2164709e-01  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 2
train:	 Loss = 1.4245,	 Acc = 0.4607
8218 0.22
16075 0.511
8293 0.583
1067 0.602
185 0.503
18 0.278
0 0.0
0 0.0
0.5377174506591778
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3721,	 Acc = 0.5064
1049 0.305
4874 0.527
2304 0.574
235 0.328
6 0.0
0 0.0
0 0.0
0 0.0
0.534842970750775
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4483,	 Acc1 = 0.3918,	 Acc2 = 0.4160

 ===== Epoch 43	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.2427468   2.647134
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03 -9.0182051e-02  3.1918278e-01
 -1.5997890e-03 -1.7057455e-03] 4 4
train:	 Loss = 1.4232,	 Acc = 0.4631
8215 0.225
16077 0.514
8293 0.584
1068 0.584
185 0.47
18 0.389
0 0.0
0 0.0
0.5392535392535392
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3780,	 Acc = 0.4924
1049 0.305
4874 0.522
2304 0.526
235 0.404
6 0.0
0 0.0
0 0.0
0 0.0
0.5189378622455857
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4562,	 Acc1 = 0.3891,	 Acc2 = 0.4128

 ===== Epoch 44	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 1 1
train:	 Loss = 1.4223,	 Acc = 0.4646
8218 0.224
16076 0.515
8292 0.587
1067 0.606
185 0.503
18 0.278
0 0.0
0 0.0
0.5416179109134878
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4177,	 Acc = 0.4570
1049 0.305
4874 0.494
2304 0.457
235 0.366
6 0.833
0 0.0
0 0.0
0 0.0
0.4785011457069686
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4825,	 Acc1 = 0.3850,	 Acc2 = 0.4078

 ===== Epoch 45	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  0.8496693   0.94814354] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -2.4674208e+00 -2.3900750e+00] 1 1
train:	 Loss = 1.4246,	 Acc = 0.4631
8214 0.221
16077 0.514
8294 0.584
1068 0.608
185 0.508
18 0.333
0 0.0
0 0.0
0.5404804617424538
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3801,	 Acc = 0.4980
1049 0.183
4874 0.547
2304 0.551
235 0.379
6 0.0
0 0.0
0 0.0
0 0.0
0.5425259468931123
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4553,	 Acc1 = 0.3722,	 Acc2 = 0.4262

 ===== Epoch 46	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  2.0675957   1.5239612
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
 -4.5162553e-01  1.0903254e-01  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 2
train:	 Loss = 1.4211,	 Acc = 0.4629
8214 0.226
16079 0.514
8292 0.581
1068 0.602
185 0.481
18 0.333
0 0.0
0 0.0
0.5387645269479759
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.3892,	 Acc = 0.4895
1049 0.305
4874 0.522
2304 0.523
235 0.328
6 0.0
0 0.0
0 0.0
0 0.0
0.5155681358673676
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4670,	 Acc1 = 0.4002,	 Acc2 = 0.4262

 ===== Epoch 47	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7056503   1.4208906  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 3.2954953e+00  2.8239675e+00  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04 -2.5331575e-01  5.6009513e-01
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 6 6
train:	 Loss = 1.4237,	 Acc = 0.4626
8217 0.222
16081 0.514
8287 0.584
1068 0.593
185 0.503
18 0.389
0 0.0
0 0.0
0.5396856351651781
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3892,	 Acc = 0.4791
1049 0.305
4874 0.524
2304 0.48
235 0.319
6 0.0
0 0.0
0 0.0
0 0.0
0.5037066990160399
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4536,	 Acc1 = 0.3982,	 Acc2 = 0.4237

 ===== Epoch 48	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.1339538   2.4727104
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  1.9430822e-01  1.2955958e+00
 -1.5997890e-03 -1.7057455e-03] 6 6
train:	 Loss = 1.4187,	 Acc = 0.4657
8219 0.222
16074 0.521
8293 0.581
1068 0.615
184 0.473
18 0.389
0 0.0
0 0.0
0.5437453680227796
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3876,	 Acc = 0.4731
1049 0.305
4874 0.519
2304 0.473
235 0.294
6 0.0
0 0.0
0 0.0
0 0.0
0.496832457204475
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4575,	 Acc1 = 0.3986,	 Acc2 = 0.4242

 ===== Epoch 49	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 2 1
train:	 Loss = 1.4237,	 Acc = 0.4633
8215 0.223
16077 0.517
8293 0.58
1068 0.599
185 0.535
18 0.333
0 0.0
0 0.0
0.5404235404235405
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3676,	 Acc = 0.4959
1049 0.305
4874 0.532
2304 0.52
235 0.37
6 0.0
0 0.0
0 0.0
0 0.0
0.5228467448443186
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4419,	 Acc1 = 0.4040,	 Acc2 = 0.4307

 ===== Epoch 50	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.4218029   1.5883087
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03 -4.9766663e-02  1.6828257e-01
 -1.5997890e-03 -1.7057455e-03] 2 4
train:	 Loss = 1.4224,	 Acc = 0.4653
8219 0.225
16076 0.518
8290 0.585
1068 0.586
185 0.476
18 0.389
0 0.0
0 0.0
0.5423801536841284
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3674,	 Acc = 0.5057
1049 0.305
4874 0.518
2304 0.579
235 0.417
6 0.833
0 0.0
0 0.0
0 0.0
0.5340342364200027
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4608,	 Acc1 = 0.3831,	 Acc2 = 0.4056

 ===== Epoch 51	 =====
[ 1.1514666   1.9712012  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  1.1358105   2.2618663 ] [ 2.5549662e-01  1.9425784e-01  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.0378159e-02  3.1391701e-01] 4 4
train:	 Loss = 1.4224,	 Acc = 0.4645
8218 0.224
16078 0.515
8290 0.585
1068 0.616
184 0.522
18 0.389
0 0.0
0 0.0
0.5416179109134878
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3995,	 Acc = 0.4629
1049 0.305
4874 0.499
2304 0.474
235 0.319
6 0.0
0 0.0
0 0.0
0 0.0
0.4852405984634048
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4749,	 Acc1 = 0.3827,	 Acc2 = 0.4051

 ===== Epoch 52	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 3 1
train:	 Loss = 1.4215,	 Acc = 0.4645
8217 0.223
16076 0.515
8292 0.587
1068 0.604
185 0.524
18 0.333
0 0.0
0 0.0
0.541830804633566
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.3629,	 Acc = 0.5136
1049 0.305
4874 0.546
2304 0.554
235 0.391
6 0.0
0 0.0
0 0.0
0 0.0
0.5430651031136272
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4446,	 Acc1 = 0.4050,	 Acc2 = 0.4319

 ===== Epoch 53	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  2.3626964   2.2120445 ] [ 3.4306810e+00  2.6704938e+00  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
  1.5956951e-02  2.1027967e-01] 2 4
train:	 Loss = 1.4243,	 Acc = 0.4650
8218 0.221
16074 0.518
8294 0.585
1068 0.609
184 0.511
18 0.389
0 0.0
0 0.0
0.5431780950152117
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3664,	 Acc = 0.5113
1049 0.305
4874 0.536
2304 0.568
235 0.383
6 0.0
0 0.0
0 0.0
0 0.0
0.5405041110661815
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4516,	 Acc1 = 0.3992,	 Acc2 = 0.4250

 ===== Epoch 54	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  0.9571656   1.3500113
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  1.6005730e-02  7.1862441e-01
 -1.5997890e-03 -1.7057455e-03] 6 6
train:	 Loss = 1.4203,	 Acc = 0.4647
8216 0.222
16078 0.518
8292 0.583
1067 0.616
185 0.514
18 0.278
0 0.0
0 0.0
0.5425897035881435
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3664,	 Acc = 0.4686
1049 0.305
4874 0.511
2304 0.47
235 0.315
6 0.0
0 0.0
0 0.0
0 0.0
0.4917104731095835
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4526,	 Acc1 = 0.3974,	 Acc2 = 0.4227

 ===== Epoch 55	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.599327    1.9784487  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.16784401 -0.14521286  0.00253475  0.00406766
 -0.00159979 -0.00170575] 2 5
train:	 Loss = 1.4214,	 Acc = 0.4652
8215 0.225
16077 0.518
8294 0.582
1067 0.604
185 0.546
18 0.333
0 0.0
0 0.0
0.5421005421005421
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.4200,	 Acc = 0.4628
1049 0.305
4874 0.491
2304 0.486
235 0.357
6 0.0
0 0.0
0 0.0
0 0.0
0.485105809408276
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.5004,	 Acc1 = 0.3773,	 Acc2 = 0.3986

 ===== Epoch 56	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.9559462   1.7037723
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03 -5.9814018e-01  8.8394232e-02
 -1.5997890e-03 -1.7057455e-03] 1 1
train:	 Loss = 1.4213,	 Acc = 0.4664
8216 0.221
16077 0.521
8293 0.584
1067 0.604
185 0.514
18 0.333
0 0.0
0 0.0
0.5450078003120125
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3914,	 Acc = 0.4799
1049 0.305
4874 0.518
2304 0.49
235 0.379
6 0.0
0 0.0
0 0.0
0 0.0
0.504650222401941
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4688,	 Acc1 = 0.3883,	 Acc2 = 0.4118

 ===== Epoch 57	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.9449916   1.802039
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.7346196e-01
 -1.5997890e-03 -1.7057455e-03] 1 5
train:	 Loss = 1.4206,	 Acc = 0.4661
8213 0.223
16077 0.518
8295 0.586
1068 0.616
185 0.503
18 0.278
0 0.0
0 0.0
0.543813126389268
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3614,	 Acc = 0.5001
1049 0.307
4874 0.532
2304 0.53
235 0.417
6 0.0
0 0.0
0 0.0
0 0.0
0.5274295727186953
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4402,	 Acc1 = 0.4035,	 Acc2 = 0.4302

 ===== Epoch 58	 =====
[-0.36710912 -0.3811568   1.9416491   0.93952847 -0.44130662 -0.36481208
  4.6772504   2.309041   -0.40162212 -0.40945497  3.9871294   2.3547902
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  1.4579287e-01 -6.3597478e-02
  1.9079351e-03  5.4739986e-04  1.1816299e+00 -1.8120308e-01
 -1.2693105e-04  5.0422540e-03  1.0525315e+00 -1.4239429e-01
 -1.5997890e-03 -1.7057455e-03] 3 2
train:	 Loss = 1.4197,	 Acc = 0.4698
8216 0.229
16079 0.521
8290 0.59
1068 0.614
185 0.508
18 0.333
0 0.0
0 0.0
0.546996879875195
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3926,	 Acc = 0.4773
1049 0.305
4874 0.523
2304 0.471
235 0.374
6 0.0
0 0.0
0 0.0
0 0.0
0.5016848631891091
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4670,	 Acc1 = 0.4007,	 Acc2 = 0.4267

 ===== Epoch 59	 =====
[ 1.6817352   2.5018084  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  1.5386096   2.7731955 ] [-1.2728070e-01 -4.1668481e-01  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
  3.3196470e-01 -6.7534834e-01] 5 5
train:	 Loss = 1.4187,	 Acc = 0.4659
8215 0.222
16078 0.52
8292 0.584
1068 0.609
185 0.497
18 0.278
0 0.0
0 0.0
0.5442455442455443
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4091,	 Acc = 0.4513
1049 0.305
4874 0.488
2304 0.448
235 0.383
6 0.0
0 0.0
0 0.0
0 0.0
0.47203127106078985
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.5025,	 Acc1 = 0.3592,	 Acc2 = 0.3767

 ===== Epoch 60	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 4 1
train:	 Loss = 1.4213,	 Acc = 0.4649
8220 0.216
16073 0.52
8292 0.584
1068 0.627
185 0.524
18 0.278
0 0.0
0 0.0
0.5447807770322983
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3930,	 Acc = 0.4711
1049 0.305
4874 0.514
2304 0.465
235 0.379
6 0.833
0 0.0
0 0.0
0 0.0
0.4945410432672867
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4736,	 Acc1 = 0.3994,	 Acc2 = 0.4252

 ===== Epoch 61	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 6 1
train:	 Loss = 1.4187,	 Acc = 0.4681
8218 0.224
16076 0.521
8291 0.59
1068 0.606
185 0.514
18 0.222
0 0.0
0 0.0
0.5463374678212028
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3952,	 Acc = 0.4989
1049 0.305
4874 0.508
2304 0.581
235 0.387
6 0.0
0 0.0
0 0.0
0 0.0
0.5263512602776654
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4749,	 Acc1 = 0.3827,	 Acc2 = 0.4051

 ===== Epoch 62	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  2.487397    2.200901
 -0.3641531  -0.3721681   1.6348625   1.2727623  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.08801064  0.05605142
  0.0014167   0.00272805  0.0996833   0.13812535  0.00253475  0.00406766
 -0.00159979 -0.00170575] 4 4
train:	 Loss = 1.4197,	 Acc = 0.4638
8219 0.216
16076 0.517
8291 0.587
1068 0.618
184 0.478
18 0.389
0 0.0
0 0.0
0.5433553067831649
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3732,	 Acc = 0.5038
1049 0.305
4874 0.525
2304 0.553
235 0.455
6 0.833
0 0.0
0 0.0
0 0.0
0.5318776115379431
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4596,	 Acc1 = 0.3961,	 Acc2 = 0.4212

 ===== Epoch 63	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 1
train:	 Loss = 1.4194,	 Acc = 0.4654
8219 0.221
16074 0.519
8292 0.587
1068 0.595
185 0.519
18 0.333
0 0.0
0 0.0
0.5437453680227796
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3948,	 Acc = 0.4779
1049 0.305
4874 0.512
2304 0.493
235 0.374
6 0.833
0 0.0
0 0.0
0 0.0
0.5023588084647527
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4707,	 Acc1 = 0.4017,	 Acc2 = 0.4279

 ===== Epoch 64	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  0.6115207   3.0721383
  3.5081434   2.6394632 ] [ 1.32085965e-03  2.41595390e-03  3.61774070e-03  2.40210793e-03
  1.90793513e-03  5.47399861e-04  1.41669821e-03  2.72805081e-03
 -1.26931045e-04  5.04225399e-03  1.06343865e-01  2.57047385e-01
 -7.76845503e+00 -5.42853212e+00] 4 6
train:	 Loss = 1.4213,	 Acc = 0.4663
8218 0.22
16073 0.521
8295 0.585
1068 0.608
184 0.489
18 0.333
0 0.0
0 0.0
0.5450893205398237
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3746,	 Acc = 0.4941
1049 0.305
4874 0.526
2304 0.52
235 0.409
6 0.833
0 0.0
0 0.0
0 0.0
0.5208249090173878
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4549,	 Acc1 = 0.3984,	 Acc2 = 0.4240

 ===== Epoch 65	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 6 1
train:	 Loss = 1.4194,	 Acc = 0.4654
8216 0.218
16077 0.517
8292 0.59
1068 0.618
185 0.514
18 0.167
0 0.0
0 0.0
0.5446177847113884
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.3956,	 Acc = 0.4806
1049 0.305
4874 0.522
2304 0.487
235 0.366
6 0.0
0 0.0
0 0.0
0 0.0
0.5054589567327133
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4794,	 Acc1 = 0.3893,	 Acc2 = 0.4130

 ===== Epoch 66	 =====
[-0.36710912 -0.3811568   2.8301227   1.2025901  -0.44130662 -0.36481208
  2.056896    2.6665359  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  2.5431815e-01 -1.8826337e-01
  1.9079351e-03  5.4739986e-04 -3.4176867e-02 -4.9332866e-01
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 5 5
train:	 Loss = 1.4208,	 Acc = 0.4657
8219 0.219
16076 0.52
8290 0.586
1068 0.611
185 0.541
18 0.333
0 0.0
0 0.0
0.5449155517416234
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3588,	 Acc = 0.5039
1049 0.305
4874 0.535
2304 0.55
235 0.311
6 0.0
0 0.0
0 0.0
0 0.0
0.5320124005930719
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4510,	 Acc1 = 0.4035,	 Acc2 = 0.4302

 ===== Epoch 67	 =====
[-0.36710912 -0.3811568   1.6038413   1.7219101  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595 -0.05274883  0.10751256  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 4 4
train:	 Loss = 1.4192,	 Acc = 0.4683
8215 0.223
16076 0.521
8294 0.589
1068 0.622
185 0.503
18 0.167
0 0.0
0 0.0
0.5469365469365469
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3697,	 Acc = 0.4942
1049 0.305
4874 0.527
2304 0.52
235 0.421
6 0.0
0 0.0
0 0.0
0 0.0
0.5209596980725165
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4497,	 Acc1 = 0.4005,	 Acc2 = 0.4264

 ===== Epoch 68	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.3216977   1.6669222
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.1649531e-01 -7.5820670e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
train:	 Loss = 1.4185,	 Acc = 0.4675
8220 0.23
16073 0.518
8292 0.586
1068 0.61
185 0.53
18 0.389
0 0.0
0 0.0
0.5435325323763458
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3848,	 Acc = 0.4783
1049 0.336
4874 0.515
2304 0.476
235 0.37
6 0.833
0 0.0
0 0.0
0 0.0
0.49844992586601966
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4602,	 Acc1 = 0.3918,	 Acc2 = 0.4160

 ===== Epoch 69	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.9434803   1.7111423
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  3.9780214e-02  2.5704738e-01
 -1.5997890e-03 -1.7057455e-03] 1 4
train:	 Loss = 1.4192,	 Acc = 0.4699
8215 0.237
16076 0.52
8294 0.584
1068 0.621
185 0.497
18 0.389
0 0.0
0 0.0
0.5445965445965446
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3689,	 Acc = 0.5004
1049 0.315
4874 0.533
2304 0.527
235 0.391
6 0.0
0 0.0
0 0.0
0 0.0
0.526620838387923
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4475,	 Acc1 = 0.4054,	 Acc2 = 0.4324

 ===== Epoch 70	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 1 1
train:	 Loss = 1.4151,	 Acc = 0.4708
8215 0.238
16078 0.521
8293 0.585
1068 0.614
184 0.5
18 0.278
0 0.0
0 0.0
0.5454935454935455
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3758,	 Acc = 0.4968
1049 0.326
4874 0.524
2304 0.532
235 0.362
6 0.0
0 0.0
0 0.0
0 0.0
0.5209596980725165
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4604,	 Acc1 = 0.3949,	 Acc2 = 0.4197

 ===== Epoch 71	 =====
[-0.36710912 -0.3811568   2.6872675   2.1958747  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.03642759 -0.00493118  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4198,	 Acc = 0.4651
8218 0.226
16076 0.517
8293 0.581
1066 0.614
185 0.497
18 0.333
0 0.0
0 0.0
0.541695920118574
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3965,	 Acc = 0.4672
1049 0.183
4874 0.541
2304 0.455
235 0.34
6 0.0
0 0.0
0 0.0
0 0.0
0.5073460035045154
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4683,	 Acc1 = 0.3685,	 Acc2 = 0.4217

 ===== Epoch 72	 =====
[-0.36710912 -0.3811568   3.18828     2.6585002   2.7974682   0.88475233
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -7.4552102e+00 -3.2242446e+00
 -6.9629294e-01  6.4136654e-01  1.4166982e-03  2.7280508e-03
  3.6239080e+00  2.2459898e+00  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 6 6
train:	 Loss = 1.4163,	 Acc = 0.4684
8215 0.237
16078 0.518
8292 0.584
1068 0.607
185 0.514
18 0.333
0 0.0
0 0.0
0.5426855426855427
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3600,	 Acc = 0.4982
1049 0.346
4874 0.53
2304 0.509
235 0.417
6 0.0
0 0.0
0 0.0
0 0.0
0.519746596576358
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4448,	 Acc1 = 0.3959,	 Acc2 = 0.4210

 ===== Epoch 73	 =====
[ 3.300393    2.006575   -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  2.5876482   2.2382665 ] [-1.6080595e+00 -1.1859201e-01  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -4.8702329e-01 -2.1840195e-01] 1 2
train:	 Loss = 1.4185,	 Acc = 0.4685
8216 0.233
16078 0.518
8291 0.587
1068 0.605
185 0.53
18 0.222
0 0.0
0 0.0
0.5440717628705148
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3539,	 Acc = 0.5204
1049 0.336
4874 0.55
2304 0.558
235 0.387
6 0.0
0 0.0
0 0.0
0 0.0
0.546569618546974
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4340,	 Acc1 = 0.4106,	 Acc2 = 0.4386

 ===== Epoch 74	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  2.4700696   0.87587386
  2.0642285   3.2189696 ] [ 1.32085965e-03  2.41595390e-03  3.61774070e-03  2.40210793e-03
  1.90793513e-03  5.47399861e-04  1.41669821e-03  2.72805081e-03
 -1.26931045e-04  5.04225399e-03  2.86231309e-01  2.61485636e-01
  1.00226596e-01  2.90363044e-01] 4 4
train:	 Loss = 1.4195,	 Acc = 0.4702
8216 0.243
16076 0.52
8293 0.582
1068 0.601
185 0.492
18 0.333
0 0.0
0 0.0
0.5429407176287051
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3676,	 Acc = 0.5032
1049 0.343
4874 0.538
2304 0.513
235 0.421
6 0.0
0 0.0
0 0.0
0 0.0
0.5258121040571505
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4456,	 Acc1 = 0.3982,	 Acc2 = 0.4237

 ===== Epoch 75	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   3.3319857   1.4541535  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00115433  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4157,	 Acc = 0.4732
8217 0.242
16077 0.522
8291 0.588
1068 0.616
185 0.53
18 0.389
0 0.0
0 0.0
0.5472132298451577
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3634,	 Acc = 0.5129
1049 0.337
4874 0.546
2304 0.535
235 0.4
6 0.0
0 0.0
0 0.0
0 0.0
0.537808329963607
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4488,	 Acc1 = 0.3996,	 Acc2 = 0.4254

 ===== Epoch 76	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  2.8502302  -4.1090665
 -0.3641531  -0.3721681   1.8068105   2.144931   -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
 -6.9970316e-01  7.9552832e+00  1.4166982e-03  2.7280508e-03
  2.0360632e-01  1.6817637e-01  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 0 2
train:	 Loss = 1.4142,	 Acc = 0.4706
8219 0.245
16075 0.521
8292 0.58
1068 0.604
184 0.484
18 0.389
0 0.0
0 0.0
0.5429262394195888
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.3785,	 Acc = 0.5113
1049 0.317
4874 0.546
2304 0.537
235 0.413
6 0.0
0 0.0
0 0.0
0 0.0
0.538751853349508
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4547,	 Acc1 = 0.4048,	 Acc2 = 0.4317

 ===== Epoch 77	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.1252656   1.8044958
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  1.4279808e-01 -1.0122895e+00
 -1.5997890e-03 -1.7057455e-03] 5 5
train:	 Loss = 1.4161,	 Acc = 0.4727
8215 0.247
16076 0.521
8294 0.584
1068 0.607
185 0.541
18 0.333
0 0.0
0 0.0
0.5451035451035451
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3815,	 Acc = 0.4915
1049 0.339
4874 0.534
2304 0.487
235 0.34
6 0.0
0 0.0
0 0.0
0 0.0
0.5130071438199219
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4546,	 Acc1 = 0.4062,	 Acc2 = 0.4334

 ===== Epoch 78	 =====
[ 1.7234782   1.7614851  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  1.7318645   2.0075128 ] [-5.4960870e-03 -6.2918657e-01  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -4.9879469e-02 -1.0003926e+00] 5 5
train:	 Loss = 1.4144,	 Acc = 0.4738
8218 0.249
16074 0.522
8293 0.584
1068 0.617
185 0.53
18 0.389
0 0.0
0 0.0
0.5459084171932288
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3869,	 Acc = 0.4792
1049 0.321
4874 0.517
2304 0.475
235 0.421
6 0.833
0 0.0
0 0.0
0 0.0
0.5015500741339803
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4662,	 Acc1 = 0.3827,	 Acc2 = 0.4051

 ===== Epoch 79	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.3843932   2.9251618  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00115751  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 6 0
train:	 Loss = 1.4145,	 Acc = 0.4713
8219 0.241
16075 0.52
8291 0.587
1068 0.61
185 0.481
18 0.444
0 0.0
0 0.0
0.5453446191051995
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3667,	 Acc = 0.4891
1049 0.316
4874 0.532
2304 0.49
235 0.379
6 0.0
0 0.0
0 0.0
0 0.0
0.5136810890955654
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4486,	 Acc1 = 0.3939,	 Acc2 = 0.4185

 ===== Epoch 80	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.2107267   2.3760185  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
  5.6887954e-01  6.5144300e-02  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 2 2
train:	 Loss = 1.4133,	 Acc = 0.4734
8218 0.243
16075 0.523
8292 0.586
1068 0.616
185 0.557
18 0.333
0 0.0
0 0.0
0.5471175598720649
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3700,	 Acc = 0.5022
1049 0.349
4874 0.542
2304 0.506
235 0.34
6 0.0
0 0.0
0 0.0
0 0.0
0.5239250572853484
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4518,	 Acc1 = 0.4077,	 Acc2 = 0.4351

 ===== Epoch 81	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 1
train:	 Loss = 1.4135,	 Acc = 0.4728
8216 0.248
16076 0.52
8293 0.586
1068 0.61
185 0.514
18 0.278
0 0.0
0 0.0
0.5448127925117004
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4020,	 Acc = 0.4875
1049 0.349
4874 0.524
2304 0.485
235 0.357
6 0.833
0 0.0
0 0.0
0 0.0
0.507076425394258
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4844,	 Acc1 = 0.3926,	 Acc2 = 0.4170

 ===== Epoch 82	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  2.6770794   1.915046
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03 -7.3541142e-02  1.7715906e-01
 -1.5997890e-03 -1.7057455e-03] 3 2
train:	 Loss = 1.4118,	 Acc = 0.4758
8213 0.252
16080 0.524
8292 0.585
1068 0.61
185 0.535
18 0.389
0 0.0
0 0.0
0.5475958351206957
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3975,	 Acc = 0.4704
1049 0.349
4874 0.519
2304 0.435
235 0.332
6 0.833
0 0.0
0 0.0
0 0.0
0.4875320124005931
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4654,	 Acc1 = 0.3986,	 Acc2 = 0.4242

 ===== Epoch 83	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  2.1825988   1.7332523
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  5.0177926e-01 -3.0660918e-01
 -1.5997890e-03 -1.7057455e-03] 4 5
train:	 Loss = 1.4126,	 Acc = 0.4739
8219 0.251
16076 0.521
8290 0.585
1068 0.61
185 0.508
18 0.333
0 0.0
0 0.0
0.5453446191051995
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3954,	 Acc = 0.4772
1049 0.344
4874 0.519
2304 0.461
235 0.357
6 0.833
0 0.0
0 0.0
0 0.0
0.49602372287370267
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4647,	 Acc1 = 0.3901,	 Acc2 = 0.4140

 ===== Epoch 84	 =====
[ 1.2852527   1.3268926  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 5.9460521e-01  6.9599819e-01  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 6 6
train:	 Loss = 1.4123,	 Acc = 0.4739
8218 0.243
16075 0.523
8292 0.588
1068 0.612
185 0.535
18 0.389
0 0.0
0 0.0
0.5478586473203838
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4064,	 Acc = 0.4821
1049 0.348
4874 0.529
2304 0.458
235 0.362
6 0.0
0 0.0
0 0.0
0 0.0
0.5010109179134654
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4730,	 Acc1 = 0.3972,	 Acc2 = 0.4225

 ===== Epoch 85	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.3247839   2.9201922  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.12462651  0.14241835  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 1
train:	 Loss = 1.4130,	 Acc = 0.4726
8219 0.248
16073 0.519
8293 0.587
1068 0.609
185 0.514
18 0.333
0 0.0
0 0.0
0.5446815149978547
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3838,	 Acc = 0.4838
1049 0.345
4874 0.535
2304 0.452
235 0.349
6 0.833
0 0.0
0 0.0
0 0.0
0.5034371209057824
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4550,	 Acc1 = 0.4027,	 Acc2 = 0.4292

 ===== Epoch 86	 =====
[ 1.0592406   0.9150405  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  1.027077    1.0923647 ] [-1.5348148e+00 -1.5116595e+00  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
  5.4811530e+00  6.5003562e+00  2.5347492e-03  4.0676598e-03
 -2.8211744e+00 -2.6491680e+00] 5 5
train:	 Loss = 1.4124,	 Acc = 0.4719
8218 0.246
16077 0.523
8290 0.58
1068 0.603
185 0.535
18 0.222
0 0.0
0 0.0
0.544426242296591
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3694,	 Acc = 0.4894
1049 0.346
4874 0.532
2304 0.481
235 0.336
6 0.0
0 0.0
0 0.0
0 0.0
0.5096374174417038
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4566,	 Acc1 = 0.3901,	 Acc2 = 0.4140

 ===== Epoch 87	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   2.1249137   1.6653625  -0.42469367 -0.42124885
  3.9351535   1.3257405 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
  1.1305855e-01  3.7853354e-01  2.5347492e-03  4.0676598e-03
 -1.2033057e+00  4.3639746e-01] 2 6
train:	 Loss = 1.4103,	 Acc = 0.4738
8217 0.249
16076 0.521
8292 0.586
1068 0.615
185 0.546
18 0.333
0 0.0
0 0.0
0.5458091189203947
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3971,	 Acc = 0.4727
1049 0.32
4874 0.513
2304 0.464
235 0.404
6 0.833
0 0.0
0 0.0
0 0.0
0.49427146515702924
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4699,	 Acc1 = 0.3856,	 Acc2 = 0.4085

 ===== Epoch 88	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  2.6529033   1.8609993
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  7.0327425e+00  3.1351311e+00
 -1.2693105e-04  5.0422540e-03  2.1728656e-01  1.0293013e+00
 -1.5997890e-03 -1.7057455e-03] 6 6
train:	 Loss = 1.4098,	 Acc = 0.4742
8218 0.253
16077 0.52
8290 0.584
1068 0.625
185 0.53
18 0.389
0 0.0
0 0.0
0.5452843435525392
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3900,	 Acc = 0.4822
1049 0.342
4874 0.521
2304 0.476
235 0.353
6 0.833
0 0.0
0 0.0
0 0.0
0.5019544412993665
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4656,	 Acc1 = 0.3963,	 Acc2 = 0.4215

 ===== Epoch 89	 =====
[ 2.973189    2.4917014  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  1.5241525   1.8984809  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [-6.3723460e-02 -3.1338534e-01  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  9.2630573e-02 -5.7136005e-01
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 5 5
train:	 Loss = 1.4107,	 Acc = 0.4754
8217 0.252
16075 0.523
8293 0.584
1068 0.618
185 0.578
18 0.278
0 0.0
0 0.0
0.5469402082764538
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4061,	 Acc = 0.4786
1049 0.347
4874 0.526
2304 0.451
235 0.366
6 0.0
0 0.0
0 0.0
0 0.0
0.49723682436986116
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4796,	 Acc1 = 0.3963,	 Acc2 = 0.4215

 ===== Epoch 90	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.3557358   1.7722094  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.01967929  0.06085129  0.00253475  0.00406766
 -0.00159979 -0.00170575] 4 4
train:	 Loss = 1.4120,	 Acc = 0.4748
8214 0.247
16077 0.522
8294 0.588
1068 0.62
185 0.562
18 0.333
0 0.0
0 0.0
0.5476171905467592
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4179,	 Acc = 0.4636
1049 0.306
4874 0.495
2304 0.474
235 0.4
6 0.833
0 0.0
0 0.0
0 0.0
0.4859145437390484
0.5492653996495485
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.5034,	 Acc1 = 0.3722,	 Acc2 = 0.3924

 ===== Epoch 91	 =====
[-0.36710912 -0.3811568   1.783734    3.0213442  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00193512 -0.00248675  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4137,	 Acc = 0.4718
8215 0.244
16078 0.518
8292 0.588
1068 0.624
185 0.497
18 0.278
0 0.0
0 0.0
0.5447135447135447
0.5492653996495485
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3515,	 Acc = 0.5249
1049 0.343
4874 0.552
2304 0.568
235 0.357
6 0.0
0 0.0
0 0.0
0 0.0
0.5506132902008357
0.5506132902008357
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4468,	 Acc1 = 0.3928,	 Acc2 = 0.4172

 ===== Epoch 92	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 5 1
train:	 Loss = 1.4100,	 Acc = 0.4745
8216 0.251
16078 0.521
8292 0.587
1067 0.623
185 0.519
18 0.389
0 0.0
0 0.0
0.5461778471138845
0.5506132902008357
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3821,	 Acc = 0.4933
1049 0.343
4874 0.537
2304 0.486
235 0.336
6 0.0
0 0.0
0 0.0
0 0.0
0.5144898234263378
0.5506132902008357
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4593,	 Acc1 = 0.4005,	 Acc2 = 0.4264

 ===== Epoch 93	 =====
[-0.36710912 -0.3811568   2.0543864   1.7332491  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  2.6189125e-01  2.2973402e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 5 2
train:	 Loss = 1.4111,	 Acc = 0.4738
8216 0.249
16077 0.521
8292 0.586
1068 0.616
185 0.514
18 0.444
0 0.0
0 0.0
0.5459828393135725
0.5506132902008357
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4272,	 Acc = 0.4655
1049 0.344
4874 0.512
2304 0.435
235 0.336
6 0.833
0 0.0
0 0.0
0 0.0
0.48267960641595903
0.5506132902008357
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4935,	 Acc1 = 0.3893,	 Acc2 = 0.4130

 ===== Epoch 94	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.045657    2.800921   -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.30057865  0.4515146   0.00253475  0.00406766
 -0.00159979 -0.00170575] 1 1
train:	 Loss = 1.4117,	 Acc = 0.4765
8216 0.251
16077 0.525
8293 0.588
1067 0.626
185 0.492
18 0.333
0 0.0
0 0.0
0.5489079563182527
0.5506132902008357
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.4036,	 Acc = 0.4850
1049 0.343
4874 0.523
2304 0.481
235 0.374
6 0.0
0 0.0
0 0.0
0 0.0
0.5050545895673272
0.5506132902008357
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4763,	 Acc1 = 0.3988,	 Acc2 = 0.4245

 ===== Epoch 95	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 2 1
train:	 Loss = 1.4107,	 Acc = 0.4748
8218 0.247
16078 0.524
8289 0.587
1068 0.622
185 0.519
18 0.333
0 0.0
0 0.0
0.5478586473203838
0.5506132902008357
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3901,	 Acc = 0.4969
1049 0.345
4874 0.541
2304 0.484
235 0.379
6 0.833
0 0.0
0 0.0
0 0.0
0.5183987060250708
0.5506132902008357
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4646,	 Acc1 = 0.4035,	 Acc2 = 0.4302

 ===== Epoch 96	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  1.5384473   1.2398684
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4147,	 Acc = 0.4701
8219 0.243
16077 0.518
8290 0.581
1067 0.628
185 0.551
18 0.333
0 0.0
0 0.0
0.5428092210477045
0.5506132902008357
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4024,	 Acc = 0.4771
1049 0.32
4874 0.515
2304 0.474
235 0.404
6 0.833
0 0.0
0 0.0
0 0.0
0.49925866019679205
0.5506132902008357
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4747,	 Acc1 = 0.3945,	 Acc2 = 0.4192

 ===== Epoch 97	 =====
[-0.36710912 -0.3811568   1.8252481   2.4612043  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  1.8112534e-01 -2.3470752e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 5 5
train:	 Loss = 1.4130,	 Acc = 0.4744
8218 0.245
16074 0.522
8293 0.59
1068 0.632
185 0.503
18 0.278
0 0.0
0 0.0
0.5480536703330993
0.5506132902008357
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3926,	 Acc = 0.4833
1049 0.337
4874 0.524
2304 0.473
235 0.383
6 0.833
0 0.0
0 0.0
0 0.0
0.5039762771262973
0.5506132902008357
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4714,	 Acc1 = 0.3943,	 Acc2 = 0.4190

 ===== Epoch 98	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 1 1
train:	 Loss = 1.4113,	 Acc = 0.4750
8216 0.246
16080 0.523
8290 0.587
1067 0.629
185 0.541
18 0.333
0 0.0
0 0.0
0.5484789391575663
0.5506132902008357
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4006,	 Acc = 0.4680
1049 0.333
4874 0.507
2304 0.459
235 0.362
6 0.0
0 0.0
0 0.0
0 0.0
0.4871276452352069
0.5506132902008357
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4739,	 Acc1 = 0.3901,	 Acc2 = 0.4140

 ===== Epoch 99	 =====
[-0.36710912 -0.3811568   1.633145    1.7944789  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  8.1015788e-02 -3.9603984e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 5 5
train:	 Loss = 1.4117,	 Acc = 0.4745
8217 0.25
16075 0.519
8293 0.59
1068 0.619
185 0.551
18 0.389
0 0.0
0 0.0
0.546394165139046
0.5506132902008357
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3716,	 Acc = 0.5204
1049 0.345
4874 0.549
2304 0.552
235 0.404
6 0.833
0 0.0
0 0.0
0 0.0
0.5452217279956868
0.5506132902008357
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4431,	 Acc1 = 0.4073,	 Acc2 = 0.4346

 ===== Epoch 100	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  3.079248    1.4928886
 -0.3641531  -0.3721681   2.3295321   1.2354901  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211 -0.02707846  0.13678455
  0.0014167   0.00272805 -0.35511342  0.24545044  0.00253475  0.00406766
 -0.00159979 -0.00170575] 6 2
train:	 Loss = 1.4104,	 Acc = 0.4760
8212 0.25
16081 0.524
8292 0.587
1068 0.625
185 0.519
18 0.389
0 0.0
0 0.0
0.5483543908906566
0.5506132902008357
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3850,	 Acc = 0.4953
1049 0.316
4874 0.532
2304 0.503
235 0.447
6 0.833
0 0.0
0 0.0
0 0.0
0.5205553309071304
0.5506132902008357
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4667,	 Acc1 = 0.3943,	 Acc2 = 0.4190

 ===== Epoch 101	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  0.78755337  2.342507
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  1.0000646e-01 -5.1520652e-01
 -1.5997890e-03 -1.7057455e-03] 5 5
train:	 Loss = 1.4125,	 Acc = 0.4732
8213 0.247
16079 0.521
8293 0.586
1068 0.601
185 0.562
18 0.389
0 0.0
0 0.0
0.5454899972702102
0.5506132902008357
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3712,	 Acc = 0.5031
1049 0.309
4874 0.537
2304 0.539
235 0.34
6 0.0
0 0.0
0 0.0
0 0.0
0.5305297209866559
0.5506132902008357
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4529,	 Acc1 = 0.4017,	 Acc2 = 0.4279

 ===== Epoch 102	 =====
[ 0.6141392   1.1677105  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  0.54239666  1.5276499 ] [ 8.5750120e-03  4.9825349e-01  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -5.6022972e-02  6.5780443e-01] 6 6
train:	 Loss = 1.4089,	 Acc = 0.4765
8218 0.255
16076 0.523
8292 0.588
1068 0.625
184 0.489
18 0.278
0 0.0
0 0.0
0.5476636243076684
0.5506132902008357
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3765,	 Acc = 0.5001
1049 0.344
4874 0.533
2304 0.512
235 0.396
6 0.833
0 0.0
0 0.0
0 0.0
0.522172799568675
0.5506132902008357
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4597,	 Acc1 = 0.3815,	 Acc2 = 0.4036

 ===== Epoch 103	 =====
[-0.36710912 -0.3811568   3.0332146   2.381832   -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  1.2055613e-01  1.9551203e-01
  6.9720678e+00  1.3780563e+00  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 6 2
train:	 Loss = 1.4129,	 Acc = 0.4735
8218 0.241
16077 0.522
8291 0.59
1067 0.621
185 0.508
18 0.389
0 0.0
0 0.0
0.5482096887432717
0.5506132902008357
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4028,	 Acc = 0.4640
1049 0.309
4874 0.506
2304 0.458
235 0.345
6 0.833
0 0.0
0 0.0
0 0.0
0.4859145437390484
0.5506132902008357
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4846,	 Acc1 = 0.3914,	 Acc2 = 0.4155

 ===== Epoch 104	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7664702   1.8845164  -0.40162212 -0.40945497  3.1908243   2.7355742
 -0.38694263 -0.3813124 ] [ 1.32085965e-03  2.41595390e-03  3.61774070e-03  2.40210793e-03
  1.90793513e-03  5.47399861e-04  1.09375501e+00 -1.25466377e-01
 -1.26931045e-04  5.04225399e-03  2.15543341e-02 -1.24641314e-01
 -1.59978902e-03 -1.70574547e-03] 2 2
train:	 Loss = 1.4113,	 Acc = 0.4750
8218 0.248
16076 0.524
8291 0.585
1068 0.623
185 0.535
18 0.333
0 0.0
0 0.0
0.5476246197051252
0.5506132902008357
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3641,	 Acc = 0.5120
1049 0.183
4874 0.557
2304 0.576
235 0.443
6 0.0
0 0.0
0 0.0
0 0.0
0.5585658444534304
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4478,	 Acc1 = 0.3755,	 Acc2 = 0.4302

 ===== Epoch 105	 =====
[-0.36710912 -0.3811568   1.2375436   2.2661757  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -8.3033435e-02 -3.1781811e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 5 5
train:	 Loss = 1.4110,	 Acc = 0.4754
8217 0.25
16077 0.523
8291 0.588
1068 0.61
185 0.524
18 0.444
0 0.0
0 0.0
0.5477592729825657
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3749,	 Acc = 0.5216
1049 0.349
4874 0.551
2304 0.551
235 0.404
6 0.0
0 0.0
0 0.0
0 0.0
0.5460304623264591
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4562,	 Acc1 = 0.4040,	 Acc2 = 0.4307

 ===== Epoch 106	 =====
[-0.36710912 -0.3811568   1.6608207   0.8034621  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -2.5465316e-01  2.6846400e-02
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 3 1
train:	 Loss = 1.4114,	 Acc = 0.4745
8217 0.246
16074 0.525
8294 0.583
1068 0.621
185 0.508
18 0.333
0 0.0
0 0.0
0.5477592729825657
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.3948,	 Acc = 0.4697
1049 0.317
4874 0.506
2304 0.471
235 0.366
6 0.833
0 0.0
0 0.0
0 0.0
0.4911713168890686
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4739,	 Acc1 = 0.3860,	 Acc2 = 0.4090

 ===== Epoch 107	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  0.7068733   2.0588546
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  6.1693233e-03 -3.3247674e-01  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 5 5
train:	 Loss = 1.4089,	 Acc = 0.4762
8216 0.25
16078 0.524
8291 0.588
1068 0.618
185 0.519
18 0.389
0 0.0
0 0.0
0.5486739469578783
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.4094,	 Acc = 0.4771
1049 0.183
4874 0.524
2304 0.525
235 0.353
6 0.0
0 0.0
0 0.0
0 0.0
0.5186682841353282
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4984,	 Acc1 = 0.3588,	 Acc2 = 0.4100

 ===== Epoch 108	 =====
[ 0.53611106  2.0217352  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  0.5644071   2.3431544 ] [ 1.9676876e-01  7.7568638e-01  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5784664e-01  1.3973980e+00] 6 6
train:	 Loss = 1.4094,	 Acc = 0.4755
8217 0.247
16074 0.523
8294 0.59
1068 0.624
185 0.514
18 0.278
0 0.0
0 0.0
0.5489293654198681
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3983,	 Acc = 0.4751
1049 0.307
4874 0.523
2304 0.464
235 0.357
6 0.0
0 0.0
0 0.0
0 0.0
0.4988542930314058
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4706,	 Acc1 = 0.3976,	 Acc2 = 0.4230

 ===== Epoch 109	 =====
[-0.36710912 -0.3811568   2.2440474   2.1482515  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  1.6514173e-01 -7.4848843e+00
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 2 1
train:	 Loss = 1.4119,	 Acc = 0.4735
8219 0.243
16077 0.522
8290 0.585
1067 0.634
185 0.535
18 0.333
0 0.0
0 0.0
0.5473729375511955
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3929,	 Acc = 0.4818
1049 0.346
4874 0.524
2304 0.468
235 0.357
6 0.0
0 0.0
0 0.0
0 0.0
0.5010109179134654
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4687,	 Acc1 = 0.3951,	 Acc2 = 0.4200

 ===== Epoch 110	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  2.2037785   3.090482  ] [ 3.2375371e+00  3.5765781e+00  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
  9.5836051e-02 -2.8435296e-01] 5 5
train:	 Loss = 1.4094,	 Acc = 0.4773
8219 0.245
16076 0.526
8290 0.593
1068 0.627
185 0.503
18 0.389
0 0.0
0 0.0
0.5515855989390335
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3950,	 Acc = 0.5038
1049 0.335
4874 0.54
2304 0.519
235 0.366
6 0.333
0 0.0
0 0.0
0 0.0
0.5276991508289527
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4598,	 Acc1 = 0.4095,	 Acc2 = 0.4374

 ===== Epoch 111	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  4.5688167   2.915572
 -0.3641531  -0.3721681   5.3959317   2.462987    0.29307398  1.4605619
  3.1185498   1.3414737 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
 -9.6142405e-01 -7.8759780e+00  1.4166982e-03  2.7280508e-03
  1.8919730e-01  8.6609311e-02  2.9574111e-01  1.6384433e-01
  9.7890216e-01  2.0556888e-01] 2 2
train:	 Loss = 1.4103,	 Acc = 0.4757
8218 0.253
16073 0.521
8294 0.589
1068 0.622
185 0.519
18 0.444
0 0.0
0 0.0
0.5470785552695218
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3929,	 Acc = 0.4765
1049 0.316
4874 0.517
2304 0.471
235 0.421
6 0.0
0 0.0
0 0.0
0 0.0
0.49925866019679205
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4749,	 Acc1 = 0.3897,	 Acc2 = 0.4135

 ===== Epoch 112	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 1
train:	 Loss = 1.4116,	 Acc = 0.4749
8217 0.241
16077 0.528
8291 0.586
1068 0.619
185 0.497
18 0.278
0 0.0
0 0.0
0.5499824486134405
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3942,	 Acc = 0.4822
1049 0.332
4874 0.526
2304 0.468
235 0.366
6 0.833
0 0.0
0 0.0
0 0.0
0.5034371209057824
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4796,	 Acc1 = 0.3918,	 Acc2 = 0.4160

 ===== Epoch 113	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 1 1
train:	 Loss = 1.4120,	 Acc = 0.4758
8216 0.248
16080 0.525
8291 0.588
1067 0.614
184 0.5
18 0.333
0 0.0
0 0.0
0.5486349453978159
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3608,	 Acc = 0.5103
1049 0.343
4874 0.545
2304 0.519
235 0.455
6 0.333
0 0.0
0 0.0
0 0.0
0.5338994473648739
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4523,	 Acc1 = 0.3951,	 Acc2 = 0.4200

 ===== Epoch 114	 =====
[-0.36710912 -0.3811568   1.605063    1.7037679  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -2.3304224e-02  5.0106567e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 6 6
train:	 Loss = 1.4149,	 Acc = 0.4736
8217 0.244
16078 0.525
8290 0.582
1068 0.617
185 0.53
18 0.333
0 0.0
0 0.0
0.547330239088888
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3777,	 Acc = 0.5084
1049 0.306
4874 0.535
2304 0.553
235 0.417
6 0.833
0 0.0
0 0.0
0 0.0
0.5369995956328346
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4569,	 Acc1 = 0.4071,	 Acc2 = 0.4344

 ===== Epoch 115	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  1.2735499   2.543647   -0.40162212 -0.40945497  2.3850756   2.0133128
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4491196e-01  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  5.4536217e-01  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 0 0
train:	 Loss = 1.4086,	 Acc = 0.4784
8213 0.254
16080 0.527
8292 0.589
1068 0.613
185 0.508
18 0.333
0 0.0
0 0.0
0.550403618921343
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3969,	 Acc = 0.4778
1049 0.322
4874 0.512
2304 0.485
235 0.391
6 0.833
0 0.0
0 0.0
0 0.0
0.4997978164173069
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4758,	 Acc1 = 0.3939,	 Acc2 = 0.4185

 ===== Epoch 116	 =====
[-0.36710912 -0.3811568   2.2123017   1.5382205  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.04736333  0.06595727  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 2 3
train:	 Loss = 1.4095,	 Acc = 0.4765
8220 0.25
16074 0.524
8291 0.589
1068 0.621
185 0.508
18 0.389
0 0.0
0 0.0
0.5491106256826338
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3640,	 Acc = 0.5188
1049 0.337
4874 0.537
2304 0.576
235 0.417
6 0.0
0 0.0
0 0.0
0 0.0
0.5445477827200431
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4473,	 Acc1 = 0.4029,	 Acc2 = 0.4294

 ===== Epoch 117	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
  3.2428286e+00  2.3913741e+00] 1 1
train:	 Loss = 1.4100,	 Acc = 0.4749
8219 0.249
16073 0.524
8293 0.583
1068 0.629
185 0.503
18 0.389
0 0.0
0 0.0
0.5473339314272341
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.4071,	 Acc = 0.4995
1049 0.352
4874 0.524
2304 0.525
235 0.387
6 0.833
0 0.0
0 0.0
0 0.0
0.5204205418520016
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4872,	 Acc1 = 0.3974,	 Acc2 = 0.4227

 ===== Epoch 118	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 1 1
train:	 Loss = 1.4099,	 Acc = 0.4749
8218 0.252
16077 0.523
8290 0.585
1068 0.609
185 0.481
18 0.444
0 0.0
0 0.0
0.5464934862313753
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3707,	 Acc = 0.5254
1049 0.347
4874 0.55
2304 0.57
235 0.396
6 0.0
0 0.0
0 0.0
0 0.0
0.5506132902008357
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4621,	 Acc1 = 0.3959,	 Acc2 = 0.4210

 ===== Epoch 119	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  2.19091     2.1459732
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  7.9726872e+00  2.7951372e+00
 -1.2693105e-04  5.0422540e-03  4.2490968e-01  3.1030628e-01
 -1.5997890e-03 -1.7057455e-03] 2 2
train:	 Loss = 1.4109,	 Acc = 0.4742
8214 0.241
16079 0.525
8292 0.588
1068 0.618
185 0.492
18 0.389
0 0.0
0 0.0
0.5488261446065049
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4061,	 Acc = 0.4824
1049 0.317
4874 0.519
2304 0.488
235 0.404
6 0.833
0 0.0
0 0.0
0 0.0
0.5057285348429708
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4881,	 Acc1 = 0.3951,	 Acc2 = 0.4200

 ===== Epoch 120	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 5 1
train:	 Loss = 1.4085,	 Acc = 0.4766
8217 0.254
16077 0.523
8292 0.588
1067 0.615
185 0.524
18 0.333
0 0.0
0 0.0
0.5478372791450524
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3894,	 Acc = 0.5109
1049 0.317
4874 0.529
2304 0.572
235 0.426
6 0.0
0 0.0
0 0.0
0 0.0
0.5382126971289931
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4688,	 Acc1 = 0.3992,	 Acc2 = 0.4250

 ===== Epoch 121	 =====
[-0.36710912 -0.3811568   1.7190219   1.7083036  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595 -0.05190621  0.11484585  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 4 4
train:	 Loss = 1.4092,	 Acc = 0.4742
8216 0.248
16077 0.523
8292 0.582
1068 0.631
185 0.546
18 0.389
0 0.0
0 0.0
0.5464898595943838
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3862,	 Acc = 0.5022
1049 0.323
4874 0.539
2304 0.513
235 0.443
6 0.0
0 0.0
0 0.0
0 0.0
0.5275643617738239
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4568,	 Acc1 = 0.4097,	 Acc2 = 0.4376

 ===== Epoch 122	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 6 1
train:	 Loss = 1.4112,	 Acc = 0.4766
8213 0.251
16081 0.524
8291 0.588
1068 0.637
185 0.519
18 0.333
0 0.0
0 0.0
0.5489997270210194
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3621,	 Acc = 0.5145
1049 0.347
4874 0.549
2304 0.531
235 0.387
6 0.0
0 0.0
0 0.0
0 0.0
0.5382126971289931
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4448,	 Acc1 = 0.4091,	 Acc2 = 0.4369

 ===== Epoch 123	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   2.5490515   2.132507   -0.42469367 -0.42124885
  3.8625178   1.9655575 ] [0.00132086 0.00241595 0.00361774 0.00240211 0.00190794 0.0005474
 0.0014167  0.00272805 0.36926544 0.13383234 0.00253475 0.00406766
 0.46099997 0.10664236] 3 2
train:	 Loss = 1.4098,	 Acc = 0.4746
8214 0.246
16080 0.522
8292 0.588
1067 0.632
185 0.503
18 0.389
0 0.0
0 0.0
0.5478121831370408
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.3805,	 Acc = 0.4963
1049 0.343
4874 0.542
2304 0.477
235 0.413
6 0.833
0 0.0
0 0.0
0 0.0
0.5179943388596846
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4611,	 Acc1 = 0.3959,	 Acc2 = 0.4210

 ===== Epoch 124	 =====
[ 1.7594522   1.3749     -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.01591402 -0.0093897   0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4101,	 Acc = 0.4755
8220 0.247
16077 0.526
8288 0.584
1068 0.633
185 0.486
18 0.278
0 0.0
0 0.0
0.5487205492276486
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.4109,	 Acc = 0.4708
1049 0.317
4874 0.521
2304 0.447
235 0.328
6 0.833
0 0.0
0 0.0
0 0.0
0.4925192074403558
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4898,	 Acc1 = 0.3943,	 Acc2 = 0.4190

 ===== Epoch 125	 =====
[ 2.791942    3.2749786  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  2.5942512   3.525767  ] [ 0.00617326  0.0112702   0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4132,	 Acc = 0.4738
8216 0.248
16078 0.523
8291 0.581
1068 0.627
185 0.524
18 0.389
0 0.0
0 0.0
0.5461388455538222
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3830,	 Acc = 0.5162
1049 0.347
4874 0.53
2304 0.572
235 0.417
6 0.833
0 0.0
0 0.0
0 0.0
0.5400997439007953
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4674,	 Acc1 = 0.3959,	 Acc2 = 0.4210

 ===== Epoch 126	 =====
[ 1.4532032   1.4178538  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   3.4741302   3.2357633  -0.42469367 -0.42124885
  1.5328859   1.4856948 ] [-0.20061465  0.11161827  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805  0.05131928  0.10378133  0.00253475  0.00406766
 -0.3395521   0.22441202] 4 4
train:	 Loss = 1.4098,	 Acc = 0.4756
8216 0.245
16077 0.526
8292 0.586
1068 0.635
185 0.486
18 0.333
0 0.0
0 0.0
0.549609984399376
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3762,	 Acc = 0.5040
1049 0.343
4874 0.53
2304 0.538
235 0.366
6 0.0
0 0.0
0 0.0
0 0.0
0.5267556274430516
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4664,	 Acc1 = 0.3910,	 Acc2 = 0.4150

 ===== Epoch 127	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  0.09552297  1.144431
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.32085965e-03  2.41595390e-03  3.61774070e-03  2.40210793e-03
  1.02505155e-01 -1.53350115e-01  1.41669821e-03  2.72805081e-03
 -1.26931045e-04  5.04225399e-03  2.53474922e-03  4.06765984e-03
 -1.59978902e-03 -1.70574547e-03] 5 5
train:	 Loss = 1.4102,	 Acc = 0.4791
8217 0.253
16075 0.527
8294 0.588
1067 0.634
185 0.562
18 0.333
0 0.0
0 0.0
0.5516595811069075
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.4186,	 Acc = 0.4695
1049 0.344
4874 0.521
2304 0.437
235 0.294
6 0.0
0 0.0
0 0.0
0 0.0
0.4872624342903356
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4900,	 Acc1 = 0.3992,	 Acc2 = 0.4250

 ===== Epoch 128	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.770847    2.9050846
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.11189247 -0.04031475
 -0.00159979 -0.00170575] 1 2
train:	 Loss = 1.4067,	 Acc = 0.4780
8216 0.253
16077 0.527
8292 0.588
1068 0.615
185 0.503
18 0.389
0 0.0
0 0.0
0.5501170046801872
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3828,	 Acc = 0.4874
1049 0.343
4874 0.521
2304 0.493
235 0.396
6 0.0
0 0.0
0 0.0
0 0.0
0.5077503706699016
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4821,	 Acc1 = 0.3778,	 Acc2 = 0.3991

 ===== Epoch 129	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  1.4031014   1.3863539
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
 -9.5279120e-02  3.3861738e-01  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 6 6
train:	 Loss = 1.4082,	 Acc = 0.4788
8217 0.255
16079 0.525
8290 0.592
1067 0.617
185 0.557
18 0.333
0 0.0
0 0.0
0.5506455009945785
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4074,	 Acc = 0.5096
1049 0.35
4874 0.538
2304 0.533
235 0.409
6 0.0
0 0.0
0 0.0
0 0.0
0.5321471896482005
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4842,	 Acc1 = 0.4031,	 Acc2 = 0.4297

 ===== Epoch 130	 =====
[ 1.9137604   2.1076431  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  2.1918914   2.3300436 ] [ 2.1213855e-01  7.9152711e-02  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.0375446e-02  1.4903945e-01] 1 4
train:	 Loss = 1.4072,	 Acc = 0.4776
8217 0.254
16078 0.525
8291 0.588
1068 0.621
184 0.527
18 0.389
0 0.0
0 0.0
0.5490853777448419
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3834,	 Acc = 0.4967
1049 0.342
4874 0.541
2304 0.489
235 0.362
6 0.0
0 0.0
0 0.0
0 0.0
0.5185334950801995
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4761,	 Acc1 = 0.3990,	 Acc2 = 0.4247

 ===== Epoch 131	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 5 1
train:	 Loss = 1.4102,	 Acc = 0.4765
8217 0.245
16074 0.526
8294 0.592
1068 0.613
185 0.519
18 0.333
0 0.0
0 0.0
0.5507235071570654
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3719,	 Acc = 0.5179
1049 0.348
4874 0.545
2304 0.547
235 0.426
6 0.833
0 0.0
0 0.0
0 0.0
0.5419867906725974
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4699,	 Acc1 = 0.3982,	 Acc2 = 0.4237

 ===== Epoch 132	 =====
[ 2.9173803   1.4734412  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [-3.5359757e+00 -2.1639218e+00  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 1 1
train:	 Loss = 1.4077,	 Acc = 0.4781
8219 0.253
16076 0.528
8293 0.587
1065 0.613
185 0.497
18 0.333
0 0.0
0 0.0
0.5500643601045364
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.4076,	 Acc = 0.4776
1049 0.345
4874 0.516
2304 0.47
235 0.362
6 0.0
0 0.0
0 0.0
0 0.0
0.49629330098396013
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4775,	 Acc1 = 0.3920,	 Acc2 = 0.4163

 ===== Epoch 133	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.6952968   2.4579706
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03 -2.8354049e-01  1.1502369e-01
 -1.5997890e-03 -1.7057455e-03] 6 4
train:	 Loss = 1.4136,	 Acc = 0.4753
8218 0.249
16075 0.524
8292 0.583
1068 0.627
185 0.535
18 0.278
0 0.0
0 0.0
0.5476636243076684
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3626,	 Acc = 0.5205
1049 0.348
4874 0.546
2304 0.559
235 0.374
6 0.833
0 0.0
0 0.0
0 0.0
0.5449521498854293
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4490,	 Acc1 = 0.3992,	 Acc2 = 0.4250

 ===== Epoch 134	 =====
[ 3.2557964   3.052629   -0.4201916  -0.33495995 -0.44130662 -0.36481208
  1.5055686   2.3062482  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [-3.9004395e+00 -4.0085554e+00  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04 -1.2872969e-01 -3.6513424e-01
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 5 5
train:	 Loss = 1.4101,	 Acc = 0.4741
8216 0.246
16079 0.521
8290 0.59
1068 0.61
185 0.541
18 0.389
0 0.0
0 0.0
0.5471528861154447
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4362,	 Acc = 0.4620
1049 0.316
4874 0.492
2304 0.468
235 0.421
6 0.833
0 0.0
0 0.0
0 0.0
0.4825448173608303
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4994,	 Acc1 = 0.3852,	 Acc2 = 0.4081

 ===== Epoch 135	 =====
[ 0.8434029   3.0627358  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00538658  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4099,	 Acc = 0.4760
8217 0.253
16077 0.524
8291 0.586
1068 0.621
185 0.492
18 0.389
0 0.0
0 0.0
0.5474472483326183
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3872,	 Acc = 0.4885
1049 0.347
4874 0.528
2304 0.482
235 0.366
6 0.833
0 0.0
0 0.0
0 0.0
0.5085591050006739
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4648,	 Acc1 = 0.3883,	 Acc2 = 0.4118

 ===== Epoch 136	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 1
train:	 Loss = 1.4091,	 Acc = 0.4747
8217 0.248
16073 0.523
8295 0.585
1068 0.638
185 0.546
18 0.389
0 0.0
0 0.0
0.5474862514138616
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3928,	 Acc = 0.4940
1049 0.345
4874 0.536
2304 0.487
235 0.366
6 0.0
0 0.0
0 0.0
0 0.0
0.5150289796468527
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4663,	 Acc1 = 0.4031,	 Acc2 = 0.4297

 ===== Epoch 137	 =====
[ 0.415078    2.7544785  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [-8.4107113e-01 -3.6602886e+00  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 1 5
train:	 Loss = 1.4107,	 Acc = 0.4782
8216 0.25
16076 0.526
8293 0.59
1068 0.642
185 0.546
18 0.333
0 0.0
0 0.0
0.5515210608424337
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3949,	 Acc = 0.5022
1049 0.346
4874 0.523
2304 0.539
235 0.391
6 0.833
0 0.0
0 0.0
0 0.0
0.5243294244507346
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4727,	 Acc1 = 0.4077,	 Acc2 = 0.4351

 ===== Epoch 138	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  5.9081464e+00  3.6869247e+00
 -1.2693105e-04  5.0422540e-03  4.9332252e+00  6.6392374e+00
 -1.5997890e-03 -1.7057455e-03] 2 6
train:	 Loss = 1.4082,	 Acc = 0.4776
8217 0.252
16076 0.526
8293 0.588
1067 0.631
185 0.514
18 0.389
0 0.0
0 0.0
0.5498264362884668
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3767,	 Acc = 0.5135
1049 0.343
4874 0.55
2304 0.526
235 0.409
6 0.0
0 0.0
0 0.0
0 0.0
0.5375387518533495
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4605,	 Acc1 = 0.4019,	 Acc2 = 0.4282

 ===== Epoch 139	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  1.680675    2.411751
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
 -4.7295742e+00 -3.1556132e+00  1.4166982e-03  2.7280508e-03
  3.1475072e+00  2.6495321e+00  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 6 6
train:	 Loss = 1.4079,	 Acc = 0.4770
8217 0.25
16079 0.524
8292 0.592
1066 0.626
184 0.505
18 0.389
0 0.0
0 0.0
0.5495924178010063
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3603,	 Acc = 0.5192
1049 0.348
4874 0.552
2304 0.54
235 0.413
6 0.0
0 0.0
0 0.0
0 0.0
0.5434694702790134
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4480,	 Acc1 = 0.4009,	 Acc2 = 0.4269

 ===== Epoch 140	 =====
[-0.36710912 -0.3811568   1.8451899   1.6697514  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  4.3771622e-01 -9.0486199e-02
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 2 3
train:	 Loss = 1.4194,	 Acc = 0.4694
8215 0.239
16077 0.515
8293 0.587
1068 0.643
185 0.503
18 0.389
0 0.0
0 0.0
0.5432315432315432
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3895,	 Acc = 0.4855
1049 0.316
4874 0.516
2304 0.504
235 0.413
6 0.833
0 0.0
0 0.0
0 0.0
0.509502628386575
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4721,	 Acc1 = 0.3947,	 Acc2 = 0.4195

 ===== Epoch 141	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 1 1
train:	 Loss = 1.4090,	 Acc = 0.4753
8216 0.246
16076 0.524
8293 0.587
1068 0.637
185 0.524
18 0.278
0 0.0
0 0.0
0.5488689547581903
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3782,	 Acc = 0.4981
1049 0.324
4874 0.527
2304 0.528
235 0.396
6 0.0
0 0.0
0 0.0
0 0.0
0.5227119557891899
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4707,	 Acc1 = 0.3868,	 Acc2 = 0.4100

 ===== Epoch 142	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  2.2637317   1.7481282
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.03600958 -0.08018573
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 2 2
train:	 Loss = 1.4106,	 Acc = 0.4729
8219 0.247
16077 0.52
8290 0.585
1067 0.628
185 0.497
18 0.389
0 0.0
0 0.0
0.545383625229161
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4241,	 Acc = 0.4698
1049 0.343
4874 0.511
2304 0.448
235 0.37
6 0.833
0 0.0
0 0.0
0 0.0
0.4876668014557218
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4959,	 Acc1 = 0.3883,	 Acc2 = 0.4118

 ===== Epoch 143	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  2.6521814   2.9732783
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
 -6.8957877e+00 -3.7939093e+00  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
train:	 Loss = 1.4102,	 Acc = 0.4753
8216 0.247
16076 0.524
8293 0.588
1068 0.623
185 0.53
18 0.333
0 0.0
0 0.0
0.5483229329173167
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3777,	 Acc = 0.4949
1049 0.183
4874 0.557
2304 0.514
235 0.434
6 0.0
0 0.0
0 0.0
0 0.0
0.5390214314597654
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4551,	 Acc1 = 0.3724,	 Acc2 = 0.4264

 ===== Epoch 144	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  1.7735816   1.4240848
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
 -2.0951435e-01  1.3930745e-01  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 1 4
train:	 Loss = 1.4101,	 Acc = 0.4757
8217 0.249
16077 0.523
8291 0.588
1068 0.626
185 0.519
18 0.389
0 0.0
0 0.0
0.5483443192012168
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3616,	 Acc = 0.5168
1049 0.344
4874 0.536
2304 0.566
235 0.4
6 0.833
0 0.0
0 0.0
0 0.0
0.541178056341825
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4490,	 Acc1 = 0.4066,	 Acc2 = 0.4339

 ===== Epoch 145	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.8804872e+00  3.7271001e+00  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
  2.8873198e+00  6.3531461e+00] 5 1
train:	 Loss = 1.4102,	 Acc = 0.4735
8216 0.247
16077 0.521
8292 0.585
1068 0.633
185 0.492
18 0.333
0 0.0
0 0.0
0.5459048361934478
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3740,	 Acc = 0.5044
1049 0.344
4874 0.543
2304 0.504
235 0.43
6 0.0
0 0.0
0 0.0
0 0.0
0.5270252055533091
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4575,	 Acc1 = 0.4048,	 Acc2 = 0.4317

 ===== Epoch 146	 =====
[ 2.164799    1.4835482  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   2.0549889   3.3500645  -0.42469367 -0.42124885
  2.2592456   1.6744932 ] [-2.7254679e+00 -2.1757274e+00  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -4.4102764e+00 -6.4902711e+00  2.5347492e-03  4.0676598e-03
  7.3223943e-01  2.1027967e-01] 3 2
train:	 Loss = 1.4104,	 Acc = 0.4736
8216 0.244
16077 0.521
8292 0.588
1068 0.625
185 0.524
18 0.389
0 0.0
0 0.0
0.5472698907956318
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3844,	 Acc = 0.4914
1049 0.348
4874 0.535
2304 0.48
235 0.349
6 0.0
0 0.0
0 0.0
0 0.0
0.5116592532686346
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4744,	 Acc1 = 0.3984,	 Acc2 = 0.4240

 ===== Epoch 147	 =====
[-0.36710912 -0.3811568   1.518372    2.7129269  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  9.5056193e-03  2.0773415e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 5 4
train:	 Loss = 1.4056,	 Acc = 0.4789
8217 0.253
16078 0.526
8291 0.591
1067 0.644
185 0.524
18 0.278
0 0.0
0 0.0
0.5513865595382035
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3786,	 Acc = 0.5072
1049 0.342
4874 0.533
2304 0.54
235 0.379
6 0.833
0 0.0
0 0.0
0 0.0
0.5305297209866559
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4593,	 Acc1 = 0.4054,	 Acc2 = 0.4324

 ===== Epoch 148	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.9387953   1.0326738  -0.40162212 -0.40945497  2.410007    2.3793569
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04 -1.4763887e-01  2.2567488e-01
 -1.2693105e-04  5.0422540e-03 -7.7663017e-03  1.5496786e-01
 -1.5997890e-03 -1.7057455e-03] 6 2
train:	 Loss = 1.4104,	 Acc = 0.4765
8216 0.252
16078 0.523
8293 0.589
1066 0.629
185 0.503
18 0.333
0 0.0
0 0.0
0.5484399375975039
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3789,	 Acc = 0.5046
1049 0.344
4874 0.545
2304 0.502
235 0.413
6 0.333
0 0.0
0 0.0
0 0.0
0.5272947836635665
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4743,	 Acc1 = 0.3945,	 Acc2 = 0.4192

 ===== Epoch 149	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   3.5520792   1.7150588  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 3.3498240e+00  1.6286449e+00  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -9.6845433e-02  6.1894172e-01  2.5347492e-03  4.0676598e-03
  9.4708204e+00  2.7258399e+00] 6 6
train:	 Loss = 1.4095,	 Acc = 0.4741
8219 0.254
16075 0.519
8292 0.585
1068 0.635
185 0.524
17 0.412
0 0.0
0 0.0
0.544798533369739
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3849,	 Acc = 0.5019
1049 0.343
4874 0.543
2304 0.496
235 0.426
6 0.0
0 0.0
0 0.0
0 0.0
0.5243294244507346
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4637,	 Acc1 = 0.4011,	 Acc2 = 0.4272

 ===== Epoch 150	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.0405648   1.0270879  -0.40162212 -0.40945497  1.8445094   3.0893352
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  2.8114449e-02 -8.4192920e-03
 -1.2693105e-04  5.0422540e-03 -1.7814395e-01  7.9517759e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
train:	 Loss = 1.4118,	 Acc = 0.4738
8218 0.248
16078 0.52
8290 0.587
1067 0.632
185 0.503
18 0.389
0 0.0
0 0.0
0.5461814494110305
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3753,	 Acc = 0.4955
1049 0.345
4874 0.531
2304 0.497
235 0.409
6 0.833
0 0.0
0 0.0
0 0.0
0.5167812373635261
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4621,	 Acc1 = 0.3928,	 Acc2 = 0.4172

 ===== Epoch 151	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 2 1
train:	 Loss = 1.4093,	 Acc = 0.4769
8218 0.252
16076 0.525
8292 0.586
1067 0.631
185 0.53
18 0.389
0 0.0
0 0.0
0.5489507761915906
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3747,	 Acc = 0.4930
1049 0.346
4874 0.531
2304 0.487
235 0.417
6 0.833
0 0.0
0 0.0
0 0.0
0.5138158781506942
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4537,	 Acc1 = 0.3969,	 Acc2 = 0.4222

 ===== Epoch 152	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  1.658117    1.2398684
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00105408  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4108,	 Acc = 0.4731
8217 0.248
16080 0.52
8290 0.586
1066 0.623
185 0.492
18 0.389
0 0.0
0 0.0
0.5454190881079606
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3931,	 Acc = 0.4786
1049 0.344
4874 0.528
2304 0.452
235 0.332
6 0.0
0 0.0
0 0.0
0 0.0
0.49764119153524733
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4736,	 Acc1 = 0.3928,	 Acc2 = 0.4172

 ===== Epoch 153	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   2.6980736   3.2705507   3.6237314   1.1657611
  3.6225994   2.938394  ] [1.3208597e-03 2.4159539e-03 3.6177407e-03 2.4021079e-03 1.9079351e-03
 5.4739986e-04 1.4166982e-03 2.7280508e-03 2.3652758e-01 9.9488318e-02
 9.2336047e-01 1.2390017e-01 3.6444330e-01 1.3019630e-01] 2 3
train:	 Loss = 1.4112,	 Acc = 0.4773
8216 0.251
16078 0.526
8292 0.586
1067 0.636
185 0.514
18 0.389
0 0.0
0 0.0
0.5497269890795632
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3828,	 Acc = 0.4868
1049 0.317
4874 0.527
2304 0.485
235 0.417
6 0.833
0 0.0
0 0.0
0 0.0
0.5107157298827335
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4613,	 Acc1 = 0.3957,	 Acc2 = 0.4207

 ===== Epoch 154	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 2 1
train:	 Loss = 1.4084,	 Acc = 0.4761
8216 0.246
16076 0.523
8293 0.593
1068 0.627
185 0.503
18 0.389
0 0.0
0 0.0
0.55
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3760,	 Acc = 0.5061
1049 0.344
4874 0.542
2304 0.517
235 0.374
6 0.833
0 0.0
0 0.0
0 0.0
0.52904704138024
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4512,	 Acc1 = 0.4040,	 Acc2 = 0.4307

 ===== Epoch 155	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  1.4784201   1.5239612
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
 -3.0499369e-01  6.6143066e-02  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 1 1
train:	 Loss = 1.4075,	 Acc = 0.4737
8217 0.251
16079 0.519
8289 0.584
1068 0.638
185 0.514
18 0.333
0 0.0
0 0.0
0.5450680603767698
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3843,	 Acc = 0.4927
1049 0.35
4874 0.53
2304 0.49
235 0.396
6 0.0
0 0.0
0 0.0
0 0.0
0.5128723547647931
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4628,	 Acc1 = 0.3953,	 Acc2 = 0.4202

 ===== Epoch 156	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
  2.4642212e+00  2.3866634e+00] 1 6
train:	 Loss = 1.4075,	 Acc = 0.4774
8218 0.247
16076 0.524
8291 0.594
1068 0.636
185 0.535
18 0.389
0 0.0
0 0.0
0.5514080661518059
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4075,	 Acc = 0.4867
1049 0.338
4874 0.522
2304 0.482
235 0.447
6 0.833
0 0.0
0 0.0
0 0.0
0.5076155816147728
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4853,	 Acc1 = 0.3881,	 Acc2 = 0.4115

 ===== Epoch 157	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.2680414   2.9947364  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4082,	 Acc = 0.4786
8219 0.252
16076 0.523
8292 0.595
1066 0.64
185 0.53
18 0.333
0 0.0
0 0.0
0.5511175254514958
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3744,	 Acc = 0.5113
1049 0.347
4874 0.538
2304 0.542
235 0.387
6 0.833
0 0.0
0 0.0
0 0.0
0.5345733926405176
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4628,	 Acc1 = 0.3949,	 Acc2 = 0.4197

 ===== Epoch 158	 =====
[ 2.9790301   1.8019122  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.9357723   3.335156   -0.42469367 -0.42124885
  2.8685067   1.9917797 ] [-0.02781655 -0.00053546  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805  0.21080448  0.00933526  0.00253475  0.00406766
 -0.00159979 -0.00641653] 0 0
train:	 Loss = 1.4085,	 Acc = 0.4745
8218 0.251
16077 0.518
8290 0.59
1068 0.643
185 0.503
18 0.278
0 0.0
0 0.0
0.5462594586161167
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3736,	 Acc = 0.5152
1049 0.345
4874 0.549
2304 0.539
235 0.362
6 0.0
0 0.0
0 0.0
0 0.0
0.539291009570023
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4599,	 Acc1 = 0.4044,	 Acc2 = 0.4312

 ===== Epoch 159	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  3.278941    1.6862186  -0.40162212 -0.40945497  3.1522944   2.7552278
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  2.0275363e-01 -1.1565955e+00
 -1.2693105e-04  5.0422540e-03 -9.1353858e-01 -9.2352474e-01
 -1.5997890e-03 -1.7057455e-03] 5 5
train:	 Loss = 1.4213,	 Acc = 0.4698
8215 0.237
16078 0.513
8292 0.595
1068 0.629
185 0.535
18 0.278
0 0.0
0 0.0
0.5444795444795445
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3598,	 Acc = 0.5183
1049 0.343
4874 0.541
2304 0.565
235 0.37
6 0.833
0 0.0
0 0.0
0 0.0
0.5430651031136272
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4532,	 Acc1 = 0.4015,	 Acc2 = 0.4277

 ===== Epoch 160	 =====
[ 1.830447    1.3824801  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [-2.3653808e+00 -2.0576711e+00  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 0 1
train:	 Loss = 1.4110,	 Acc = 0.4755
8214 0.252
16078 0.52
8294 0.593
1067 0.617
185 0.486
18 0.333
0 0.0
0 0.0
0.5469932142578582
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3541,	 Acc = 0.5099
1049 0.343
4874 0.549
2304 0.514
235 0.4
6 0.833
0 0.0
0 0.0
0 0.0
0.5334950801994878
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4545,	 Acc1 = 0.3959,	 Acc2 = 0.4210

 ===== Epoch 161	 =====
[ 1.9253691   3.1991775  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  1.8036209   3.5703447 ] [-2.4676092e+00 -4.1797376e+00  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -4.3696136e+00 -7.1008615e+00] 1 1
train:	 Loss = 1.4100,	 Acc = 0.4750
8219 0.248
16075 0.521
8291 0.589
1068 0.634
185 0.514
18 0.333
0 0.0
0 0.0
0.5476849865428872
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4273,	 Acc = 0.4731
1049 0.344
4874 0.514
2304 0.45
235 0.421
6 0.833
0 0.0
0 0.0
0 0.0
0.4913061059441973
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4930,	 Acc1 = 0.3918,	 Acc2 = 0.4160

 ===== Epoch 162	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7940648   1.633153   -0.40162212 -0.40945497  2.6177711   3.3178058
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  8.3679771e-01  6.9612101e-02
 -1.2693105e-04  5.0422540e-03 -1.2352694e+00 -3.1438269e-02
 -1.5997890e-03 -1.7057455e-03] 2 2
train:	 Loss = 1.4082,	 Acc = 0.4753
8216 0.253
16076 0.519
8293 0.591
1068 0.627
185 0.514
18 0.333
0 0.0
0 0.0
0.5465678627145086
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3997,	 Acc = 0.4944
1049 0.355
4874 0.535
2304 0.477
235 0.426
6 0.833
0 0.0
0 0.0
0 0.0
0.5142202453160803
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4680,	 Acc1 = 0.3934,	 Acc2 = 0.4180

 ===== Epoch 163	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.2253705   3.187602
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03 -3.4589562e+00 -6.5157080e+00
 -1.5997890e-03 -1.7057455e-03] 6 1
train:	 Loss = 1.4082,	 Acc = 0.4741
8219 0.244
16077 0.522
8289 0.589
1068 0.621
185 0.546
18 0.333
0 0.0
0 0.0
0.5479970355345789
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3750,	 Acc = 0.5068
1049 0.344
4874 0.54
2304 0.52
235 0.4
6 0.833
0 0.0
0 0.0
0 0.0
0.5298557757110123
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4605,	 Acc1 = 0.4025,	 Acc2 = 0.4289

 ===== Epoch 164	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  1.3641033   1.5461559
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211 -0.05009576  0.04091397
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 1 4
train:	 Loss = 1.4097,	 Acc = 0.4766
8218 0.248
16072 0.523
8295 0.591
1068 0.635
185 0.535
18 0.389
0 0.0
0 0.0
0.5497308682424527
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3911,	 Acc = 0.4906
1049 0.256
4874 0.525
2304 0.538
235 0.374
6 0.0
0 0.0
0 0.0
0 0.0
0.523655479175091
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4837,	 Acc1 = 0.3571,	 Acc2 = 0.4143

 ===== Epoch 165	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  1.4013851   1.2728655  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04 -3.0329272e-03 -4.4316563e-01
 -1.2693105e-04  5.0422540e-03  4.4205117e+00  6.6259227e+00
 -1.5997890e-03 -1.7057455e-03] 1 5
train:	 Loss = 1.4072,	 Acc = 0.4745
8217 0.247
16077 0.522
8291 0.586
1068 0.63
185 0.551
18 0.389
0 0.0
0 0.0
0.5475252544951051
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4255,	 Acc = 0.4636
1049 0.343
4874 0.503
2304 0.441
235 0.396
6 0.833
0 0.0
0 0.0
0 0.0
0.48065777058902814
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4956,	 Acc1 = 0.3920,	 Acc2 = 0.4163

 ===== Epoch 166	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  1.6577342   1.2398684
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4133,	 Acc = 0.4698
8216 0.241
16077 0.516
8292 0.585
1068 0.634
185 0.541
18 0.389
0 0.0
0 0.0
0.5429797191887675
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4025,	 Acc = 0.4857
1049 0.341
4874 0.514
2304 0.49
235 0.489
6 0.833
0 0.0
0 0.0
0 0.0
0.5061329020083569
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4799,	 Acc1 = 0.3932,	 Acc2 = 0.4177

 ===== Epoch 167	 =====
[-0.36710912 -0.3811568   1.2082398   0.8987085  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -7.4620321e-02  1.4662343e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
train:	 Loss = 1.4084,	 Acc = 0.4753
8218 0.249
16076 0.523
8291 0.587
1068 0.633
185 0.508
18 0.333
0 0.0
0 0.0
0.54793665652547
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3944,	 Acc = 0.4864
1049 0.316
4874 0.528
2304 0.485
235 0.417
6 0.0
0 0.0
0 0.0
0 0.0
0.5105809408276047
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4698,	 Acc1 = 0.4064,	 Acc2 = 0.4336

 ===== Epoch 168	 =====
[ 1.7256695   3.4518478  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [-2.2525387e+00 -4.4748788e+00  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 1 1
train:	 Loss = 1.4103,	 Acc = 0.4761
8215 0.25
16078 0.521
8294 0.592
1066 0.639
185 0.508
18 0.389
0 0.0
0 0.0
0.5487305487305487
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3782,	 Acc = 0.4998
1049 0.349
4874 0.534
2304 0.502
235 0.426
6 0.833
0 0.0
0 0.0
0 0.0
0.5210944871276453
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4659,	 Acc1 = 0.4009,	 Acc2 = 0.4269

 ===== Epoch 169	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  1.6386179   1.2398684
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.05050146 -0.03477334
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 2 3
train:	 Loss = 1.4081,	 Acc = 0.4775
8218 0.251
16077 0.523
8290 0.591
1068 0.644
185 0.508
18 0.389
0 0.0
0 0.0
0.5500039004602543
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3743,	 Acc = 0.5085
1049 0.348
4874 0.546
2304 0.514
235 0.417
6 0.0
0 0.0
0 0.0
0 0.0
0.5312036662622995
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4512,	 Acc1 = 0.4151,	 Acc2 = 0.4441

 ===== Epoch 170	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 3 1
train:	 Loss = 1.4070,	 Acc = 0.4765
8217 0.25
16078 0.526
8291 0.585
1067 0.628
185 0.508
18 0.389
0 0.0
0 0.0
0.5490463746635984
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3969,	 Acc = 0.4773
1049 0.343
4874 0.518
2304 0.461
235 0.4
6 0.0
0 0.0
0 0.0
0 0.0
0.49629330098396013
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4858,	 Acc1 = 0.3903,	 Acc2 = 0.4143

 ===== Epoch 171	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.1290435   3.1237285
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03 -3.2568820e+00 -6.4003139e+00
 -1.5997890e-03 -1.7057455e-03] 6 1
train:	 Loss = 1.4067,	 Acc = 0.4753
8217 0.253
16077 0.52
8291 0.587
1068 0.643
185 0.519
18 0.333
0 0.0
0 0.0
0.5467061897889933
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3798,	 Acc = 0.5087
1049 0.347
4874 0.537
2304 0.536
235 0.37
6 0.833
0 0.0
0 0.0
0 0.0
0.5316080334276857
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4612,	 Acc1 = 0.4099,	 Acc2 = 0.4379

 ===== Epoch 172	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 1
train:	 Loss = 1.4082,	 Acc = 0.4766
8219 0.254
16076 0.52
8291 0.59
1067 0.64
185 0.535
18 0.333
0 0.0
0 0.0
0.5479580294106174
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3621,	 Acc = 0.5152
1049 0.344
4874 0.54
2304 0.553
235 0.387
6 0.833
0 0.0
0 0.0
0 0.0
0.5394257986251516
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4514,	 Acc1 = 0.4077,	 Acc2 = 0.4351

 ===== Epoch 173	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 1
train:	 Loss = 1.4075,	 Acc = 0.4760
8219 0.253
16076 0.52
8291 0.591
1068 0.638
185 0.503
17 0.412
0 0.0
0 0.0
0.5476459804189258
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4069,	 Acc = 0.4608
1049 0.335
4874 0.502
2304 0.438
235 0.37
6 0.833
0 0.0
0 0.0
0 0.0
0.4786359347620973
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4842,	 Acc1 = 0.3891,	 Acc2 = 0.4128

 ===== Epoch 174	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.3318971   1.0773209
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03 -3.6824267e+00 -2.7032595e+00
 -1.5997890e-03 -1.7057455e-03] 5 1
train:	 Loss = 1.4082,	 Acc = 0.4750
8215 0.251
16079 0.519
8291 0.588
1068 0.641
185 0.535
18 0.389
0 0.0
0 0.0
0.5467025467025467
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3835,	 Acc = 0.4861
1049 0.347
4874 0.53
2304 0.468
235 0.366
6 0.833
0 0.0
0 0.0
0 0.0
0.5057285348429708
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4628,	 Acc1 = 0.4062,	 Acc2 = 0.4334

 ===== Epoch 175	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 1 1
train:	 Loss = 1.4092,	 Acc = 0.4728
8215 0.248
16079 0.519
8293 0.585
1066 0.638
185 0.503
18 0.389
0 0.0
0 0.0
0.5449475449475449
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3948,	 Acc = 0.4900
1049 0.339
4874 0.519
2304 0.508
235 0.4
6 0.0
0 0.0
0 0.0
0 0.0
0.5112548861032484
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4717,	 Acc1 = 0.3906,	 Acc2 = 0.4145

 ===== Epoch 176	 =====
[ 1.3713146   1.0514823  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  1.6068429   1.2837852 ] [ 3.5293419e-02  3.1930089e-02  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -2.4562763e-01  2.6558977e-02] 1 3
train:	 Loss = 1.4093,	 Acc = 0.4778
8217 0.252
16078 0.524
8291 0.592
1067 0.629
185 0.524
18 0.333
0 0.0
0 0.0
0.5501774640196575
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3624,	 Acc = 0.5237
1049 0.346
4874 0.543
2304 0.573
235 0.426
6 0.833
0 0.0
0 0.0
0 0.0
0.5488610324841623
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4607,	 Acc1 = 0.3998,	 Acc2 = 0.4257

 ===== Epoch 177	 =====
[ 0.54775035  2.233978   -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  0.56748945  2.5162199 ] [ 1.67782366e-01  9.39097852e-02  3.61774070e-03  2.40210793e-03
  1.90793513e-03  5.47399861e-04  1.41669821e-03  2.72805081e-03
 -1.26931045e-04  5.04225399e-03  2.53474922e-03  4.06765984e-03
  1.13392785e-01  3.12697664e-02] 2 4
train:	 Loss = 1.4085,	 Acc = 0.4752
8215 0.247
16076 0.52
8294 0.592
1068 0.635
185 0.503
18 0.333
0 0.0
0 0.0
0.5482235482235482
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3884,	 Acc = 0.4924
1049 0.347
4874 0.531
2304 0.482
235 0.443
6 0.833
0 0.0
0 0.0
0 0.0
0.5130071438199219
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4729,	 Acc1 = 0.3926,	 Acc2 = 0.4170

 ===== Epoch 178	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  1.6760868   2.4317265
 -0.3641531  -0.3721681   0.77512527  0.84288996 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  8.4600478e-02  1.8471983e-01  1.4166982e-03  2.7280508e-03
 -2.1126437e+00 -2.1586313e+00  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 1 4
train:	 Loss = 1.4079,	 Acc = 0.4764
8216 0.251
16078 0.522
8291 0.59
1068 0.64
185 0.497
18 0.333
0 0.0
0 0.0
0.5486349453978159
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3929,	 Acc = 0.4895
1049 0.341
4874 0.529
2304 0.484
235 0.374
6 0.833
0 0.0
0 0.0
0 0.0
0.5104461517724761
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4667,	 Acc1 = 0.4077,	 Acc2 = 0.4351

 ===== Epoch 179	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  2.0958884   1.4773521
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.2892997e-01 -3.8545784e-01  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 5 5
train:	 Loss = 1.4082,	 Acc = 0.4722
8219 0.241
16078 0.518
8289 0.589
1068 0.638
184 0.56
18 0.333
0 0.0
0 0.0
0.5461637477083903
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3680,	 Acc = 0.5021
1049 0.317
4874 0.531
2304 0.528
235 0.464
6 0.833
0 0.0
0 0.0
0 0.0
0.5282383070494676
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4531,	 Acc1 = 0.4021,	 Acc2 = 0.4284

 ===== Epoch 180	 =====
[-0.36710912 -0.3811568   3.1019967   2.542844   -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  1.6177909e-01 -7.6462164e+00
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 2 1
train:	 Loss = 1.4087,	 Acc = 0.4742
8219 0.248
16074 0.519
8292 0.587
1068 0.649
185 0.514
18 0.389
0 0.0
0 0.0
0.5465148028240434
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4432,	 Acc = 0.4695
1049 0.343
4874 0.5
2304 0.47
235 0.396
6 0.833
0 0.0
0 0.0
0 0.0
0.48739722334546437
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.5197,	 Acc1 = 0.3924,	 Acc2 = 0.4167

 ===== Epoch 181	 =====
[ 2.071259    2.1303835  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  2.3314416   2.3457768 ] [ 2.0564662e-01  1.1161827e-01  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -2.2105090e-01  1.9614731e-01] 4 2
train:	 Loss = 1.4057,	 Acc = 0.4772
8219 0.254
16074 0.522
8292 0.591
1068 0.634
185 0.535
18 0.389
0 0.0
0 0.0
0.5486601396419237
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3656,	 Acc = 0.5081
1049 0.343
4874 0.546
2304 0.513
235 0.413
6 0.833
0 0.0
0 0.0
0 0.0
0.5314732443725569
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4570,	 Acc1 = 0.4056,	 Acc2 = 0.4327

 ===== Epoch 182	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  1.2796084   1.0179209
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  2.8749472e-01  1.0639041e-02  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 2 0
train:	 Loss = 1.4083,	 Acc = 0.4781
8217 0.249
16076 0.524
8292 0.596
1068 0.628
185 0.541
18 0.278
0 0.0
0 0.0
0.551425562619447
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3944,	 Acc = 0.4763
1049 0.346
4874 0.505
2304 0.482
235 0.396
6 0.833
0 0.0
0 0.0
0 0.0
0.4946758323224154
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4831,	 Acc1 = 0.3889,	 Acc2 = 0.4125

 ===== Epoch 183	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   3.3314135   1.4541535  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4079,	 Acc = 0.4773
8218 0.252
16080 0.522
8287 0.592
1068 0.631
185 0.508
18 0.278
0 0.0
0 0.0
0.5493018176144785
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4184,	 Acc = 0.4870
1049 0.352
4874 0.536
2304 0.455
235 0.383
6 0.833
0 0.0
0 0.0
0 0.0
0.5061329020083569
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.5020,	 Acc1 = 0.3957,	 Acc2 = 0.4207

 ===== Epoch 184	 =====
[ 0.8436326   2.7595317  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.6358432e-01  7.9152711e-02  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 0 4
train:	 Loss = 1.4223,	 Acc = 0.4696
8217 0.253
16076 0.509
8292 0.587
1068 0.632
185 0.476
18 0.333
0 0.0
0 0.0
0.5389055735403097
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4158,	 Acc = 0.4805
1049 0.344
4874 0.518
2304 0.472
235 0.379
6 0.833
0 0.0
0 0.0
0 0.0
0.4997978164173069
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.5013,	 Acc1 = 0.3802,	 Acc2 = 0.4021

 ===== Epoch 185	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  1.342254    3.1050253  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04 -6.1988741e-02  3.7616399e-01
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
train:	 Loss = 1.4155,	 Acc = 0.4723
8214 0.245
16079 0.518
8292 0.586
1068 0.641
185 0.508
18 0.333
0 0.0
0 0.0
0.5450042898369862
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3990,	 Acc = 0.4845
1049 0.305
4874 0.528
2304 0.48
235 0.409
6 0.833
0 0.0
0 0.0
0 0.0
0.5099069955519612
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4782,	 Acc1 = 0.4019,	 Acc2 = 0.4282

 ===== Epoch 186	 =====
[-0.36710912 -0.3811568   0.5517544   1.5178107  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00445775 -0.02937547  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 2
train:	 Loss = 1.4077,	 Acc = 0.4750
8218 0.25
16076 0.519
8291 0.592
1068 0.627
185 0.503
18 0.333
0 0.0
0 0.0
0.5471955690771511
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4092,	 Acc = 0.4776
1049 0.343
4874 0.517
2304 0.463
235 0.4
6 0.833
0 0.0
0 0.0
0 0.0
0.49656287909421754
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4818,	 Acc1 = 0.3974,	 Acc2 = 0.4227

 ===== Epoch 187	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 1
train:	 Loss = 1.4086,	 Acc = 0.4753
8213 0.247
16079 0.522
8294 0.589
1067 0.639
185 0.551
18 0.333
0 0.0
0 0.0
0.5484927660570136
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3892,	 Acc = 0.4968
1049 0.343
4874 0.535
2304 0.494
235 0.409
6 0.833
0 0.0
0 0.0
0 0.0
0.5185334950801995
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4708,	 Acc1 = 0.4013,	 Acc2 = 0.4274

 ===== Epoch 188	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.3872582   2.9326162  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00933526  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4100,	 Acc = 0.4758
8218 0.251
16077 0.521
8292 0.588
1066 0.654
185 0.503
18 0.389
0 0.0
0 0.0
0.5477806381152976
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3985,	 Acc = 0.5085
1049 0.346
4874 0.53
2304 0.547
235 0.417
6 0.0
0 0.0
0 0.0
0 0.0
0.5314732443725569
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4904,	 Acc1 = 0.3936,	 Acc2 = 0.4182

 ===== Epoch 189	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 3 1
train:	 Loss = 1.4096,	 Acc = 0.4766
8218 0.253
16073 0.521
8295 0.591
1067 0.629
185 0.508
18 0.333
0 0.0
0 0.0
0.548326702550901
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3722,	 Acc = 0.5092
1049 0.341
4874 0.53
2304 0.553
235 0.391
6 0.833
0 0.0
0 0.0
0 0.0
0.532955923978973
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4593,	 Acc1 = 0.3963,	 Acc2 = 0.4215

 ===== Epoch 190	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.4465992   1.5158501  -0.40162212 -0.40945497  2.5569532   2.7601411
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04 -4.3079555e-02  3.0927995e-01
 -1.2693105e-04  5.0422540e-03  6.7515880e-02  1.7272080e-01
 -1.5997890e-03 -1.7057455e-03] 3 2
train:	 Loss = 1.4068,	 Acc = 0.4766
8218 0.255
16077 0.519
8290 0.593
1068 0.636
185 0.514
18 0.222
0 0.0
0 0.0
0.5476246197051252
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3781,	 Acc = 0.5170
1049 0.344
4874 0.543
2304 0.549
235 0.438
6 0.833
0 0.0
0 0.0
0 0.0
0.5414476344520824
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4613,	 Acc1 = 0.4042,	 Acc2 = 0.4309

 ===== Epoch 191	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 1
train:	 Loss = 1.4080,	 Acc = 0.4763
8220 0.25
16077 0.519
8288 0.595
1068 0.64
185 0.524
18 0.333
0 0.0
0 0.0
0.5488765798096427
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3999,	 Acc = 0.4845
1049 0.349
4874 0.534
2304 0.453
235 0.391
6 0.0
0 0.0
0 0.0
0 0.0
0.5037066990160399
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4890,	 Acc1 = 0.3908,	 Acc2 = 0.4148

 ===== Epoch 192	 =====
[ 3.3333035   1.6300967  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   2.625282    3.317762   -0.42469367 -0.42124885
  3.1894245   2.049468  ] [-3.9839122e+00 -2.3469095e+00  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
  3.4868568e-01 -3.4269097e-01  2.5347492e-03  4.0676598e-03
 -1.6048150e-01 -3.7856868e-01] 5 5
train:	 Loss = 1.4071,	 Acc = 0.4755
8218 0.254
16077 0.517
8290 0.595
1068 0.633
185 0.514
18 0.278
0 0.0
0 0.0
0.5466105000390046
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4071,	 Acc = 0.4767
1049 0.345
4874 0.529
2304 0.438
235 0.362
6 0.833
0 0.0
0 0.0
0 0.0
0.49534977759805904
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4841,	 Acc1 = 0.3943,	 Acc2 = 0.4190

 ===== Epoch 193	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 3 1
train:	 Loss = 1.4058,	 Acc = 0.4764
8218 0.251
16074 0.524
8293 0.587
1068 0.634
185 0.524
18 0.222
0 0.0
0 0.0
0.548716748576332
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3880,	 Acc = 0.4799
1049 0.343
4874 0.526
2304 0.453
235 0.383
6 0.833
0 0.0
0 0.0
0 0.0
0.49925866019679205
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4699,	 Acc1 = 0.3969,	 Acc2 = 0.4222

 ===== Epoch 194	 =====
[-0.36710912 -0.3811568   1.5904105   2.6426258  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  1.8761346e-02  2.4928947e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 2 4
train:	 Loss = 1.4053,	 Acc = 0.4760
8218 0.252
16077 0.517
8290 0.596
1068 0.641
185 0.557
18 0.333
0 0.0
0 0.0
0.5477416335127545
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3745,	 Acc = 0.5035
1049 0.344
4874 0.53
2304 0.525
235 0.443
6 0.833
0 0.0
0 0.0
0 0.0
0.526081682167408
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4676,	 Acc1 = 0.3969,	 Acc2 = 0.4222

 ===== Epoch 195	 =====
[-0.36710912 -0.3811568   1.8797855   0.823872   -0.44130662 -0.36481208
  5.055126    2.052092   -0.40162212 -0.40945497  4.4581895   2.0992966
  4.8965883  -4.692211  ] [ 1.3208597e-03  2.4159539e-03  6.5029569e-02  2.1506743e-01
  1.9079351e-03  5.4739986e-04 -9.7300994e-01  4.6534270e-01
 -1.2693105e-04  5.0422540e-03 -1.4106165e-02  3.1030628e-01
 -1.0537033e+01  7.7428288e+00] 4 4
train:	 Loss = 1.4061,	 Acc = 0.4735
8216 0.244
16077 0.52
8293 0.587
1067 0.641
185 0.53
18 0.389
0 0.0
0 0.0
0.5471138845553822
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4058,	 Acc = 0.4855
1049 0.346
4874 0.509
2304 0.505
235 0.421
6 0.833
0 0.0
0 0.0
0 0.0
0.5051893786224558
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4861,	 Acc1 = 0.4019,	 Acc2 = 0.4282

 ===== Epoch 196	 =====
[-0.36710912 -0.3811568   1.0804437   1.5472916  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4067,	 Acc = 0.4751
8215 0.249
16077 0.519
8295 0.591
1067 0.643
184 0.549
18 0.333
0 0.0
0 0.0
0.5476385476385477
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4108,	 Acc = 0.4647
1049 0.349
4874 0.514
2304 0.425
235 0.332
6 0.833
0 0.0
0 0.0
0 0.0
0.48106213775441437
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.5002,	 Acc1 = 0.3928,	 Acc2 = 0.4172

 ===== Epoch 197	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  2.3616548   1.0724076
  2.5779629   3.5572336 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.7100489e-02  3.0697105e-02
 -3.7729773e-01 -1.5838107e-02] 2 2
train:	 Loss = 1.4099,	 Acc = 0.4755
8216 0.25
16078 0.518
8292 0.592
1067 0.646
185 0.562
18 0.333
0 0.0
0 0.0
0.5476989079563183
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4154,	 Acc = 0.5044
1049 0.36
4874 0.525
2304 0.537
235 0.383
6 0.833
0 0.0
0 0.0
0 0.0
0.5247337916161208
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4901,	 Acc1 = 0.4058,	 Acc2 = 0.4329

 ===== Epoch 198	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.4440895   1.4458216
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  1.1189492e-01  9.4053644e-01
 -1.5997890e-03 -1.7057455e-03] 6 6
train:	 Loss = 1.4084,	 Acc = 0.4752
8216 0.249
16079 0.519
8290 0.591
1068 0.642
185 0.508
18 0.444
0 0.0
0 0.0
0.5475039001560063
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4183,	 Acc = 0.4617
1049 0.347
4874 0.505
2304 0.433
235 0.34
6 0.833
0 0.0
0 0.0
0 0.0
0.4779619894864537
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.5031,	 Acc1 = 0.3903,	 Acc2 = 0.4143

 ===== Epoch 199	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.7024738   2.5414972
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.7830648e-01 -2.0452964e-01
 -1.5997890e-03 -1.7057455e-03] 5 5
train:	 Loss = 1.4073,	 Acc = 0.4761
8217 0.248
16078 0.523
8290 0.59
1068 0.64
185 0.519
18 0.333
0 0.0
0 0.0
0.5493583993135458
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3669,	 Acc = 0.5123
1049 0.32
4874 0.534
2304 0.561
235 0.434
6 0.833
0 0.0
0 0.0
0 0.0
0.5394257986251516
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4526,	 Acc1 = 0.4126,	 Acc2 = 0.4411

 ===== Epoch 200	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.1081314   2.6095908  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805  0.18199597  0.24115743  0.00253475  0.00406766
 -0.00159979 -0.00170575] 1 4
train:	 Loss = 1.4088,	 Acc = 0.4742
8218 0.249
16077 0.521
8291 0.586
1068 0.621
184 0.522
18 0.333
0 0.0
0 0.0
0.5462984632186598
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4047,	 Acc = 0.4859
1049 0.319
4874 0.51
2304 0.516
235 0.43
6 0.833
0 0.0
0 0.0
0 0.0
0.509502628386575
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4919,	 Acc1 = 0.3864,	 Acc2 = 0.4095

 ===== Epoch 201	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.8652732   1.5634853  -0.42469367 -0.42124885
  3.6468117   1.8842694 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -5.2603722e-02 -9.7805548e-01  2.5347492e-03  4.0676598e-03
 -3.7817693e-01 -1.0851868e+00] 5 5
train:	 Loss = 1.4085,	 Acc = 0.4742
8219 0.248
16077 0.518
8291 0.589
1066 0.656
185 0.524
18 0.333
0 0.0
0 0.0
0.5465538089480049
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3818,	 Acc = 0.4928
1049 0.347
4874 0.533
2304 0.485
235 0.379
6 0.833
0 0.0
0 0.0
0 0.0
0.513411510985308
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4640,	 Acc1 = 0.4011,	 Acc2 = 0.4272

 ===== Epoch 202	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.5079308   1.7897557
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.07623197 -0.12464131
 -0.00159979 -0.00170575] 2 3
train:	 Loss = 1.4075,	 Acc = 0.4756
8217 0.251
16078 0.519
8290 0.59
1068 0.648
185 0.541
18 0.389
0 0.0
0 0.0
0.5475252544951051
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3779,	 Acc = 0.5146
1049 0.344
4874 0.531
2304 0.568
235 0.4
6 0.833
0 0.0
0 0.0
0 0.0
0.538751853349508
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4695,	 Acc1 = 0.3945,	 Acc2 = 0.4192

 ===== Epoch 203	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  2.432672    1.0429275
  2.399675    3.4811897 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  3.3060792e-01  1.7715906e-01
  7.2434026e-01  7.7158287e-03] 2 2
train:	 Loss = 1.4091,	 Acc = 0.4739
8214 0.247
16078 0.519
8294 0.589
1067 0.636
185 0.535
18 0.278
0 0.0
0 0.0
0.5466422275953514
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.3977,	 Acc = 0.4817
1049 0.344
4874 0.528
2304 0.458
235 0.357
6 0.833
0 0.0
0 0.0
0 0.0
0.5011457069685942
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4766,	 Acc1 = 0.4064,	 Acc2 = 0.4336

 ===== Epoch 204	 =====
[ 2.4524286   0.9706279  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  1.8172675   1.1788973 ] [-1.0302485e+00 -1.2341115e-02  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
  9.1445506e-02 -2.9970469e-02] 1 1
train:	 Loss = 1.4077,	 Acc = 0.4743
8217 0.253
16077 0.516
8292 0.588
1067 0.648
185 0.535
18 0.333
0 0.0
0 0.0
0.5450680603767698
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3944,	 Acc = 0.4861
1049 0.348
4874 0.53
2304 0.464
235 0.391
6 0.833
0 0.0
0 0.0
0 0.0
0.505593745787842
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4749,	 Acc1 = 0.4000,	 Acc2 = 0.4259

 ===== Epoch 205	 =====
[ 2.448134    1.5366088  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  1.9783871   1.7479148 ] [-6.2864560e-01  7.3731798e-01  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -2.3334062e-01  1.1854125e+00] 6 6
train:	 Loss = 1.4077,	 Acc = 0.4750
8219 0.251
16075 0.517
8291 0.593
1068 0.631
185 0.557
18 0.278
0 0.0
0 0.0
0.5466708273198893
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3919,	 Acc = 0.4952
1049 0.256
4874 0.539
2304 0.521
235 0.409
6 0.0
0 0.0
0 0.0
0 0.0
0.5289122523251112
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4660,	 Acc1 = 0.3743,	 Acc2 = 0.4349

 ===== Epoch 206	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  1.0907351   1.8147124
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
 -2.8538656e-01  2.5776500e-02  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 1 1
train:	 Loss = 1.4081,	 Acc = 0.4735
8217 0.246
16075 0.521
8293 0.587
1068 0.623
185 0.53
18 0.278
0 0.0
0 0.0
0.5462381528140723
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3964,	 Acc = 0.4862
1049 0.344
4874 0.515
2304 0.498
235 0.4
6 0.833
0 0.0
0 0.0
0 0.0
0.5062676910634857
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4862,	 Acc1 = 0.3778,	 Acc2 = 0.3991

 ===== Epoch 207	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.5381514   2.9517615
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.08177812  0.04845006
 -0.00159979 -0.00170575] 4 3
train:	 Loss = 1.4091,	 Acc = 0.4772
8218 0.254
16078 0.524
8289 0.587
1068 0.644
185 0.519
18 0.389
0 0.0
0 0.0
0.5489117715890475
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3970,	 Acc = 0.4993
1049 0.344
4874 0.522
2304 0.534
235 0.374
6 0.833
0 0.0
0 0.0
0 0.0
0.5212292761827739
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4832,	 Acc1 = 0.3990,	 Acc2 = 0.4247

 ===== Epoch 208	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.2680414   2.9947364  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4140,	 Acc = 0.4742
8216 0.251
16077 0.519
8292 0.587
1068 0.626
185 0.573
18 0.333
0 0.0
0 0.0
0.5455928237129485
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3915,	 Acc = 0.4789
1049 0.346
4874 0.53
2304 0.439
235 0.396
6 0.833
0 0.0
0 0.0
0 0.0
0.49764119153524733
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4804,	 Acc1 = 0.3870,	 Acc2 = 0.4103

 ===== Epoch 209	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 1 1
train:	 Loss = 1.4059,	 Acc = 0.4773
8217 0.254
16075 0.521
8294 0.591
1067 0.648
185 0.524
18 0.389
0 0.0
0 0.0
0.5487343500136511
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4012,	 Acc = 0.4786
1049 0.346
4874 0.52
2304 0.46
235 0.391
6 0.833
0 0.0
0 0.0
0 0.0
0.49737161342498987
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4803,	 Acc1 = 0.3866,	 Acc2 = 0.4098

 ===== Epoch 210	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  4.840565    1.7727994   5.05089     3.2904289   5.3765097   1.8781959
  5.6726923  -4.9203424 ] [ 1.3208597e-03  2.4159539e-03  4.7577453e+00  1.2515054e+00
  1.9079351e-03  5.4739986e-04  4.2522460e-01  5.6009513e-01
 -9.7885685e+00 -6.3872390e+00 -1.9239087e+00  4.0350935e-01
 -1.5491626e+00  4.0813273e-01] 4 4
train:	 Loss = 1.4083,	 Acc = 0.4745
8216 0.25
16077 0.518
8293 0.59
1067 0.64
185 0.541
18 0.333
0 0.0
0 0.0
0.5464118564742589
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3893,	 Acc = 0.5083
1049 0.346
4874 0.541
2304 0.521
235 0.409
6 0.833
0 0.0
0 0.0
0 0.0
0.5312036662622995
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4646,	 Acc1 = 0.3990,	 Acc2 = 0.4247

 ===== Epoch 211	 =====
[ 1.0422546   2.292092   -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  0.84262544  2.521464  ] [-2.0278919e-01  1.5588948e-01  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
  1.5815841e-01  2.6209834e-01] 5 6
train:	 Loss = 1.4093,	 Acc = 0.4731
8218 0.25
16079 0.517
8289 0.589
1067 0.628
185 0.508
18 0.333
0 0.0
0 0.0
0.5446212653093065
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3930,	 Acc = 0.4880
1049 0.344
4874 0.532
2304 0.467
235 0.417
6 0.833
0 0.0
0 0.0
0 0.0
0.5082895268904165
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4767,	 Acc1 = 0.3978,	 Acc2 = 0.4232

 ===== Epoch 212	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.3043205   2.057533
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225 -0.01886106 -0.08913539
 -0.00159979 -0.00170575] 3 3
train:	 Loss = 1.4082,	 Acc = 0.4744
8216 0.248
16078 0.519
8291 0.589
1068 0.644
185 0.557
18 0.333
0 0.0
0 0.0
0.5468408736349454
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3921,	 Acc = 0.4897
1049 0.349
4874 0.522
2304 0.494
235 0.387
6 0.833
0 0.0
0 0.0
0 0.0
0.5096374174417038
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4795,	 Acc1 = 0.3961,	 Acc2 = 0.4212

 ===== Epoch 213	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  2.1912873   1.720969
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.6309231e-02  1.4165312e-01
 -1.5997890e-03 -1.7057455e-03] 3 2
train:	 Loss = 1.4073,	 Acc = 0.4747
8217 0.251
16077 0.522
8292 0.585
1068 0.623
184 0.478
18 0.278
0 0.0
0 0.0
0.5462381528140723
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3967,	 Acc = 0.4744
1049 0.344
4874 0.523
2304 0.441
235 0.37
6 0.833
0 0.0
0 0.0
0 0.0
0.4927887855506133
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4825,	 Acc1 = 0.3959,	 Acc2 = 0.4210

 ===== Epoch 214	 =====
[-0.36710912 -0.3811568   2.221256    1.6674837  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -2.8157511e-01 -4.1597616e-02
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 2 1
train:	 Loss = 1.4071,	 Acc = 0.4748
8218 0.25
16075 0.519
8292 0.589
1068 0.647
185 0.546
18 0.333
0 0.0
0 0.0
0.5470005460644356
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3670,	 Acc = 0.5136
1049 0.346
4874 0.538
2304 0.546
235 0.43
6 0.833
0 0.0
0 0.0
0 0.0
0.537269173743092
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4562,	 Acc1 = 0.3969,	 Acc2 = 0.4222

 ===== Epoch 215	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 1 1
train:	 Loss = 1.4054,	 Acc = 0.4746
8216 0.25
16079 0.518
8290 0.589
1068 0.66
185 0.508
18 0.333
0 0.0
0 0.0
0.5466848673946958
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3762,	 Acc = 0.4883
1049 0.344
4874 0.53
2304 0.474
235 0.396
6 0.833
0 0.0
0 0.0
0 0.0
0.5086938940558027
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4664,	 Acc1 = 0.3988,	 Acc2 = 0.4245

 ===== Epoch 216	 =====
[ 1.9416528   2.8732333  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  2.022408    3.132437  ] [ 3.3483639e-01  1.6769513e-01  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.4906827e-01  3.1391701e-01] 4 4
train:	 Loss = 1.4044,	 Acc = 0.4730
8215 0.244
16079 0.521
8292 0.587
1067 0.631
185 0.492
18 0.278
0 0.0
0 0.0
0.5463125463125463
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3860,	 Acc = 0.4906
1049 0.307
4874 0.52
2304 0.519
235 0.409
6 0.833
0 0.0
0 0.0
0 0.0
0.5165116592532686
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4641,	 Acc1 = 0.4108,	 Acc2 = 0.4389

 ===== Epoch 217	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  1.7127912   1.9789536
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.01384088 -0.00702133
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4088,	 Acc = 0.4728
8218 0.248
16076 0.517
8292 0.588
1067 0.64
185 0.492
18 0.333
0 0.0
0 0.0
0.5446992745143927
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3863,	 Acc = 0.4841
1049 0.348
4874 0.523
2304 0.474
235 0.387
6 0.833
0 0.0
0 0.0
0 0.0
0.5033023318506538
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4786,	 Acc1 = 0.3852,	 Acc2 = 0.4081

 ===== Epoch 218	 =====
[-0.36710912 -0.3811568   1.6604143   2.8149767  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4049,	 Acc = 0.4765
8215 0.254
16076 0.52
8294 0.59
1068 0.653
185 0.514
18 0.333
0 0.0
0 0.0
0.5477945477945478
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3720,	 Acc = 0.4979
1049 0.346
4874 0.533
2304 0.498
235 0.438
6 0.833
0 0.0
0 0.0
0 0.0
0.5193422294109719
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4537,	 Acc1 = 0.4000,	 Acc2 = 0.4259

 ===== Epoch 219	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 6 1
train:	 Loss = 1.4053,	 Acc = 0.4750
8215 0.251
16077 0.519
8293 0.59
1068 0.64
185 0.53
18 0.278
0 0.0
0 0.0
0.5468975468975469
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4218,	 Acc = 0.4630
1049 0.344
4874 0.503
2304 0.44
235 0.374
6 0.833
0 0.0
0 0.0
0 0.0
0.4798490362582558
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.5104,	 Acc1 = 0.3782,	 Acc2 = 0.3996

 ===== Epoch 220	 =====
[-0.36710912 -0.3811568   1.7568723   2.2185524  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.32085965e-03  2.41595390e-03 -2.60543615e-01  1.21798245e-02
  1.90793513e-03  5.47399861e-04  1.41669821e-03  2.72805081e-03
 -1.26931045e-04  5.04225399e-03  2.53474922e-03  4.06765984e-03
 -1.59978902e-03 -1.70574547e-03] 0 1
train:	 Loss = 1.4092,	 Acc = 0.4731
8218 0.245
16075 0.521
8293 0.587
1067 0.618
185 0.524
18 0.333
0 0.0
0 0.0
0.5461814494110305
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3868,	 Acc = 0.5005
1049 0.347
4874 0.535
2304 0.505
235 0.421
6 0.833
0 0.0
0 0.0
0 0.0
0.522172799568675
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4746,	 Acc1 = 0.3930,	 Acc2 = 0.4175

 ===== Epoch 221	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 4 1
train:	 Loss = 1.4025,	 Acc = 0.4781
8217 0.254
16077 0.522
8291 0.594
1068 0.645
185 0.53
18 0.278
0 0.0
0 0.0
0.5500214516946839
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3805,	 Acc = 0.5119
1049 0.349
4874 0.535
2304 0.546
235 0.417
6 0.833
0 0.0
0 0.0
0 0.0
0.5349777598059038
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4749,	 Acc1 = 0.4079,	 Acc2 = 0.4354

 ===== Epoch 222	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 1 1
train:	 Loss = 1.4060,	 Acc = 0.4749
8218 0.25
16077 0.519
8291 0.591
1067 0.633
185 0.53
18 0.333
0 0.0
0 0.0
0.5469225368593494
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3999,	 Acc = 0.4850
1049 0.349
4874 0.525
2304 0.472
235 0.383
6 0.833
0 0.0
0 0.0
0 0.0
0.5042458552365547
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4765,	 Acc1 = 0.3965,	 Acc2 = 0.4217

 ===== Epoch 223	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 4 1
train:	 Loss = 1.4047,	 Acc = 0.4768
8216 0.251
16078 0.519
8291 0.596
1068 0.648
185 0.541
18 0.333
0 0.0
0 0.0
0.5492199687987519
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4120,	 Acc = 0.4626
1049 0.344
4874 0.506
2304 0.436
235 0.349
6 0.833
0 0.0
0 0.0
0 0.0
0.47930988003774094
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4966,	 Acc1 = 0.3852,	 Acc2 = 0.4081

 ===== Epoch 224	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  1.1879504   3.864701   -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  4.4473128e+00  1.3223939e+00
  1.9079351e-03  5.4739986e-04  2.3946133e-01  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 0 0
train:	 Loss = 1.4045,	 Acc = 0.4748
8217 0.253
16076 0.52
8292 0.586
1068 0.632
185 0.535
18 0.333
0 0.0
0 0.0
0.5458871250828815
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3915,	 Acc = 0.4870
1049 0.347
4874 0.532
2304 0.466
235 0.366
6 0.833
0 0.0
0 0.0
0 0.0
0.5068068472840005
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4772,	 Acc1 = 0.3986,	 Acc2 = 0.4242

 ===== Epoch 225	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  2.9921255   1.691489
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  6.8547649e+00  2.8397267e+00
 -1.2693105e-04  5.0422540e-03  7.1336353e-01  1.8159729e-01
 -1.5997890e-03 -1.7057455e-03] 2 2
train:	 Loss = 1.4053,	 Acc = 0.4758
8218 0.246
16076 0.523
8291 0.589
1068 0.651
185 0.541
18 0.333
0 0.0
0 0.0
0.5494968406271941
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3932,	 Acc = 0.4988
1049 0.351
4874 0.537
2304 0.496
235 0.379
6 0.833
0 0.0
0 0.0
0 0.0
0.519746596576358
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4692,	 Acc1 = 0.4044,	 Acc2 = 0.4312

 ===== Epoch 226	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  2.5237184   2.0166848
 -0.3641531  -0.3721681   2.7806087   0.85282916 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  5.8331728e-01 -3.2238510e-01  1.4166982e-03  2.7280508e-03
 -5.7129216e+00 -2.1758034e+00  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 5 5
train:	 Loss = 1.4062,	 Acc = 0.4748
8217 0.248
16077 0.519
8291 0.593
1068 0.642
185 0.486
18 0.333
0 0.0
0 0.0
0.5475252544951051
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3999,	 Acc = 0.4844
1049 0.348
4874 0.538
2304 0.445
235 0.37
6 0.833
0 0.0
0 0.0
0 0.0
0.5037066990160399
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4825,	 Acc1 = 0.3916,	 Acc2 = 0.4158

 ===== Epoch 227	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  1.8217552   2.4295073
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
 -4.0585352e-03  2.3253588e-02  1.4166982e-03  2.7280508e-03
  3.8862889e+00  2.1129067e+00  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
train:	 Loss = 1.4054,	 Acc = 0.4774
8216 0.25
16076 0.521
8293 0.595
1068 0.64
185 0.53
18 0.333
0 0.0
0 0.0
0.5501170046801872
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3814,	 Acc = 0.5159
1049 0.35
4874 0.541
2304 0.546
235 0.43
6 0.833
0 0.0
0 0.0
0 0.0
0.5394257986251516
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4545,	 Acc1 = 0.4165,	 Acc2 = 0.4458

 ===== Epoch 228	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 6 1
train:	 Loss = 1.4040,	 Acc = 0.4756
8219 0.249
16076 0.521
8290 0.59
1068 0.649
185 0.519
18 0.333
0 0.0
0 0.0
0.5481530600304247
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4438,	 Acc = 0.4425
1049 0.348
4874 0.478
2304 0.421
235 0.336
6 0.833
0 0.0
0 0.0
0 0.0
0.45585658444534305
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.5380,	 Acc1 = 0.3666,	 Acc2 = 0.3857

 ===== Epoch 229	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.5657269   1.1436511
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.4343970e-01 -7.5820670e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
train:	 Loss = 1.4043,	 Acc = 0.4752
8217 0.253
16077 0.519
8291 0.591
1068 0.635
185 0.497
18 0.333
0 0.0
0 0.0
0.5464721713015328
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4007,	 Acc = 0.4617
1049 0.183
4874 0.529
2304 0.456
235 0.374
6 0.0
0 0.0
0 0.0
0 0.0
0.5011457069685942
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4893,	 Acc1 = 0.3631,	 Acc2 = 0.4153

 ===== Epoch 230	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 4 6
train:	 Loss = 1.4035,	 Acc = 0.4770
8216 0.251
16076 0.522
8293 0.591
1068 0.642
185 0.535
18 0.333
0 0.0
0 0.0
0.5492589703588143
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3517,	 Acc = 0.5253
1049 0.348
4874 0.548
2304 0.569
235 0.409
6 0.833
0 0.0
0 0.0
0 0.0
0.5503437120905782
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4558,	 Acc1 = 0.3951,	 Acc2 = 0.4200

 ===== Epoch 231	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   2.208595    1.250399   -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
  5.6785214e-01  1.7921265e-02  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 6 2
train:	 Loss = 1.4046,	 Acc = 0.4768
8219 0.25
16078 0.522
8289 0.592
1067 0.64
185 0.546
18 0.333
0 0.0
0 0.0
0.5497133049888833
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3711,	 Acc = 0.5091
1049 0.35
4874 0.541
2304 0.525
235 0.4
6 0.833
0 0.0
0 0.0
0 0.0
0.5316080334276857
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4563,	 Acc1 = 0.3992,	 Acc2 = 0.4250

 ===== Epoch 232	 =====
[ 1.8218963   2.327466   -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  2.2042181   2.5634193 ] [ 6.5164608e-01  1.5588948e-01  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
  5.3702582e-02  2.8565225e-01] 4 2
train:	 Loss = 1.4040,	 Acc = 0.4761
8219 0.256
16076 0.522
8290 0.585
1068 0.632
185 0.497
18 0.333
0 0.0
0 0.0
0.5465538089480049
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3882,	 Acc = 0.4966
1049 0.347
4874 0.526
2304 0.507
235 0.451
6 0.833
0 0.0
0 0.0
0 0.0
0.5177247607494272
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4721,	 Acc1 = 0.3951,	 Acc2 = 0.4200

 ===== Epoch 233	 =====
[ 1.3852254   2.6079297  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  1.2154899   2.9331498 ] [ 1.7305471e-01 -9.3897022e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
  5.4229070e-03  1.2426616e-02] 3 0
train:	 Loss = 1.4090,	 Acc = 0.4737
8213 0.25
16081 0.517
8291 0.592
1068 0.621
185 0.514
18 0.333
0 0.0
0 0.0
0.5453340092812854
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4049,	 Acc = 0.4685
1049 0.347
4874 0.516
2304 0.434
235 0.353
6 0.833
0 0.0
0 0.0
0 0.0
0.48564496562879095
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4970,	 Acc1 = 0.3901,	 Acc2 = 0.4140

 ===== Epoch 234	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.6365831   3.3127925  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -3.6591475e+00 -6.4258761e+00  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 6 1
train:	 Loss = 1.4031,	 Acc = 0.4755
8218 0.253
16076 0.52
8291 0.588
1068 0.635
185 0.514
18 0.333
0 0.0
0 0.0
0.5469225368593494
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3951,	 Acc = 0.4943
1049 0.349
4874 0.524
2304 0.508
235 0.374
6 0.833
0 0.0
0 0.0
0 0.0
0.5148941905917239
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4736,	 Acc1 = 0.4058,	 Acc2 = 0.4329

 ===== Epoch 235	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.6869856   2.521844
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03 -1.3772857e-01  3.3249748e-01
 -1.5997890e-03 -1.7057455e-03] 6 4
train:	 Loss = 1.4036,	 Acc = 0.4784
8216 0.253
16076 0.522
8293 0.596
1068 0.638
185 0.519
18 0.333
0 0.0
0 0.0
0.5507020280811232
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3875,	 Acc = 0.4877
1049 0.346
4874 0.523
2304 0.486
235 0.409
6 0.833
0 0.0
0 0.0
0 0.0
0.5077503706699016
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4800,	 Acc1 = 0.4009,	 Acc2 = 0.4269

 ===== Epoch 236	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.4308183   2.3685641  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.12154114  0.09948832  0.00253475  0.00406766
 -0.00159979 -0.00170575] 4 1
train:	 Loss = 1.4021,	 Acc = 0.4800
8215 0.256
16077 0.523
8293 0.595
1068 0.655
185 0.535
18 0.333
0 0.0
0 0.0
0.5516555516555517
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3883,	 Acc = 0.4943
1049 0.35
4874 0.538
2304 0.477
235 0.387
6 0.833
0 0.0
0 0.0
0 0.0
0.5147594015365953
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4663,	 Acc1 = 0.4066,	 Acc2 = 0.4339

 ===== Epoch 237	 =====
[ 0.21154992  1.5290287  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [-0.00043659  0.00536737  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4043,	 Acc = 0.4755
8217 0.248
16077 0.521
8291 0.59
1068 0.642
185 0.557
18 0.222
0 0.0
0 0.0
0.5484613284449471
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4122,	 Acc = 0.4790
1049 0.352
4874 0.525
2304 0.447
235 0.383
6 0.833
0 0.0
0 0.0
0 0.0
0.4969672462596037
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4941,	 Acc1 = 0.3926,	 Acc2 = 0.4170

 ===== Epoch 238	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  3.8997333   1.7681035
  1.9346924   3.8200142   4.60096     1.0739774  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  2.0054345e-01  4.4205669e-01 -4.5393362e+00 -8.3633518e+00
 -4.5697847e-01  7.5202477e-01  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 2 6
train:	 Loss = 1.4061,	 Acc = 0.4759
8218 0.252
16078 0.523
8290 0.586
1067 0.636
185 0.519
18 0.278
0 0.0
0 0.0
0.5478586473203838
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3907,	 Acc = 0.4896
1049 0.351
4874 0.537
2304 0.467
235 0.349
6 0.833
0 0.0
0 0.0
0 0.0
0.5092330502763176
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4730,	 Acc1 = 0.4038,	 Acc2 = 0.4304

 ===== Epoch 239	 =====
[-0.36710912 -0.3811568   1.580642    2.8376544  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  2.6273125e-01 -2.7137396e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 5 5
train:	 Loss = 1.4067,	 Acc = 0.4742
8215 0.251
16079 0.517
8292 0.592
1068 0.625
184 0.549
18 0.222
0 0.0
0 0.0
0.5456885456885456
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3957,	 Acc = 0.4789
1049 0.349
4874 0.523
2304 0.457
235 0.353
6 0.833
0 0.0
0 0.0
0 0.0
0.49723682436986116
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4674,	 Acc1 = 0.4005,	 Acc2 = 0.4264

 ===== Epoch 240	 =====
[ 1.315757    1.3218393  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   3.0517128   3.0767353  -0.42469367 -0.42124885
  1.3048544   1.39654   ] [0.2660327  0.1411324  0.00361774 0.00240211 0.00190794 0.0005474
 0.0014167  0.00272805 0.20154515 0.15100436 0.00253475 0.00406766
 0.09934469 0.15375023] 2 4
train:	 Loss = 1.4059,	 Acc = 0.4752
8216 0.252
16078 0.52
8291 0.588
1068 0.633
185 0.53
18 0.389
0 0.0
0 0.0
0.5467628705148206
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3711,	 Acc = 0.5000
1049 0.349
4874 0.534
2304 0.505
235 0.4
6 0.833
0 0.0
0 0.0
0 0.0
0.5213640652379027
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4713,	 Acc1 = 0.3893,	 Acc2 = 0.4130

 ===== Epoch 241	 =====
[ 0.57297987  0.92514724 -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   3.2288182   3.1065528  -0.42469367 -0.42124885
  1.1925976   1.291652  ] [ 6.7514008e-01  4.1561392e-01  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.7916445e-01  7.8023307e-02  2.5347492e-03  4.0676598e-03
  3.0878821e-02  7.8377642e-02] 2 4
train:	 Loss = 1.4034,	 Acc = 0.4763
8217 0.252
16078 0.523
8291 0.588
1067 0.635
185 0.519
18 0.333
0 0.0
0 0.0
0.5482663130387301
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3574,	 Acc = 0.5025
1049 0.259
4874 0.551
2304 0.521
235 0.417
6 0.0
0 0.0
0 0.0
0 0.0
0.5368648065777059
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4439,	 Acc1 = 0.3811,	 Acc2 = 0.4431

 ===== Epoch 242	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   2.9141538   1.2727623  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805  0.36823484  0.0737303   0.00253475  0.00406766
 -0.00159979 -0.00170575] 2 2
train:	 Loss = 1.4073,	 Acc = 0.4722
8219 0.248
16078 0.517
8289 0.587
1067 0.632
185 0.524
18 0.333
0 0.0
0 0.0
0.5440964231384328
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4269,	 Acc = 0.4610
1049 0.315
4874 0.494
2304 0.461
235 0.417
6 0.833
0 0.0
0 0.0
0 0.0
0.48173608303005794
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.5066,	 Acc1 = 0.3908,	 Acc2 = 0.4148

 ===== Epoch 243	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   2.8195832   3.1164923  -0.42469367 -0.42124885
  3.1097453   1.8396919 ] [ 2.8290639e+00  2.0211830e+00  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -2.4604708e-01 -5.5734116e-01  2.5347492e-03  4.0676598e-03
  2.2838536e-01 -5.9526497e-01] 5 5
train:	 Loss = 1.4041,	 Acc = 0.4762
8216 0.25
16078 0.522
8293 0.589
1066 0.637
185 0.551
18 0.333
0 0.0
0 0.0
0.5485959438377536
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3727,	 Acc = 0.5152
1049 0.347
4874 0.548
2304 0.537
235 0.37
6 0.833
0 0.0
0 0.0
0 0.0
0.5390214314597654
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4657,	 Acc1 = 0.4118,	 Acc2 = 0.4401

 ===== Epoch 244	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.5219092e+00  1.2515054e+00
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
train:	 Loss = 1.4065,	 Acc = 0.4760
8218 0.251
16079 0.521
8289 0.588
1067 0.644
185 0.584
18 0.389
0 0.0
0 0.0
0.5481706841407286
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3805,	 Acc = 0.5063
1049 0.351
4874 0.534
2304 0.53
235 0.387
6 0.833
0 0.0
0 0.0
0 0.0
0.5282383070494676
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4778,	 Acc1 = 0.3996,	 Acc2 = 0.4254

 ===== Epoch 245	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  1.0792614   2.2112887  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4491196e-01  6.4038426e-02
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 2
train:	 Loss = 1.4050,	 Acc = 0.4756
8216 0.254
16078 0.518
8291 0.59
1068 0.645
185 0.519
18 0.333
0 0.0
0 0.0
0.546606864274571
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4133,	 Acc = 0.4633
1049 0.324
4874 0.511
2304 0.433
235 0.383
6 0.833
0 0.0
0 0.0
0 0.0
0.4829491845262165
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4815,	 Acc1 = 0.4019,	 Acc2 = 0.4282

 ===== Epoch 246	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  2.2131977   0.956944
  2.2548432   3.5677223 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  3.7260824e-01  1.4165312e-01
  1.1228620e+00  2.1848189e-02] 2 2
train:	 Loss = 1.4007,	 Acc = 0.4796
8217 0.251
16079 0.526
8290 0.595
1067 0.639
185 0.551
18 0.333
0 0.0
0 0.0
0.5527906704629666
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4031,	 Acc = 0.4956
1049 0.347
4874 0.53
2304 0.504
235 0.366
6 0.833
0 0.0
0 0.0
0 0.0
0.5166464483083973
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4917,	 Acc1 = 0.3945,	 Acc2 = 0.4192

 ===== Epoch 247	 =====
[-0.36710912 -0.3811568   1.6644845   2.8149767  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00277513  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4043,	 Acc = 0.4742
8219 0.25
16076 0.518
8290 0.588
1068 0.644
185 0.535
18 0.333
0 0.0
0 0.0
0.5460467293365058
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3904,	 Acc = 0.4881
1049 0.324
4874 0.522
2304 0.492
235 0.46
6 0.833
0 0.0
0 0.0
0 0.0
0.5112548861032484
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4659,	 Acc1 = 0.4071,	 Acc2 = 0.4344

 ===== Epoch 248	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  2.0950437   2.7469735 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.7101283e-01 -1.9013722e-01] 4 5
train:	 Loss = 1.4050,	 Acc = 0.4766
8213 0.25
16079 0.521
8294 0.593
1067 0.641
185 0.551
18 0.278
0 0.0
0 0.0
0.5491947120071754
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3829,	 Acc = 0.4884
1049 0.349
4874 0.527
2304 0.476
235 0.421
6 0.833
0 0.0
0 0.0
0 0.0
0.5081547378352878
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4750,	 Acc1 = 0.4035,	 Acc2 = 0.4302

 ===== Epoch 249	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 2 1
train:	 Loss = 1.4046,	 Acc = 0.4773
8216 0.25
16078 0.523
8291 0.591
1068 0.642
185 0.562
18 0.333
0 0.0
0 0.0
0.5502730109204368
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4075,	 Acc = 0.4725
1049 0.345
4874 0.522
2304 0.437
235 0.362
6 0.833
0 0.0
0 0.0
0 0.0
0.490497371613425
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4904,	 Acc1 = 0.3914,	 Acc2 = 0.4155

 ===== Epoch 250	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  0.45568016  1.6970803
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  5.6470573e-02 -3.3247674e-01  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 5 5
train:	 Loss = 1.4045,	 Acc = 0.4779
8218 0.254
16077 0.521
8290 0.594
1068 0.635
185 0.551
18 0.278
0 0.0
0 0.0
0.5496138544348234
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3936,	 Acc = 0.5015
1049 0.348
4874 0.518
2304 0.543
235 0.434
6 0.833
0 0.0
0 0.0
0 0.0
0.5232511120097049
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4843,	 Acc1 = 0.3945,	 Acc2 = 0.4192

 ===== Epoch 251	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  1.757906    0.9113861
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
 -4.6356109e-01 -3.9819162e-02  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 1 1
train:	 Loss = 1.4066,	 Acc = 0.4731
8216 0.254
16077 0.516
8292 0.586
1068 0.636
185 0.497
18 0.389
0 0.0
0 0.0
0.5431357254290171
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3684,	 Acc = 0.5081
1049 0.353
4874 0.531
2304 0.54
235 0.4
6 0.833
0 0.0
0 0.0
0 0.0
0.5301253538212697
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4655,	 Acc1 = 0.4075,	 Acc2 = 0.4349

 ===== Epoch 252	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 2 1
train:	 Loss = 1.4045,	 Acc = 0.4769
8216 0.25
16078 0.522
8291 0.591
1068 0.641
185 0.578
18 0.333
0 0.0
0 0.0
0.5496489859594383
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3970,	 Acc = 0.4759
1049 0.352
4874 0.525
2304 0.44
235 0.349
6 0.833
0 0.0
0 0.0
0 0.0
0.4934627308262569
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4836,	 Acc1 = 0.3963,	 Acc2 = 0.4215

 ===== Epoch 253	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 4 1
train:	 Loss = 1.4045,	 Acc = 0.4762
8219 0.251
16077 0.52
8290 0.59
1068 0.655
184 0.554
18 0.333
0 0.0
0 0.0
0.5485041151460779
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4155,	 Acc = 0.4809
1049 0.348
4874 0.517
2304 0.473
235 0.387
6 0.833
0 0.0
0 0.0
0 0.0
0.4996630273621782
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.5047,	 Acc1 = 0.3887,	 Acc2 = 0.4123

 ===== Epoch 254	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.9699231   0.85130715
  2.705626    3.3107464 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  5.2079642e-01  1.9047378e-01
 -6.1682243e+00 -6.6344938e+00] 2 2
train:	 Loss = 1.4056,	 Acc = 0.4749
8215 0.25
16078 0.519
8293 0.587
1068 0.651
184 0.554
18 0.333
0 0.0
0 0.0
0.5469365469365469
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3636,	 Acc = 0.5053
1049 0.352
4874 0.539
2304 0.512
235 0.413
6 0.833
0 0.0
0 0.0
0 0.0
0.5270252055533091
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4617,	 Acc1 = 0.4046,	 Acc2 = 0.4314

 ===== Epoch 255	 =====
[-0.36710912 -0.3811568   2.143926    2.8875456  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -1.8230297e-01 -2.5426295e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 5 5
train:	 Loss = 1.4047,	 Acc = 0.4766
8212 0.251
16081 0.523
8292 0.588
1068 0.637
185 0.551
18 0.333
0 0.0
0 0.0
0.5489393230385275
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3963,	 Acc = 0.4806
1049 0.205
4874 0.521
2304 0.52
235 0.494
6 0.0
0 0.0
0 0.0
0 0.0
0.5196118075212293
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4719,	 Acc1 = 0.3674,	 Acc2 = 0.4190

 ===== Epoch 256	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.599327    2.22693    -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.16990198 -0.04218078  0.00253475  0.00406766
 -0.00159979 -0.00170575] 3 3
train:	 Loss = 1.4051,	 Acc = 0.4747
8218 0.247
16077 0.518
8291 0.592
1067 0.654
185 0.541
18 0.389
0 0.0
0 0.0
0.5476246197051252
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4298,	 Acc = 0.4685
1049 0.349
4874 0.522
2304 0.423
235 0.336
6 0.833
0 0.0
0 0.0
0 0.0
0.4853753875185335
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.5037,	 Acc1 = 0.3974,	 Acc2 = 0.4227

 ===== Epoch 257	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.5076231   2.1822033  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805  0.1727335   0.05655829  0.00253475  0.00406766
 -0.00159979 -0.00170575] 3 2
train:	 Loss = 1.4024,	 Acc = 0.4782
8217 0.25
16079 0.523
8289 0.594
1068 0.649
185 0.546
18 0.333
0 0.0
0 0.0
0.551425562619447
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3774,	 Acc = 0.4943
1049 0.347
4874 0.528
2304 0.499
235 0.396
6 0.833
0 0.0
0 0.0
0 0.0
0.5151637687019814
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4624,	 Acc1 = 0.4077,	 Acc2 = 0.4351

 ===== Epoch 258	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 1
train:	 Loss = 1.4036,	 Acc = 0.4780
8218 0.255
16077 0.522
8290 0.592
1068 0.641
185 0.541
18 0.333
0 0.0
0 0.0
0.5494968406271941
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3766,	 Acc = 0.4954
1049 0.347
4874 0.53
2304 0.497
235 0.421
6 0.833
0 0.0
0 0.0
0 0.0
0.5163768701981399
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4579,	 Acc1 = 0.4005,	 Acc2 = 0.4264

 ===== Epoch 259	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.7386043   2.4679565   3.6905937   1.1289111
  3.2783494   2.833506  ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
  1.3569629e-01 -3.2981199e-01  1.0723399e+00 -2.7110326e-01
 -6.8804115e-01 -3.2203928e-01] 5 5
train:	 Loss = 1.4040,	 Acc = 0.4766
8216 0.252
16075 0.52
8294 0.591
1068 0.649
185 0.578
18 0.333
0 0.0
0 0.0
0.5486739469578783
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3901,	 Acc = 0.4789
1049 0.348
4874 0.514
2304 0.473
235 0.379
6 0.833
0 0.0
0 0.0
0 0.0
0.49737161342498987
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4699,	 Acc1 = 0.3994,	 Acc2 = 0.4252

 ===== Epoch 260	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.6984832   2.1822033  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.17710331  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4068,	 Acc = 0.4755
8217 0.253
16076 0.521
8292 0.585
1068 0.638
185 0.551
18 0.389
0 0.0
0 0.0
0.5467061897889933
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3874,	 Acc = 0.5002
1049 0.347
4874 0.536
2304 0.498
235 0.46
6 0.833
0 0.0
0 0.0
0 0.0
0.5219032214584176
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4757,	 Acc1 = 0.3992,	 Acc2 = 0.4250

 ===== Epoch 261	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 3.6638222e+00  4.4885650e+00  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 3 1
train:	 Loss = 1.4051,	 Acc = 0.4760
8219 0.253
16076 0.522
8290 0.584
1068 0.648
185 0.568
18 0.389
0 0.0
0 0.0
0.547411943675157
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3862,	 Acc = 0.5065
1049 0.348
4874 0.531
2304 0.539
235 0.387
6 0.833
0 0.0
0 0.0
0 0.0
0.5289122523251112
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4686,	 Acc1 = 0.3941,	 Acc2 = 0.4187

 ===== Epoch 262	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.7572488   1.3328148
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  1.8796591e-01  2.4817091e-01
 -1.5997890e-03 -1.7057455e-03] 4 2
train:	 Loss = 1.4054,	 Acc = 0.4735
8216 0.25
16077 0.518
8292 0.588
1068 0.63
185 0.551
18 0.278
0 0.0
0 0.0
0.5451248049921997
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3927,	 Acc = 0.4864
1049 0.348
4874 0.527
2304 0.474
235 0.362
6 0.833
0 0.0
0 0.0
0 0.0
0.5059981129532282
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4752,	 Acc1 = 0.4025,	 Acc2 = 0.4289

 ===== Epoch 263	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 1
train:	 Loss = 1.4039,	 Acc = 0.4777
8216 0.256
16079 0.522
8291 0.588
1067 0.654
185 0.524
18 0.222
0 0.0
0 0.0
0.5486739469578783
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3786,	 Acc = 0.5038
1049 0.352
4874 0.535
2304 0.516
235 0.417
6 0.833
0 0.0
0 0.0
0 0.0
0.5252729478366357
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4574,	 Acc1 = 0.4137,	 Acc2 = 0.4423

 ===== Epoch 264	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  2.6706579   1.8192358
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225 -0.00935372  0.09283248
 -0.00159979 -0.00170575] 2 2
train:	 Loss = 1.4055,	 Acc = 0.4759
8219 0.252
16073 0.518
8293 0.592
1068 0.65
185 0.562
18 0.333
0 0.0
0 0.0
0.5476459804189258
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4085,	 Acc = 0.4888
1049 0.349
4874 0.528
2304 0.479
235 0.383
6 0.833
0 0.0
0 0.0
0 0.0
0.5085591050006739
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4989,	 Acc1 = 0.3930,	 Acc2 = 0.4175

 ===== Epoch 265	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 1 1
train:	 Loss = 1.4048,	 Acc = 0.4761
8217 0.253
16077 0.52
8291 0.588
1068 0.646
185 0.535
18 0.278
0 0.0
0 0.0
0.5475642575763485
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3847,	 Acc = 0.4865
1049 0.316
4874 0.524
2304 0.496
235 0.379
6 0.833
0 0.0
0 0.0
0 0.0
0.5107157298827335
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4718,	 Acc1 = 0.3986,	 Acc2 = 0.4242

 ===== Epoch 266	 =====
[ 1.5911102   2.5599225  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 8.8389552e-01  8.8006951e-02  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 2 2
train:	 Loss = 1.4042,	 Acc = 0.4768
8217 0.253
16078 0.521
8290 0.59
1068 0.642
185 0.541
18 0.389
0 0.0
0 0.0
0.5483833222824603
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3908,	 Acc = 0.4900
1049 0.327
4874 0.521
2304 0.5
235 0.464
6 0.833
0 0.0
0 0.0
0 0.0
0.5130071438199219
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4716,	 Acc1 = 0.4062,	 Acc2 = 0.4334

 ===== Epoch 267	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 3 1
train:	 Loss = 1.4043,	 Acc = 0.4749
8216 0.247
16077 0.52
8292 0.592
1068 0.631
185 0.557
18 0.389
0 0.0
0 0.0
0.5479719188767551
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3781,	 Acc = 0.4961
1049 0.348
4874 0.534
2304 0.49
235 0.421
6 0.833
0 0.0
0 0.0
0 0.0
0.5170508154737835
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4636,	 Acc1 = 0.4042,	 Acc2 = 0.4309

 ===== Epoch 268	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 1 1
train:	 Loss = 1.4031,	 Acc = 0.4771
8217 0.253
16075 0.521
8293 0.589
1068 0.659
185 0.524
18 0.278
0 0.0
0 0.0
0.5488903623386248
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3644,	 Acc = 0.5189
1049 0.348
4874 0.543
2304 0.556
235 0.413
6 0.833
0 0.0
0 0.0
0 0.0
0.5430651031136272
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4676,	 Acc1 = 0.3978,	 Acc2 = 0.4232

 ===== Epoch 269	 =====
[ 2.7997553   3.2749786  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  2.4133217   3.5336337 ] [-0.00640358  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4027,	 Acc = 0.4780
8216 0.25
16078 0.523
8292 0.592
1068 0.658
185 0.535
17 0.176
0 0.0
0 0.0
0.5510140405616225
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4138,	 Acc = 0.5090
1049 0.349
4874 0.537
2304 0.532
235 0.404
6 0.833
0 0.0
0 0.0
0 0.0
0.5316080334276857
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.5042,	 Acc1 = 0.3899,	 Acc2 = 0.4138

 ===== Epoch 270	 =====
[ 2.4555268   2.1076431  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  2.1923325   2.3431544 ] [-1.32082775e-01  1.42216105e-02  3.61774070e-03  2.40210793e-03
  1.90793513e-03  5.47399861e-04  1.41669821e-03  2.72805081e-03
 -1.26931045e-04  5.04225399e-03  2.53474922e-03  4.06765984e-03
 -1.03781587e-02  1.71374027e-02] 0 0
train:	 Loss = 1.4068,	 Acc = 0.4757
8217 0.251
16077 0.521
8291 0.588
1068 0.644
185 0.541
18 0.278
0 0.0
0 0.0
0.5476812668200788
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3726,	 Acc = 0.5050
1049 0.348
4874 0.535
2304 0.522
235 0.404
6 0.833
0 0.0
0 0.0
0 0.0
0.5271599946084378
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4661,	 Acc1 = 0.4083,	 Acc2 = 0.4359

 ===== Epoch 271	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.3287971   2.9574645  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
  6.8206179e-01 -1.2804084e-01  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 2 2
train:	 Loss = 1.4024,	 Acc = 0.4775
8216 0.251
16078 0.522
8292 0.594
1067 0.641
185 0.551
18 0.333
0 0.0
0 0.0
0.5502340093603744
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4064,	 Acc = 0.4732
1049 0.348
4874 0.517
2304 0.444
235 0.391
6 0.833
0 0.0
0 0.0
0 0.0
0.49090173877881116
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4847,	 Acc1 = 0.3862,	 Acc2 = 0.4093

 ===== Epoch 272	 =====
[ 1.5869212   2.6837306  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  1.2419026   3.027549  ] [-2.1589957e-01 -8.6126462e-02  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -5.4267298e-02 -1.7129408e-01] 3 3
train:	 Loss = 1.4050,	 Acc = 0.4787
8218 0.253
16074 0.524
8293 0.592
1068 0.65
185 0.53
18 0.389
0 0.0
0 0.0
0.551057024728918
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3733,	 Acc = 0.5005
1049 0.349
4874 0.535
2304 0.507
235 0.396
6 0.833
0 0.0
0 0.0
0 0.0
0.5219032214584176
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4629,	 Acc1 = 0.4013,	 Acc2 = 0.4274

 ===== Epoch 273	 =====
[-0.36710912 -0.3811568   2.8301227   1.2025901  -0.44130662 -0.36481208
  2.056896    2.6665359  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 4.6614895e+00  4.0222416e+00  3.5022500e-01 -3.3737352e-01
  1.9079351e-03  5.4739986e-04 -3.3066180e-02 -8.7233829e-01
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 5 5
train:	 Loss = 1.4051,	 Acc = 0.4765
8218 0.254
16077 0.519
8290 0.593
1068 0.636
185 0.546
18 0.278
0 0.0
0 0.0
0.5477416335127545
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3879,	 Acc = 0.5026
1049 0.354
4874 0.533
2304 0.512
235 0.447
6 0.833
0 0.0
0 0.0
0 0.0
0.523655479175091
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4652,	 Acc1 = 0.3976,	 Acc2 = 0.4230

 ===== Epoch 274	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  0.6579834   3.2834122
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225 -0.07512366 -0.02256178
 -0.00159979 -0.00170575] 1 1
train:	 Loss = 1.4046,	 Acc = 0.4759
8216 0.246
16080 0.522
8290 0.592
1067 0.637
185 0.546
18 0.333
0 0.0
0 0.0
0.5494929797191888
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 0
val:	 Loss = 1.4015,	 Acc = 0.4846
1049 0.352
4874 0.516
2304 0.483
235 0.438
6 0.833
0 0.0
0 0.0
0 0.0
0.5034371209057824
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4908,	 Acc1 = 0.3881,	 Acc2 = 0.4115

 ===== Epoch 275	 =====
[-0.36710912 -0.3811568   2.7877958   2.4498653  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595 -0.01152586  0.09040155  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 2 1
train:	 Loss = 1.4030,	 Acc = 0.4766
8217 0.245
16076 0.523
8292 0.592
1068 0.654
185 0.53
18 0.278
0 0.0
0 0.0
0.5509185225632826
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3879,	 Acc = 0.4874
1049 0.348
4874 0.522
2304 0.486
235 0.4
6 0.833
0 0.0
0 0.0
0 0.0
0.507076425394258
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4731,	 Acc1 = 0.3924,	 Acc2 = 0.4167

 ===== Epoch 276	 =====
[ 4.900646    2.9945147  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  1.4920523   3.8060498  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [-1.8559792e+00  7.6201297e-02  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04 -3.6650195e+00 -8.3354836e+00
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 3
train:	 Loss = 1.4013,	 Acc = 0.4767
8215 0.249
16077 0.523
8293 0.589
1068 0.641
185 0.535
18 0.333
0 0.0
0 0.0
0.5495105495105496
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4181,	 Acc = 0.4706
1049 0.348
4874 0.517
2304 0.438
235 0.37
6 0.833
0 0.0
0 0.0
0 0.0
0.48793637956597924
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4851,	 Acc1 = 0.4058,	 Acc2 = 0.4329

 ===== Epoch 277	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   2.4384317   2.644378   -0.42469367 -0.42124885
  3.4302235   1.9472022 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.3285841e-01 -6.2173623e-01  2.5347492e-03  4.0676598e-03
 -3.1058484e-01 -6.6592675e-01] 5 5
train:	 Loss = 1.4041,	 Acc = 0.4747
8217 0.245
16077 0.522
8291 0.586
1068 0.636
185 0.584
18 0.389
0 0.0
0 0.0
0.5482273099574866
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4031,	 Acc = 0.4765
1049 0.348
4874 0.527
2304 0.437
235 0.374
6 0.833
0 0.0
0 0.0
0 0.0
0.4946758323224154
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4840,	 Acc1 = 0.3926,	 Acc2 = 0.4170

 ===== Epoch 278	 =====
[-0.36710912 -0.3811568   1.0918388   3.0168083  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -1.4048499e-02 -4.2321386e-05
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 0 0
train:	 Loss = 1.4063,	 Acc = 0.4750
8215 0.246
16080 0.521
8291 0.591
1067 0.641
185 0.524
18 0.389
0 0.0
0 0.0
0.5483405483405484
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3978,	 Acc = 0.4771
1049 0.351
4874 0.513
2304 0.469
235 0.374
6 0.833
0 0.0
0 0.0
0 0.0
0.49494541043267287
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4976,	 Acc1 = 0.3854,	 Acc2 = 0.4083

 ===== Epoch 279	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 3 1
train:	 Loss = 1.4035,	 Acc = 0.4778
8220 0.253
16076 0.523
8291 0.591
1066 0.648
185 0.541
18 0.333
0 0.0
0 0.0
0.5498127633016071
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3626,	 Acc = 0.5064
1049 0.183
4874 0.546
2304 0.581
235 0.404
6 0.0
0 0.0
0 0.0
0 0.0
0.5520959698072516
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4626,	 Acc1 = 0.3718,	 Acc2 = 0.4257

 ===== Epoch 280	 =====
[-0.36710912 -0.3811568   2.4992347   2.3795643  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.03390235 -0.02204218  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 2 3
train:	 Loss = 1.4047,	 Acc = 0.4763
8217 0.249
16078 0.523
8291 0.589
1067 0.64
185 0.573
18 0.278
0 0.0
0 0.0
0.5491633839073287
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3711,	 Acc = 0.5107
1049 0.352
4874 0.536
2304 0.541
235 0.391
6 0.833
0 0.0
0 0.0
0 0.0
0.5332255020892304
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4607,	 Acc1 = 0.4114,	 Acc2 = 0.4396

 ===== Epoch 281	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.3580285   2.7934668  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -3.1590817e+00 -5.5286388e+00  2.5347492e-03  4.0676598e-03
  4.7043662e+00  2.5656734e+00] 6 6
train:	 Loss = 1.4068,	 Acc = 0.4725
8218 0.24
16074 0.519
8293 0.59
1068 0.645
185 0.551
18 0.333
0 0.0
0 0.0
0.547156564474608
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4235,	 Acc = 0.4608
1049 0.349
4874 0.496
2304 0.446
235 0.37
6 0.833
0 0.0
0 0.0
0 0.0
0.4766140989351665
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.5060,	 Acc1 = 0.3883,	 Acc2 = 0.4118

 ===== Epoch 282	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  2.2196257   2.2041779 ] [ 2.8619492e+00  2.7796962e+00  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.4819178e-01  3.1269766e-02] 4 2
train:	 Loss = 1.4036,	 Acc = 0.4760
8219 0.251
16073 0.522
8294 0.587
1067 0.647
185 0.541
18 0.389
0 0.0
0 0.0
0.5481140539064633
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3911,	 Acc = 0.5015
1049 0.35
4874 0.54
2304 0.494
235 0.451
6 0.833
0 0.0
0 0.0
0 0.0
0.5229815338994473
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4779,	 Acc1 = 0.4011,	 Acc2 = 0.4272

 ===== Epoch 283	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.3269866   2.9468484
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03 -4.3251988e-01  5.7660067e-01
 -1.5997890e-03 -1.7057455e-03] 6 1
train:	 Loss = 1.4031,	 Acc = 0.4768
8217 0.25
16079 0.521
8290 0.592
1067 0.655
185 0.541
18 0.389
0 0.0
0 0.0
0.5493974023947892
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3687,	 Acc = 0.5221
1049 0.349
4874 0.54
2304 0.577
235 0.383
6 0.833
0 0.0
0 0.0
0 0.0
0.546569618546974
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4791,	 Acc1 = 0.3872,	 Acc2 = 0.4105

 ===== Epoch 284	 =====
[ 2.394816    3.1056898  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  1.9876316   3.3841684 ] [-2.9731891e+00 -4.0705352e+00  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -4.7365336e+00 -6.7663956e+00] 6 1
train:	 Loss = 1.4040,	 Acc = 0.4775
8219 0.248
16073 0.524
8293 0.591
1068 0.649
185 0.589
18 0.278
0 0.0
0 0.0
0.5511955376994188
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.3995,	 Acc = 0.4624
1049 0.347
4874 0.503
2304 0.44
235 0.349
6 0.833
0 0.0
0 0.0
0 0.0
0.478770723817226
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.5024,	 Acc1 = 0.3794,	 Acc2 = 0.4011

 ===== Epoch 285	 =====
[-0.36710912 -0.3811568   1.178122    1.5926472  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595 -0.06200195 -0.11737492  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 3 2
train:	 Loss = 1.4051,	 Acc = 0.4777
8218 0.253
16076 0.522
8292 0.592
1068 0.644
184 0.538
18 0.333
0 0.0
0 0.0
0.549886886652625
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3927,	 Acc = 0.4701
1049 0.317
4874 0.515
2304 0.452
235 0.383
6 0.833
0 0.0
0 0.0
0 0.0
0.4917104731095835
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 1
Testing:	 Loss = 1.4828,	 Acc1 = 0.3846,	 Acc2 = 0.4073

 ===== Epoch 286	 =====
[-0.36710912 -0.3811568   2.947745    1.7377845  -0.44130662 -0.36481208
  2.2523108   3.0128586  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  7.9273397e-01  1.3929014e-01
  1.9079351e-03  5.4739986e-04 -1.8212175e-01  2.8141162e-01
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 2 4
train:	 Loss = 1.4038,	 Acc = 0.4752
8217 0.25
16077 0.519
8291 0.589
1068 0.646
185 0.541
18 0.333
0 0.0
0 0.0
0.5472132298451577
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3689,	 Acc = 0.5158
1049 0.341
4874 0.536
2304 0.562
235 0.413
6 0.833
0 0.0
0 0.0
0 0.0
0.5405041110661815
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4576,	 Acc1 = 0.3978,	 Acc2 = 0.4232

 ===== Epoch 287	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 3 1
train:	 Loss = 1.4041,	 Acc = 0.4783
8215 0.253
16077 0.525
8294 0.589
1067 0.643
185 0.53
18 0.278
0 0.0
0 0.0
0.5504075504075504
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3764,	 Acc = 0.4927
1049 0.347
4874 0.531
2304 0.48
235 0.468
6 0.833
0 0.0
0 0.0
0 0.0
0.5132767219301793
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4662,	 Acc1 = 0.3994,	 Acc2 = 0.4252

 ===== Epoch 288	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.8305324   2.020683
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03 -2.9701146e-01  8.9171582e-01
 -1.5997890e-03 -1.7057455e-03] 6 6
train:	 Loss = 1.4026,	 Acc = 0.4761
8218 0.25
16078 0.52
8290 0.59
1067 0.652
185 0.595
18 0.222
0 0.0
0 0.0
0.5485217255636166
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4107,	 Acc = 0.4691
1049 0.352
4874 0.513
2304 0.437
235 0.379
6 0.833
0 0.0
0 0.0
0 0.0
0.48564496562879095
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4943,	 Acc1 = 0.3932,	 Acc2 = 0.4177

 ===== Epoch 289	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 2 1
train:	 Loss = 1.4038,	 Acc = 0.4755
8217 0.249
16077 0.521
8292 0.589
1067 0.65
185 0.503
18 0.333
0 0.0
0 0.0
0.5481883068762432
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3946,	 Acc = 0.4880
1049 0.349
4874 0.528
2304 0.476
235 0.391
6 0.833
0 0.0
0 0.0
0 0.0
0.5076155816147728
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4846,	 Acc1 = 0.3959,	 Acc2 = 0.4210

 ===== Epoch 290	 =====
[ 0.84751457  3.0627358  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [-0.01458535  0.00536737  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4019,	 Acc = 0.4785
8217 0.256
16077 0.52
8291 0.596
1068 0.651
185 0.568
18 0.333
0 0.0
0 0.0
0.5499434455321971
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4176,	 Acc = 0.4646
1049 0.347
4874 0.493
2304 0.454
235 0.489
6 0.833
0 0.0
0 0.0
0 0.0
0.48119692680954307
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.5063,	 Acc1 = 0.3798,	 Acc2 = 0.4016

 ===== Epoch 291	 =====
[ 0.86312795  2.87576    -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [-1.9352898e-02  1.9720925e-01  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 0 1
train:	 Loss = 1.4037,	 Acc = 0.4765
8218 0.249
16073 0.52
8294 0.593
1068 0.651
185 0.568
18 0.389
0 0.0
0 0.0
0.5494578360246509
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3800,	 Acc = 0.4959
1049 0.348
4874 0.532
2304 0.489
235 0.472
6 0.833
0 0.0
0 0.0
0 0.0
0.5167812373635261
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4690,	 Acc1 = 0.4040,	 Acc2 = 0.4307

 ===== Epoch 292	 =====
[ 3.860549    2.767112   -0.4201916  -0.33495995 -0.44130662 -0.36481208
  1.3039597   2.850869   -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [-4.55173969e+00 -3.67504573e+00  3.61774070e-03  2.40210793e-03
  1.90793513e-03  5.47399861e-04 -1.19321775e-02  1.97806537e-01
 -1.26931045e-04  5.04225399e-03  2.53474922e-03  4.06765984e-03
 -1.59978902e-03 -1.70574547e-03] 4 4
train:	 Loss = 1.4037,	 Acc = 0.4746
8217 0.245
16076 0.521
8292 0.589
1068 0.65
185 0.519
18 0.278
0 0.0
0 0.0
0.5481883068762432
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3726,	 Acc = 0.5139
1049 0.343
4874 0.534
2304 0.559
235 0.413
6 0.833
0 0.0
0 0.0
0 0.0
0.5380779080738644
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4627,	 Acc1 = 0.4095,	 Acc2 = 0.4374

 ===== Epoch 293	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.9408365   1.9346994
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03 -6.0861420e-02  3.8131812e-01
 -1.5997890e-03 -1.7057455e-03] 1 6
train:	 Loss = 1.4031,	 Acc = 0.4771
8218 0.25
16073 0.522
8294 0.592
1068 0.645
185 0.557
18 0.278
0 0.0
0 0.0
0.5499258912551681
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3864,	 Acc = 0.4979
1049 0.348
4874 0.535
2304 0.493
235 0.438
6 0.833
0 0.0
0 0.0
0 0.0
0.5190726513007143
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4704,	 Acc1 = 0.4093,	 Acc2 = 0.4371

 ===== Epoch 294	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  1.0523589   0.7898903
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03 -3.7387863e-01  3.0697105e-02
 -1.5997890e-03 -1.7057455e-03] 1 1
train:	 Loss = 1.4055,	 Acc = 0.4769
8217 0.256
16078 0.519
8291 0.592
1067 0.643
185 0.53
18 0.278
0 0.0
0 0.0
0.5476812668200788
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4153,	 Acc = 0.4426
1049 0.13
4874 0.515
2304 0.44
235 0.379
6 0.0
0 0.0
0 0.0
0 0.0
0.48685806712494945
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4901,	 Acc1 = 0.3683,	 Acc2 = 0.4210

 ===== Epoch 295	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681   1.3110293   2.9524949  -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805  0.15112633 -0.0765248   0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 2
train:	 Loss = 1.4035,	 Acc = 0.4744
8215 0.249
16077 0.519
8293 0.589
1068 0.636
185 0.541
18 0.333
0 0.0
0 0.0
0.5466245466245466
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3794,	 Acc = 0.5133
1049 0.348
4874 0.539
2304 0.544
235 0.409
6 0.833
0 0.0
0 0.0
0 0.0
0.5367300175225772
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4686,	 Acc1 = 0.4165,	 Acc2 = 0.4458

 ===== Epoch 296	 =====
[-0.36710912 -0.3811568   1.8215843   0.8964408  -0.44130662 -0.36481208
  1.3084651   3.864701   -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
 -0.11760562  0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4039,	 Acc = 0.4760
8215 0.249
16078 0.523
8292 0.588
1068 0.632
185 0.589
18 0.389
0 0.0
0 0.0
0.5488865488865489
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3840,	 Acc = 0.5150
1049 0.348
4874 0.537
2304 0.555
235 0.4
6 0.833
0 0.0
0 0.0
0 0.0
0.5386170642943793
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4712,	 Acc1 = 0.4081,	 Acc2 = 0.4356

 ===== Epoch 297	 =====
[ 2.1844547   2.0444756  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
  2.1852887   2.2697327 ] [ 4.5611334e-01 -1.8352312e-01  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
  2.0344779e-02 -2.5608826e-01] 4 5
train:	 Loss = 1.4014,	 Acc = 0.4783
8216 0.254
16075 0.523
8294 0.593
1068 0.633
185 0.546
18 0.333
0 0.0
0 0.0
0.5502340093603744
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4008,	 Acc = 0.5120
1049 0.348
4874 0.546
2304 0.523
235 0.434
6 0.833
0 0.0
0 0.0
0 0.0
0.5352473379161612
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 6
Testing:	 Loss = 1.4947,	 Acc1 = 0.4019,	 Acc2 = 0.4282

 ===== Epoch 298	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497  3.0382123   1.5809387
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.00361774  0.00240211  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00094978  0.00406766
 -0.00159979 -0.00170575] 0 0
train:	 Loss = 1.4044,	 Acc = 0.4748
8219 0.25
16077 0.519
8291 0.59
1067 0.64
184 0.554
18 0.278
0 0.0
0 0.0
0.5469438701876195
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 2
val:	 Loss = 1.4220,	 Acc = 0.4699
1049 0.348
4874 0.518
2304 0.432
235 0.383
6 0.833
0 0.0
0 0.0
0 0.0
0.4871276452352069
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4999,	 Acc1 = 0.3943,	 Acc2 = 0.4190

 ===== Epoch 299	 =====
[-0.36710912 -0.3811568   1.2163801   0.85788864 -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 0.00132086  0.00241595  0.11634827 -0.00493118  0.00190794  0.0005474
  0.0014167   0.00272805 -0.00012693  0.00504225  0.00253475  0.00406766
 -0.00159979 -0.00170575] 6 0
train:	 Loss = 1.4041,	 Acc = 0.4767
8217 0.254
16077 0.52
8292 0.592
1067 0.636
185 0.551
18 0.333
0 0.0
0 0.0
0.5479542883887827
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.4098,	 Acc = 0.4778
1049 0.351
4874 0.507
2304 0.475
235 0.468
6 0.833
0 0.0
0 0.0
0 0.0
0.4957541447634452
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4888,	 Acc1 = 0.4005,	 Acc2 = 0.4264

 ===== Epoch 300	 =====
[-0.36710912 -0.3811568  -0.4201916  -0.33495995  1.4275708   1.0001651
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.8519507e-01 -3.2250434e-02  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 3 3
train:	 Loss = 1.4025,	 Acc = 0.4754
8216 0.247
16076 0.518
8293 0.595
1068 0.643
185 0.584
18 0.333
0 0.0
0 0.0
0.5486349453978159
0.5585658444534304
[-0.36710912 -0.3811568  -0.4201916  -0.33495995 -0.44130662 -0.36481208
  2.7112803   1.7672136  -0.40162212 -0.40945497  2.6593246   3.0180917
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03  3.6177407e-03  2.4021079e-03
  1.9079351e-03  5.4739986e-04  1.8050896e-01 -8.6450689e-02
 -1.2693105e-04  5.0422540e-03  2.5515523e-02 -1.3685305e-02
 -1.5997890e-03 -1.7057455e-03] 3 3
val:	 Loss = 1.3808,	 Acc = 0.5163
1049 0.352
4874 0.542
2304 0.538
235 0.494
6 0.833
0 0.0
0 0.0
0 0.0
0.5395605876802804
0.5585658444534304
[-0.36710912 -0.3811568   1.0780016   2.3387444  -0.44130662 -0.36481208
 -0.3641531  -0.3721681  -0.40162212 -0.40945497 -0.42469367 -0.42124885
 -0.38694263 -0.3813124 ] [ 1.3208597e-03  2.4159539e-03 -3.7605215e-02  2.2484516e-01
  1.9079351e-03  5.4739986e-04  1.4166982e-03  2.7280508e-03
 -1.2693105e-04  5.0422540e-03  2.5347492e-03  4.0676598e-03
 -1.5997890e-03 -1.7057455e-03] 4 4
Testing:	 Loss = 1.4642,	 Acc1 = 0.4137,	 Acc2 = 0.4423
