(0.24300000000005184, array([-1.000000e+00, -1.000000e+00,  1.189783e+03,  1.790000e-01,
       -1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00]), 4, array([-1.000000e+00, -1.000000e+00,  1.173932e+03,  2.700000e-01,
       -1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00, -1.000000e+00, -1.000000e+00,
       -1.000000e+00, -1.000000e+00]), 1)
(0.2, array([-1.00000000e+00, -1.00000000e+00,  1.79280339e+03,  5.91715458e-01,
        1.79280339e+03, -5.91715458e-01, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00]), 1, array([-1.00000000e+00, -1.00000000e+00,  1.77293429e+03,  5.99266206e-01,
        1.77293429e+03, -5.99266206e-01, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00]))
(0.2, array([-1.00000000e+00, -1.00000000e+00,  1.77293429e+03,  5.99266206e-01,
        1.77293429e+03, -5.99266206e-01, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00]), 1, array([-1.00000000e+00, -1.00000000e+00,  1.74725952e+03,  6.09338117e-01,
        1.74725952e+03, -6.09338117e-01, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00]))
(0.2, array([-1.00000000e+00, -1.00000000e+00,  1.74725952e+03,  6.09338117e-01,
        1.74725952e+03, -6.09338117e-01, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00]), 1, array([-1.00000000e+00, -1.00000000e+00,  1.72293971e+03,  6.19223933e-01,
        1.72293971e+03, -6.19223933e-01, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00]))
(0.2, array([-1.00000000e+00, -1.00000000e+00,  1.72293971e+03,  6.19223933e-01,
        1.72293971e+03, -6.19223933e-01, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00]), 1, array([-1.00000000e+00, -1.00000000e+00,  1.69856028e+03,  6.29491609e-01,
        1.69856028e+03, -6.29491609e-01, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00]))
(0.2, array([-1.00000000e+00, -1.00000000e+00,  1.69856028e+03,  6.29491609e-01,
        1.69856028e+03, -6.29491609e-01, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00]), 2, array([-1.00000000e+00, -1.00000000e+00,  1.68400512e+03,  6.35801293e-01,
        1.68400512e+03, -6.35801293e-01, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00]))
(0.2, array([-1.00000000e+00, -1.00000000e+00,  1.68400512e+03,  6.35801293e-01,
        1.68400512e+03, -6.35801293e-01, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00]), 2, array([-1.00000000e+00, -1.00000000e+00,  1.67914276e+03,  6.37940147e-01,
        1.67914276e+03, -6.37940147e-01, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00]))
(0.2, array([-1.00000000e+00, -1.00000000e+00,  1.67914276e+03,  6.37940147e-01,
        1.67914276e+03, -6.37940147e-01, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00]), 2, array([-1.00000000e+00, -1.00000000e+00,  1.68392788e+03,  6.35835147e-01,
        1.68392788e+03, -6.35835147e-01, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00]))
(0.2, array([-1.00000000e+00, -1.00000000e+00,  1.68392788e+03,  6.35835147e-01,
        1.68392788e+03, -6.35835147e-01, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00]), 2, array([-1.00000000e+00, -1.00000000e+00,  1.69840508e+03,  6.29558166e-01,
        1.69840508e+03, -6.29558166e-01, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00]))
(0.2, array([-1.00000000e+00, -1.00000000e+00,  1.69840508e+03,  6.29558166e-01,
        1.69840508e+03, -6.29558166e-01, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00]), 2, array([-1.00000000e+00, -1.00000000e+00,  1.72270518e+03,  6.19320968e-01,
        1.72270518e+03, -6.19320968e-01, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00]))
(0.2, array([-1.00000000e+00, -1.00000000e+00,  1.72270518e+03,  6.19320968e-01,
        1.72270518e+03, -6.19320968e-01, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00]), 2, array([-1.00000000e+00, -1.00000000e+00,  1.74722803e+03,  6.09350699e-01,
        1.74722803e+03, -6.09350699e-01, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,
       -1.00000000e+00, -1.00000000e+00]))
14 1 14

 ===== Epoch 1	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.33980566  0.3350367
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.35374975  0.46647775
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 5
train:	 Loss = 1.8552,	 Acc = 0.2554,	 Loss Con1 = 0.1945,	 Loss Con2 = 0.1910
3164 0.163
3142 0.254
2597 0.28
1322 0.31
891 0.321
761 0.346
71 0.592
20 0.65
0.28861880963198544
0.0
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 1
val:	 Loss = 1.6914,	 Acc = 0.3637,	 Loss Con1 = 0.1011,	 Loss Con2 = 0.0951
745 0.122
668 0.392
714 0.546
562 0.422
190 0.305
103 0.35
11 0.909
7 1.0
0.4434589800443459
0.4434589800443459

 ===== Epoch 2	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.20797274  1.268008
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.17792141  1.332614
 -0.45947683 -0.42555502] 2 4
train:	 Loss = 1.5237,	 Acc = 0.4439,	 Loss Con1 = 0.0808,	 Loss Con2 = 0.0777
3163 0.181
3142 0.513
2598 0.543
1322 0.548
891 0.569
762 0.55
71 0.718
19 0.842
0.5383304940374787
0.4434589800443459
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.4308,	 Acc = 0.5333,	 Loss Con1 = 0.0776,	 Loss Con2 = 0.0735
745 0.219
668 0.591
714 0.711
562 0.593
190 0.658
103 0.563
11 1.0
7 1.0
0.637250554323725
0.637250554323725

 ===== Epoch 3	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.42860267  1.6210387
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.44505218  1.6157932
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 0
train:	 Loss = 1.3739,	 Acc = 0.5375,	 Loss Con1 = 0.0747,	 Loss Con2 = 0.0706
3162 0.163
3145 0.616
2597 0.688
1320 0.698
891 0.706
762 0.748
71 0.789
20 0.9
0.6721553486259368
0.637250554323725
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.3184,	 Acc = 0.6290,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0726
745 0.219
668 0.642
714 0.839
562 0.801
190 0.742
103 0.845
11 1.0
7 1.0
0.7645232815964523
0.7645232815964523

 ===== Epoch 4	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 0
train:	 Loss = 1.2862,	 Acc = 0.5942,	 Loss Con1 = 0.0742,	 Loss Con2 = 0.0730
3161 0.159
3143 0.671
2597 0.799
1324 0.789
891 0.78
761 0.799
71 0.845
20 0.75
0.7501987055751107
0.7645232815964523
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.2465,	 Acc = 0.6333,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0777
745 0.215
668 0.681
714 0.843
562 0.788
190 0.721
103 0.825
11 1.0
7 1.0
0.7716186252771619
0.7716186252771619

 ===== Epoch 5	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 0
train:	 Loss = 1.2219,	 Acc = 0.6171,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0739
3165 0.159
3144 0.716
2596 0.824
1320 0.817
889 0.807
763 0.811
71 0.845
20 0.85
0.781892536635238
0.7716186252771619
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.2020,	 Acc = 0.6380,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0757
745 0.216
668 0.693
714 0.85
562 0.795
190 0.711
103 0.816
11 1.0
7 0.857
0.7773835920177383
0.7773835920177383

 ===== Epoch 6	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 0
train:	 Loss = 1.1951,	 Acc = 0.6214,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0732
3162 0.157
3144 0.718
2599 0.828
1321 0.836
891 0.811
760 0.82
71 0.873
20 0.85
0.7880990233931411
0.7773835920177383
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1775,	 Acc = 0.6477,	 Loss Con1 = 0.0721,	 Loss Con2 = 0.0700
745 0.216
668 0.723
714 0.849
562 0.794
190 0.758
103 0.825
11 1.0
7 1.0
0.7902439024390244
0.7902439024390244

 ===== Epoch 7	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.1744,	 Acc = 0.6311,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0721
3164 0.154
3144 0.739
2595 0.844
1322 0.846
892 0.818
760 0.828
71 0.845
20 0.85
0.8025897319400273
0.7902439024390244
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1684,	 Acc = 0.6370,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0734
745 0.216
668 0.701
714 0.824
562 0.801
190 0.758
103 0.806
11 1.0
7 0.857
0.7760532150776053
0.7902439024390244

 ===== Epoch 8	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.3253155   1.3588175
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.32538375  1.1857842
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 5
train:	 Loss = 1.1560,	 Acc = 0.6334,	 Loss Con1 = 0.0743,	 Loss Con2 = 0.0713
3160 0.157
3145 0.736
2597 0.846
1324 0.854
891 0.824
760 0.829
71 0.873
20 0.85
0.804268846503179
0.7902439024390244
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1354,	 Acc = 0.6507,	 Loss Con1 = 0.0742,	 Loss Con2 = 0.0767
745 0.219
668 0.723
714 0.856
562 0.802
190 0.732
103 0.845
11 1.0
7 1.0
0.7933481152993348
0.7933481152993348

 ===== Epoch 9	 =====
[-0.4557189  -0.49292567  1.1770884   0.84733254 -0.6348712  -0.6508424
  2.247853    2.7816825  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.1768732   1.0190911  -0.6347739  -0.6507814
  2.2476392   2.986521   -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.1437,	 Acc = 0.6380,	 Loss Con1 = 0.0742,	 Loss Con2 = 0.0709
3160 0.153
3143 0.747
2596 0.85
1324 0.86
892 0.828
762 0.843
71 0.873
20 0.8
0.8118755676657584
0.7933481152993348
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1348,	 Acc = 0.6550,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0711
745 0.215
668 0.726
714 0.857
562 0.82
190 0.758
103 0.825
11 1.0
7 1.0
0.8004434589800443
0.8004434589800443

 ===== Epoch 10	 =====
[-0.4557189  -0.49292567  1.0644884   1.5428766  -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0641046   1.3718281  -0.6347739  -0.6507814
  2.7365165   3.1477957  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 5
train:	 Loss = 1.1306,	 Acc = 0.6414,	 Loss Con1 = 0.0743,	 Loss Con2 = 0.0710
3158 0.153
3144 0.758
2601 0.854
1320 0.855
893 0.83
761 0.845
71 0.873
20 0.85
0.8164585698070375
0.8004434589800443
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1424,	 Acc = 0.6537,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0706
745 0.213
668 0.732
714 0.85
562 0.808
190 0.763
103 0.864
11 1.0
7 1.0
0.7991130820399113
0.8004434589800443

 ===== Epoch 11	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
  1.0432359   0.34691787 -0.46656546 -0.4823711   1.0401244   3.1424687
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
  1.0219512   0.39086312 -0.46656546 -0.4823711   1.0581881   3.1798346
 -0.45947683 -0.42555502] 4 4
train:	 Loss = 1.1234,	 Acc = 0.6426,	 Loss Con1 = 0.0743,	 Loss Con2 = 0.0713
3162 0.155
3146 0.756
2595 0.86
1323 0.853
890 0.827
762 0.856
70 0.871
20 0.7
0.8178514649102885
0.8004434589800443
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1250,	 Acc = 0.6567,	 Loss Con1 = 0.0746,	 Loss Con2 = 0.0741
745 0.219
668 0.744
714 0.846
562 0.824
190 0.737
103 0.825
11 1.0
7 1.0
0.801330376940133
0.801330376940133

 ===== Epoch 12	 =====
[ 0.06550322  0.7254068  -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013  1.2277241   1.5210736  -0.4178274  -0.43225467
  1.9670708   0.22394466] [ 0.05055746  0.8815442  -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355  1.2258189   1.5689956  -0.4178274  -0.43225467
  1.9467435   0.24615945] 4 4
train:	 Loss = 1.1146,	 Acc = 0.6461,	 Loss Con1 = 0.0748,	 Loss Con2 = 0.0722
3161 0.155
3142 0.762
2596 0.857
1325 0.86
892 0.84
761 0.858
71 0.873
20 0.85
0.822186896786647
0.801330376940133
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1451,	 Acc = 0.6467,	 Loss Con1 = 0.0721,	 Loss Con2 = 0.0738
745 0.219
668 0.713
714 0.838
562 0.811
190 0.758
103 0.835
11 0.909
7 1.0
0.7880266075388027
0.801330376940133

 ===== Epoch 13	 =====
[-0.4557189  -0.49292567  1.206008    2.0766716   1.1569813   0.21537916
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.2299104   2.0633593   1.1810403   0.2307275
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.1148,	 Acc = 0.6442,	 Loss Con1 = 0.0743,	 Loss Con2 = 0.0744
3162 0.156
3145 0.758
2599 0.858
1323 0.863
889 0.827
760 0.851
70 0.9
20 0.85
0.819668407903702
0.801330376940133
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1094,	 Acc = 0.6557,	 Loss Con1 = 0.0718,	 Loss Con2 = 0.0694
745 0.217
668 0.732
714 0.859
562 0.819
190 0.737
103 0.835
11 0.909
7 1.0
0.8004434589800443
0.801330376940133

 ===== Epoch 14	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.60070604  2.5828953
 -0.43886673 -0.47319013  0.69478583  0.08036463 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.57944745  2.61099
 -0.4389609  -0.47327355  0.6668896   0.03220162 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.1084,	 Acc = 0.6468,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0706
3164 0.155
3137 0.767
2599 0.858
1324 0.859
893 0.837
761 0.859
70 0.857
20 0.8
0.8234893230349841
0.801330376940133
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1143,	 Acc = 0.6630,	 Loss Con1 = 0.0723,	 Loss Con2 = 0.0757
745 0.219
668 0.762
714 0.854
562 0.822
190 0.758
103 0.816
11 0.909
7 1.0
0.8097560975609757
0.8097560975609757

 ===== Epoch 15	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711   0.9545634   1.8005897
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711   0.9545634   1.5799886
 -0.45947683 -0.42555502] 5 5
train:	 Loss = 1.1083,	 Acc = 0.6485,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0719
3157 0.156
3144 0.77
2597 0.858
1325 0.866
892 0.832
762 0.856
71 0.901
20 0.8
0.8249914879128363
0.8097560975609757
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1163,	 Acc = 0.6540,	 Loss Con1 = 0.0725,	 Loss Con2 = 0.0713
745 0.217
668 0.717
714 0.86
562 0.826
190 0.747
103 0.816
11 0.909
7 1.0
0.7982261640798226
0.8097560975609757

 ===== Epoch 16	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.5792098   0.0442372
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.5791113   0.23542711
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0973,	 Acc = 0.6483,	 Loss Con1 = 0.0745,	 Loss Con2 = 0.0711
3159 0.155
3147 0.772
2597 0.859
1323 0.86
891 0.828
761 0.863
70 0.843
20 0.85
0.825178794414803
0.8097560975609757
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1327,	 Acc = 0.6483,	 Loss Con1 = 0.0728,	 Loss Con2 = 0.0702
745 0.219
668 0.716
714 0.846
562 0.81
190 0.747
103 0.835
11 0.909
7 1.0
0.7902439024390244
0.8097560975609757

 ===== Epoch 17	 =====
[ 0.779719    1.4705817   1.9074578   0.670337   -0.6348712  -0.6508424
  1.1915293   1.6561689  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 0.7693019   1.4197508   1.9050633   0.6557603  -0.6347739  -0.6507814
  1.179773    1.6220633  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 3
train:	 Loss = 1.0984,	 Acc = 0.6475,	 Loss Con1 = 0.0745,	 Loss Con2 = 0.0727
3165 0.156
3143 0.771
2595 0.862
1321 0.855
891 0.827
762 0.853
71 0.887
20 0.9
0.8242644552993298
0.8097560975609757
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1013,	 Acc = 0.6487,	 Loss Con1 = 0.0728,	 Loss Con2 = 0.0717
745 0.216
668 0.719
714 0.843
562 0.82
190 0.732
103 0.835
11 0.909
7 1.0
0.7915742793791575
0.8097560975609757

 ===== Epoch 18	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.40527347  2.696682
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.1042,	 Acc = 0.6456,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0717
3166 0.153
3139 0.769
2599 0.86
1325 0.853
888 0.829
760 0.853
71 0.915
20 0.8
0.8227675528289026
0.8097560975609757
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1006,	 Acc = 0.6530,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0707
745 0.216
668 0.719
714 0.86
562 0.817
190 0.753
103 0.825
11 0.909
7 1.0
0.797339246119734
0.8097560975609757

 ===== Epoch 19	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.27597627  0.6979795
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.28748828  1.164202
 -0.45947683 -0.42555502] 4 6
train:	 Loss = 1.0920,	 Acc = 0.6493,	 Loss Con1 = 0.0746,	 Loss Con2 = 0.0717
3163 0.156
3148 0.772
2591 0.861
1322 0.864
891 0.829
762 0.86
71 0.887
20 0.85
0.8265758091993186
0.8097560975609757
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1024,	 Acc = 0.6537,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0707
745 0.217
668 0.725
714 0.849
562 0.819
190 0.768
103 0.835
11 0.909
7 1.0
0.7977827050997782
0.8097560975609757

 ===== Epoch 20	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
  2.0026352   1.258108   -0.46656546 -0.4823711   2.4910612   2.5646875
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
  2.002418    1.462934   -0.46656546 -0.4823711   2.4910612   2.7852883
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0925,	 Acc = 0.6478,	 Loss Con1 = 0.0742,	 Loss Con2 = 0.0715
3160 0.155
3149 0.772
2596 0.852
1323 0.861
888 0.832
761 0.867
71 0.901
20 0.85
0.8247048138056312
0.8097560975609757
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1183,	 Acc = 0.6510,	 Loss Con1 = 0.0724,	 Loss Con2 = 0.0716
745 0.219
668 0.708
714 0.863
562 0.811
190 0.753
103 0.816
11 1.0
7 1.0
0.7937915742793792
0.8097560975609757

 ===== Epoch 21	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 0
train:	 Loss = 1.0880,	 Acc = 0.6497,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0719
3164 0.155
3145 0.772
2597 0.862
1321 0.864
892 0.837
758 0.858
71 0.887
20 0.85
0.8275783734666061
0.8097560975609757
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1178,	 Acc = 0.6447,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0711
745 0.215
668 0.683
714 0.84
562 0.829
190 0.779
103 0.845
11 0.909
7 1.0
0.7866962305986697
0.8097560975609757

 ===== Epoch 22	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  1.7914023   1.2672459
 -0.43886673 -0.47319013  2.0117328   0.36075985 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  1.7918122   1.2892954
 -0.4389609  -0.47327355  1.9902978   0.38795537 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 4
train:	 Loss = 1.0900,	 Acc = 0.6467,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0708
3166 0.156
3144 0.766
2593 0.86
1324 0.86
890 0.83
760 0.859
71 0.901
20 0.8
0.8233356055441945
0.8097560975609757
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1006,	 Acc = 0.6593,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0697
745 0.216
668 0.729
714 0.867
562 0.822
190 0.763
103 0.845
11 0.909
7 1.0
0.8057649667405765
0.8097560975609757

 ===== Epoch 23	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 0
train:	 Loss = 1.0913,	 Acc = 0.6481,	 Loss Con1 = 0.0743,	 Loss Con2 = 0.0716
3164 0.156
3148 0.77
2593 0.862
1322 0.861
890 0.828
760 0.854
71 0.887
20 0.8
0.8249659245797365
0.8097560975609757
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1056,	 Acc = 0.6517,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0731
745 0.219
668 0.71
714 0.842
562 0.827
190 0.779
103 0.845
11 0.909
7 1.0
0.7946784922394678
0.8097560975609757

 ===== Epoch 24	 =====
[ 1.4608207   2.1215396   0.77351093 -0.00855731 -0.6348712  -0.6508424
  1.8839266   2.0901845  -0.46656546 -0.4823711   2.6671333   3.2013755
 -0.45947683 -0.42555502] [ 1.4608207   2.2437243   0.7733604   0.09444319 -0.6347739  -0.6507814
  1.8837152   2.2130144  -0.46656546 -0.4823711   2.6671333   3.3337364
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0842,	 Acc = 0.6515,	 Loss Con1 = 0.0745,	 Loss Con2 = 0.0723
3155 0.156
3148 0.776
2596 0.859
1326 0.867
891 0.837
761 0.866
71 0.873
20 0.75
0.828889141041643
0.8097560975609757
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1132,	 Acc = 0.6647,	 Loss Con1 = 0.0721,	 Loss Con2 = 0.0726
745 0.219
668 0.784
714 0.852
562 0.813
190 0.753
103 0.796
11 0.909
7 1.0
0.8119733924611974
0.8119733924611974

 ===== Epoch 25	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 0
train:	 Loss = 1.0861,	 Acc = 0.6522,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0732
3162 0.155
3145 0.783
2598 0.86
1321 0.866
890 0.835
761 0.861
71 0.887
20 0.85
0.8307971837383602
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1049,	 Acc = 0.6497,	 Loss Con1 = 0.0729,	 Loss Con2 = 0.0730
745 0.217
668 0.696
714 0.87
562 0.813
190 0.742
103 0.835
11 0.909
7 1.0
0.7924611973392461
0.8119733924611974

 ===== Epoch 26	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  1.7940514   1.350111
 -0.43886673 -0.47319013  1.9331406   0.4656768  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  1.8053654   1.3497349
 -0.4389609  -0.47327355  1.9460794   0.47278288 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0845,	 Acc = 0.6496,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0721
3163 0.155
3141 0.776
2598 0.862
1324 0.859
891 0.825
760 0.863
71 0.901
20 0.8
0.8272572402044293
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0912,	 Acc = 0.6567,	 Loss Con1 = 0.0758,	 Loss Con2 = 0.0733
745 0.217
668 0.711
714 0.873
562 0.82
190 0.768
103 0.835
11 0.909
7 1.0
0.8017738359201774
0.8119733924611974

 ===== Epoch 27	 =====
[ 0.6290546   0.73271173 -0.5993768  -0.57551634  2.223712    2.5672488
 -0.43886673 -0.47319013  2.325997    2.0965517  -0.4178274  -0.43225467
  1.8206809   0.7256812 ] [ 0.62905294  0.9363491  -0.59937984 -0.57549053  2.2238712   2.7584047
 -0.4389609  -0.47327355  2.3259945   2.3099852  -0.4178274  -0.43225467
  1.8206798   0.95125616] 6 6
train:	 Loss = 1.0847,	 Acc = 0.6500,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0710
3163 0.155
3146 0.776
2594 0.857
1322 0.866
892 0.836
760 0.861
71 0.873
20 0.85
0.8277115275411698
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1370,	 Acc = 0.6440,	 Loss Con1 = 0.0759,	 Loss Con2 = 0.0738
745 0.219
668 0.702
714 0.846
562 0.801
190 0.758
103 0.825
11 0.909
7 1.0
0.7844789356984478
0.8119733924611974

 ===== Epoch 28	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 0
train:	 Loss = 1.0799,	 Acc = 0.6514,	 Loss Con1 = 0.0743,	 Loss Con2 = 0.0717
3159 0.155
3142 0.779
2601 0.861
1323 0.864
890 0.831
762 0.864
71 0.873
20 0.85
0.8293790441593825
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1245,	 Acc = 0.6477,	 Loss Con1 = 0.0725,	 Loss Con2 = 0.0712
745 0.219
668 0.699
714 0.85
562 0.811
190 0.8
103 0.786
11 0.909
7 1.0
0.7893569844789357
0.8119733924611974

 ===== Epoch 29	 =====
[ 0.4247236   0.17165276  1.6860224   0.35022646 -0.6348712  -0.6508424
  0.7622843   0.893161   -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 0.4347733   0.1007153   1.6877058   0.33417007 -0.6347739  -0.6507814
  0.76124686  0.8430094  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 3
train:	 Loss = 1.0829,	 Acc = 0.6507,	 Loss Con1 = 0.0743,	 Loss Con2 = 0.0718
3164 0.155
3144 0.778
2597 0.859
1320 0.864
890 0.83
762 0.866
71 0.901
20 0.85
0.8287142208087233
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1077,	 Acc = 0.6490,	 Loss Con1 = 0.0730,	 Loss Con2 = 0.0720
745 0.219
668 0.695
714 0.856
562 0.835
190 0.742
103 0.796
11 0.909
7 1.0
0.7911308203991131
0.8119733924611974

 ===== Epoch 30	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  1.3318295   1.6724558
 -0.43886673 -0.47319013  0.384967    2.8669226  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  1.3261868   1.6458704
 -0.4389609  -0.47327355  0.36508262  2.7845469  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0784,	 Acc = 0.6517,	 Loss Con1 = 0.0742,	 Loss Con2 = 0.0723
3161 0.157
3146 0.779
2598 0.858
1320 0.864
890 0.838
762 0.862
71 0.887
20 0.9
0.8293402974906324
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1131,	 Acc = 0.6467,	 Loss Con1 = 0.0724,	 Loss Con2 = 0.0723
745 0.217
668 0.714
714 0.854
562 0.806
190 0.716
103 0.825
11 0.909
7 1.0
0.788470066518847
0.8119733924611974

 ===== Epoch 31	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.37304124  2.2648158
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.3729381   2.2648373
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0784,	 Acc = 0.6525,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0718
3162 0.156
3140 0.781
2597 0.861
1325 0.866
891 0.834
762 0.86
71 0.887
20 0.85
0.8306836248012719
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0874,	 Acc = 0.6523,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0751
745 0.219
668 0.711
714 0.86
562 0.819
190 0.742
103 0.845
11 0.909
7 1.0
0.7955654101995565
0.8119733924611974

 ===== Epoch 32	 =====
[ 1.2847596   3.1370246   1.8206869   1.2628225   1.3894843  -0.23206039
  1.5921925   2.8883271  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 1.2729504   3.1229727   1.8196381   1.255154    1.3975084  -0.23947369
  1.5829529   2.8758075  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0784,	 Acc = 0.6527,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0713
3160 0.154
3141 0.782
2598 0.864
1324 0.862
891 0.836
763 0.862
71 0.887
20 0.9
0.8315168029064487
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0970,	 Acc = 0.6510,	 Loss Con1 = 0.0732,	 Loss Con2 = 0.0713
745 0.217
668 0.719
714 0.859
562 0.817
190 0.737
103 0.796
11 0.909
7 1.0
0.7942350332594235
0.8119733924611974

 ===== Epoch 33	 =====
[-0.4557189  -0.49292567  0.9635676   2.3460271   1.9494336   1.0862036
 -0.08947364  1.2566566   2.3699758   0.24101704 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  0.94228977  2.3667765   1.9219214   1.0844753
 -0.1268833   1.2193456   2.3400853   0.22349459 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.0769,	 Acc = 0.6521,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0705
3166 0.156
3142 0.78
2597 0.861
1323 0.864
888 0.836
761 0.866
71 0.887
20 0.9
0.8306066802999318
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1060,	 Acc = 0.6437,	 Loss Con1 = 0.0726,	 Loss Con2 = 0.0732
745 0.216
668 0.69
714 0.853
562 0.822
190 0.721
103 0.816
11 0.909
7 1.0
0.7849223946784922
0.8119733924611974

 ===== Epoch 34	 =====
[ 0.40499777  2.002576   -0.5993768  -0.57551634 -0.6348712  -0.6508424
  2.0983074   0.6264275  -0.46656546 -0.4823711   2.4480205   1.9501948
 -0.45947683 -0.42555502] [ 0.39659154  1.9045248  -0.59937984 -0.57549053 -0.6347739  -0.6507814
  2.1153004   0.59903145 -0.46656546 -0.4823711   2.4457307   1.9266069
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0773,	 Acc = 0.6528,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0715
3164 0.154
3143 0.781
2594 0.861
1324 0.865
890 0.843
763 0.869
70 0.871
20 0.9
0.8320081781008632
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0769,	 Acc = 0.6570,	 Loss Con1 = 0.0728,	 Loss Con2 = 0.0734
745 0.217
668 0.726
714 0.868
562 0.819
190 0.742
103 0.835
11 0.909
7 1.0
0.8022172949002218
0.8119733924611974

 ===== Epoch 35	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 0
train:	 Loss = 1.0737,	 Acc = 0.6552,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0724
3161 0.155
3142 0.789
2600 0.863
1323 0.86
889 0.843
762 0.867
71 0.901
20 0.9
0.8347905075508119
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1172,	 Acc = 0.6523,	 Loss Con1 = 0.0726,	 Loss Con2 = 0.0760
745 0.219
668 0.72
714 0.854
562 0.811
190 0.779
103 0.796
11 0.909
7 1.0
0.7955654101995565
0.8119733924611974

 ===== Epoch 36	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.25879735  1.1474074
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.2700699   1.2635248
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 6
train:	 Loss = 1.0762,	 Acc = 0.6525,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0713
3164 0.155
3145 0.782
2596 0.862
1319 0.863
891 0.837
762 0.861
71 0.887
20 0.85
0.8310995002271695
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1024,	 Acc = 0.6527,	 Loss Con1 = 0.0745,	 Loss Con2 = 0.0731
745 0.219
668 0.723
714 0.859
562 0.819
190 0.737
103 0.796
11 0.909
7 1.0
0.7960088691796009
0.8119733924611974

 ===== Epoch 37	 =====
[ 0.5873445   2.0890615  -0.5993768  -0.57551634  1.5325785   2.1438532
 -0.43886673 -0.47319013  1.538982    1.1604689  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 0.6279207   2.0681317  -0.59937984 -0.57549053  1.5577664   2.1330132
 -0.4389609  -0.47327355  1.5760356   1.1695472  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0773,	 Acc = 0.6509,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0725
3167 0.156
3145 0.776
2587 0.858
1325 0.866
892 0.84
761 0.862
71 0.93
20 0.85
0.8289967049198955
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1056,	 Acc = 0.6513,	 Loss Con1 = 0.0725,	 Loss Con2 = 0.0713
745 0.219
668 0.714
714 0.857
562 0.815
190 0.763
103 0.796
11 0.909
7 1.0
0.7942350332594235
0.8119733924611974

 ===== Epoch 38	 =====
[ 0.41794193  1.3145452   1.6830065   0.59446883 -0.6348712  -0.6508424
  0.8588969   1.5998719  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 0.3762026   1.3029867   1.6560384   0.58797944 -0.6347739  -0.6507814
  0.8207377   1.6004559  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.0762,	 Acc = 0.6514,	 Loss Con1 = 0.0743,	 Loss Con2 = 0.0732
3164 0.155
3144 0.78
2599 0.86
1318 0.864
890 0.834
762 0.862
71 0.901
20 0.9
0.8299636528850522
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0924,	 Acc = 0.6483,	 Loss Con1 = 0.0730,	 Loss Con2 = 0.0727
745 0.217
668 0.707
714 0.85
562 0.817
190 0.758
103 0.825
11 0.818
7 1.0
0.7906873614190687
0.8119733924611974

 ===== Epoch 39	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
  0.97288543  1.3890399 ] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
  0.99984926  1.3898273 ] 2 2
train:	 Loss = 1.0734,	 Acc = 0.6526,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0725
3167 0.156
3141 0.781
2596 0.861
1324 0.858
891 0.838
759 0.874
70 0.914
20 0.9
0.8313827974093853
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0842,	 Acc = 0.6593,	 Loss Con1 = 0.0721,	 Loss Con2 = 0.0710
745 0.217
668 0.722
714 0.868
562 0.829
190 0.774
103 0.816
11 0.909
7 1.0
0.8053215077605321
0.8119733924611974

 ===== Epoch 40	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 0
train:	 Loss = 1.0723,	 Acc = 0.6550,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0720
3162 0.154
3142 0.786
2596 0.863
1322 0.867
893 0.839
762 0.867
71 0.915
20 0.9
0.8347717465364524
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0811,	 Acc = 0.6510,	 Loss Con1 = 0.0721,	 Loss Con2 = 0.0702
745 0.217
668 0.71
714 0.868
562 0.811
190 0.737
103 0.816
11 0.909
7 1.0
0.7942350332594235
0.8119733924611974

 ===== Epoch 41	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  1.2725482   1.9269655
 -0.43886673 -0.47319013  0.92928195  0.6975641  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  1.2824128   1.9531839
 -0.4389609  -0.47327355  0.9132592   0.7506766  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 4
train:	 Loss = 1.0742,	 Acc = 0.6527,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0742
3164 0.155
3145 0.785
2595 0.86
1324 0.865
890 0.836
760 0.863
70 0.857
20 0.9
0.8317810086324398
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0946,	 Acc = 0.6520,	 Loss Con1 = 0.0727,	 Loss Con2 = 0.0740
745 0.219
668 0.731
714 0.852
562 0.817
190 0.732
103 0.796
11 0.909
7 1.0
0.7951219512195122
0.8119733924611974

 ===== Epoch 42	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.9668256   2.618399
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0682,	 Acc = 0.6555,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0731
3162 0.156
3143 0.787
2592 0.864
1325 0.864
893 0.835
762 0.873
71 0.915
20 0.85
0.8347717465364524
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1064,	 Acc = 0.6483,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0733
745 0.219
668 0.692
714 0.866
562 0.811
190 0.747
103 0.845
11 1.0
7 0.857
0.7902439024390244
0.8119733924611974

 ===== Epoch 43	 =====
[ 1.8727903   1.3023603  -0.5993768  -0.57551634 -0.6348712  -0.6508424
  0.3697518   2.5342557   2.8775828   2.7496073   1.2879736   0.3404242
  2.7253735   1.8317134 ] [ 1.831072    1.2979374  -0.59937984 -0.57549053 -0.6347739  -0.6507814
  0.3358803   2.5794759   2.8445163   2.7616735   1.2636273   0.31603768
  2.6940846   1.8317283 ] 1 1
train:	 Loss = 1.0672,	 Acc = 0.6522,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0725
3161 0.158
3141 0.78
2597 0.861
1324 0.861
892 0.836
762 0.86
71 0.873
20 0.9
0.8296809356193937
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1121,	 Acc = 0.6523,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0728
745 0.219
668 0.702
714 0.861
562 0.824
190 0.768
103 0.816
11 0.909
7 1.0
0.7955654101995565
0.8119733924611974

 ===== Epoch 44	 =====
[-0.4557189  -0.49292567  0.30365536  1.0783008  -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  0.27430114  1.0762639  -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.0731,	 Acc = 0.6531,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0717
3163 0.155
3142 0.78
2597 0.861
1322 0.866
892 0.848
762 0.867
70 0.871
20 0.85
0.8321408290743896
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0975,	 Acc = 0.6543,	 Loss Con1 = 0.0734,	 Loss Con2 = 0.0763
745 0.219
668 0.722
714 0.866
562 0.822
190 0.732
103 0.806
11 0.909
7 0.857
0.7982261640798226
0.8119733924611974

 ===== Epoch 45	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.30670232  1.7752659
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.3068206   1.660611
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 3
train:	 Loss = 1.0723,	 Acc = 0.6499,	 Loss Con1 = 0.0742,	 Loss Con2 = 0.0723
3163 0.154
3146 0.778
2595 0.859
1322 0.862
892 0.835
760 0.861
71 0.845
19 0.842
0.82793867120954
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0955,	 Acc = 0.6563,	 Loss Con1 = 0.0743,	 Loss Con2 = 0.0731
745 0.219
668 0.741
714 0.859
562 0.811
190 0.742
103 0.825
11 0.909
7 0.857
0.8008869179600887
0.8119733924611974

 ===== Epoch 46	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
  1.3075502   2.82412   ] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
  1.3075502   2.9594657 ] 5 6
train:	 Loss = 1.0714,	 Acc = 0.6540,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0725
3163 0.155
3144 0.786
2597 0.863
1321 0.862
890 0.837
762 0.866
71 0.915
20 0.85
0.8331629755820557
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0910,	 Acc = 0.6477,	 Loss Con1 = 0.0724,	 Loss Con2 = 0.0727
745 0.216
668 0.699
714 0.866
562 0.813
190 0.732
103 0.806
11 1.0
7 1.0
0.7902439024390244
0.8119733924611974

 ===== Epoch 47	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.16213782  1.6264461  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.16224596  1.8312644  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0650,	 Acc = 0.6534,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0718
3161 0.155
3145 0.787
2594 0.86
1325 0.861
892 0.837
760 0.864
71 0.901
20 0.85
0.832292494606563
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1041,	 Acc = 0.6557,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0784
745 0.219
668 0.722
714 0.861
562 0.829
190 0.721
103 0.845
11 1.0
7 0.857
0.8
0.8119733924611974

 ===== Epoch 48	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.45988256  1.1510466
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.4628728   1.1010793
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0662,	 Acc = 0.6543,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0724
3163 0.155
3142 0.79
2598 0.859
1320 0.863
892 0.837
762 0.866
71 0.901
20 0.9
0.8336172629187961
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1024,	 Acc = 0.6433,	 Loss Con1 = 0.0730,	 Loss Con2 = 0.0716
745 0.215
668 0.695
714 0.854
562 0.817
190 0.716
103 0.806
11 1.0
7 1.0
0.7849223946784922
0.8119733924611974

 ===== Epoch 49	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
  0.9182326   1.1213099 ] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
  0.9182326   1.3468866 ] 6 6
train:	 Loss = 1.0681,	 Acc = 0.6541,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0722
3166 0.155
3138 0.787
2597 0.862
1321 0.865
893 0.837
762 0.866
71 0.901
20 0.8
0.8336741649625086
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0783,	 Acc = 0.6477,	 Loss Con1 = 0.0729,	 Loss Con2 = 0.0770
745 0.217
668 0.692
714 0.866
562 0.811
190 0.737
103 0.845
11 1.0
7 1.0
0.78980044345898
0.8119733924611974

 ===== Epoch 50	 =====
[ 2.7699444   2.90672     1.9139792   0.6408532  -0.6348712  -0.6508424
  2.6248162   2.1881113  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 2.7440405   2.8857403   1.9219141   0.62270963 -0.6347739  -0.6507814
  2.6136074   2.1635752  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0692,	 Acc = 0.6517,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0729
3160 0.154
3144 0.779
2596 0.861
1324 0.86
892 0.839
763 0.866
70 0.871
19 0.895
0.8300408719346049
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1024,	 Acc = 0.6477,	 Loss Con1 = 0.0747,	 Loss Con2 = 0.0755
745 0.216
668 0.699
714 0.86
562 0.815
190 0.737
103 0.845
11 0.909
7 0.857
0.7902439024390244
0.8119733924611974

 ===== Epoch 51	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  1.1205639   2.057806
 -0.43886673 -0.47319013  0.3082753   0.92771816 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  1.1462708   2.045683
 -0.4389609  -0.47327355  0.34423232  0.9610952  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0689,	 Acc = 0.6537,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0713
3161 0.156
3144 0.784
2597 0.863
1323 0.867
890 0.835
762 0.864
71 0.887
20 0.8
0.8325195866924038
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0870,	 Acc = 0.6557,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0747
745 0.219
668 0.747
714 0.854
562 0.811
190 0.726
103 0.816
11 0.909
7 1.0
0.8
0.8119733924611974

 ===== Epoch 52	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.22746687 -0.1399921
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.23837654 -0.07970592
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
train:	 Loss = 1.0713,	 Acc = 0.6530,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0718
3162 0.157
3144 0.789
2595 0.857
1323 0.862
891 0.829
762 0.854
71 0.901
20 0.9
0.8309107426754485
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0827,	 Acc = 0.6547,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0712
745 0.219
668 0.732
714 0.857
562 0.815
190 0.763
103 0.786
11 0.909
7 0.857
0.798669623059867
0.8119733924611974

 ===== Epoch 53	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 0
train:	 Loss = 1.0653,	 Acc = 0.6548,	 Loss Con1 = 0.0742,	 Loss Con2 = 0.0732
3159 0.156
3148 0.785
2597 0.862
1322 0.868
889 0.837
762 0.867
71 0.901
20 0.9
0.8338063344306959
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1149,	 Acc = 0.6447,	 Loss Con1 = 0.0734,	 Loss Con2 = 0.0704
745 0.219
668 0.683
714 0.85
562 0.819
190 0.784
103 0.806
11 0.909
7 0.857
0.7853658536585366
0.8119733924611974

 ===== Epoch 54	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 0
train:	 Loss = 1.0652,	 Acc = 0.6527,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0721
3164 0.154
3145 0.785
2596 0.862
1324 0.862
891 0.837
757 0.861
71 0.887
20 0.85
0.8318945933666515
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0967,	 Acc = 0.6460,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0731
745 0.215
668 0.689
714 0.86
562 0.824
190 0.747
103 0.816
11 0.909
7 0.714
0.788470066518847
0.8119733924611974

 ===== Epoch 55	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.9911512   0.51474035
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.9911013   0.705773
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0709,	 Acc = 0.6527,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0718
3163 0.155
3141 0.784
2598 0.858
1322 0.865
892 0.836
761 0.866
71 0.887
20 0.9
0.8314593980692788
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1146,	 Acc = 0.6507,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0760
745 0.217
668 0.707
714 0.856
562 0.826
190 0.747
103 0.825
11 0.909
7 0.857
0.7937915742793792
0.8119733924611974

 ===== Epoch 56	 =====
[-0.4557189  -0.49292567  1.8628987   1.8087438   1.775344    0.5012988
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.8417661   1.8492849   1.755015    0.5324971
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.0639,	 Acc = 0.6550,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0726
3166 0.155
3141 0.789
2598 0.861
1319 0.865
890 0.844
763 0.866
71 0.915
20 0.85
0.8349238809361509
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0975,	 Acc = 0.6533,	 Loss Con1 = 0.0730,	 Loss Con2 = 0.0711
745 0.217
668 0.716
714 0.861
562 0.815
190 0.753
103 0.854
11 0.909
7 0.857
0.797339246119734
0.8119733924611974

 ===== Epoch 57	 =====
[-0.4557189  -0.49292567  1.1674811   2.0875978  -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.1481706   2.099628   -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.0650,	 Acc = 0.6538,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0710
3162 0.155
3145 0.784
2594 0.862
1322 0.866
892 0.837
762 0.867
71 0.887
20 0.85
0.8329548035430389
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0846,	 Acc = 0.6493,	 Loss Con1 = 0.0721,	 Loss Con2 = 0.0686
745 0.219
668 0.71
714 0.861
562 0.813
190 0.721
103 0.835
11 0.909
7 0.857
0.7915742793791575
0.8119733924611974

 ===== Epoch 58	 =====
[-0.4557189  -0.49292567  1.6331627   0.18509755 -0.6348712  -0.6508424
  1.2621074   1.6996366  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.6566337   0.19657962 -0.6347739  -0.6507814
  1.2996458   1.6970986  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0645,	 Acc = 0.6525,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0706
3163 0.155
3140 0.784
2598 0.858
1321 0.864
893 0.838
762 0.862
71 0.887
20 0.9
0.8311186825667235
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0869,	 Acc = 0.6510,	 Loss Con1 = 0.0730,	 Loss Con2 = 0.0718
745 0.216
668 0.71
714 0.863
562 0.815
190 0.747
103 0.835
11 0.909
7 0.857
0.7946784922394678
0.8119733924611974

 ===== Epoch 59	 =====
[-0.4557189  -0.49292567  1.5480413   1.3228396   2.2960365   0.15288703
  0.5748226   1.515138   -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.5478076   1.4946294   2.296199    0.34407535
  0.5746773   1.7199585  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0628,	 Acc = 0.6539,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0700
3163 0.154
3143 0.788
2596 0.86
1323 0.862
891 0.838
761 0.866
71 0.887
20 0.9
0.8333901192504259
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0965,	 Acc = 0.6493,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0701
745 0.215
668 0.708
714 0.857
562 0.822
190 0.737
103 0.825
11 0.909
7 0.857
0.7929046563192904
0.8119733924611974

 ===== Epoch 60	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013  1.0806879   3.293741   -0.4178274  -0.43225467
  1.517779    1.5071024 ] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355  1.0806967   3.2937293  -0.4178274  -0.43225467
  1.517789    1.507104  ] 0 0
train:	 Loss = 1.0626,	 Acc = 0.6540,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0725
3166 0.155
3142 0.786
2599 0.86
1319 0.864
893 0.847
759 0.862
70 0.9
20 0.9
0.8334469438763917
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0893,	 Acc = 0.6470,	 Loss Con1 = 0.0728,	 Loss Con2 = 0.0688
745 0.217
668 0.701
714 0.868
562 0.811
190 0.7
103 0.825
11 0.909
7 1.0
0.7889135254988914
0.8119733924611974

 ===== Epoch 61	 =====
[-0.4557189  -0.49292567  1.4149683   1.1998411  -0.6348712  -0.6508424
  2.030118    3.174379   -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.4147922   1.3716238  -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0641,	 Acc = 0.6534,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0691
3163 0.155
3144 0.789
2600 0.855
1321 0.865
890 0.837
761 0.863
70 0.9
19 0.895
0.8323679727427598
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0723,	 Acc = 0.6560,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0717
745 0.217
668 0.72
714 0.863
562 0.824
190 0.753
103 0.835
11 0.909
7 1.0
0.8008869179600887
0.8119733924611974

 ===== Epoch 62	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013  1.109555    1.8879429   2.984856    0.48341814
  2.3983932   1.9658844 ] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355  1.0717518   1.8937685   2.9592972   0.47233903
  2.3671596   1.9673847 ] 1 1
train:	 Loss = 1.0567,	 Acc = 0.6565,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0706
3158 0.156
3144 0.793
2598 0.861
1325 0.86
891 0.842
761 0.87
71 0.887
20 0.9
0.8358683314415437
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0825,	 Acc = 0.6547,	 Loss Con1 = 0.0728,	 Loss Con2 = 0.0686
745 0.217
668 0.744
714 0.859
562 0.826
190 0.674
103 0.816
11 0.909
7 0.857
0.7991130820399113
0.8119733924611974

 ===== Epoch 63	 =====
[-0.4557189  -0.49292567  1.1770707   2.0818853  -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.1768768   2.0823     -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0638,	 Acc = 0.6538,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0695
3159 0.156
3143 0.788
2597 0.858
1325 0.861
892 0.837
761 0.863
71 0.887
20 0.85
0.8323305710069248
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0803,	 Acc = 0.6597,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0705
745 0.219
668 0.756
714 0.857
562 0.813
190 0.732
103 0.845
11 0.909
7 0.857
0.8053215077605321
0.8119733924611974

 ===== Epoch 64	 =====
[ 1.8860888   2.183887    2.1094975   0.59595    -0.6348712  -0.6508424
  2.1239583   1.9788147  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 1.886089    2.1838875   2.109203    0.59614736 -0.6347739  -0.6507814
  2.123735    1.9786798  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0614,	 Acc = 0.6555,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0693
3167 0.156
3144 0.794
2592 0.861
1322 0.864
892 0.839
760 0.862
71 0.887
20 0.85
0.8352459947733212
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1142,	 Acc = 0.6503,	 Loss Con1 = 0.0750,	 Loss Con2 = 0.0781
745 0.219
668 0.713
714 0.86
562 0.82
190 0.721
103 0.816
11 0.909
7 0.857
0.7929046563192904
0.8119733924611974

 ===== Epoch 65	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 0
train:	 Loss = 1.0585,	 Acc = 0.6536,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0717
3160 0.155
3146 0.784
2599 0.861
1324 0.864
886 0.842
762 0.858
71 0.887
20 0.9
0.8323115349682108
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0909,	 Acc = 0.6570,	 Loss Con1 = 0.0723,	 Loss Con2 = 0.0707
745 0.217
668 0.728
714 0.867
562 0.822
190 0.732
103 0.845
11 0.909
7 0.857
0.8022172949002218
0.8119733924611974

 ===== Epoch 66	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 0
train:	 Loss = 1.0613,	 Acc = 0.6541,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0698
3164 0.155
3144 0.785
2597 0.857
1320 0.87
892 0.851
760 0.861
71 0.887
20 0.85
0.8332576101771921
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0874,	 Acc = 0.6547,	 Loss Con1 = 0.0728,	 Loss Con2 = 0.0694
745 0.219
668 0.726
714 0.866
562 0.813
190 0.716
103 0.854
11 0.909
7 1.0
0.798669623059867
0.8119733924611974

 ===== Epoch 67	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
  1.3939605   2.7231817 ] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
  1.4239773   2.7079754 ] 2 2
train:	 Loss = 1.0593,	 Acc = 0.6538,	 Loss Con1 = 0.0743,	 Loss Con2 = 0.0720
3164 0.155
3142 0.785
2594 0.861
1323 0.865
893 0.845
762 0.864
71 0.901
19 0.737
0.8332576101771921
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0985,	 Acc = 0.6467,	 Loss Con1 = 0.0726,	 Loss Con2 = 0.0730
745 0.219
668 0.705
714 0.863
562 0.811
190 0.716
103 0.845
11 0.909
7 0.143
0.7880266075388027
0.8119733924611974

 ===== Epoch 68	 =====
[-0.4557189  -0.49292567  1.06432     0.6856556  -0.6348712  -0.6508424
  2.7367945   2.3281255  -0.46656546 -0.4823711   3.401588    3.2098408
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0641382   0.5829741  -0.6347739  -0.6507814
  2.73654     2.2050147  -0.46656546 -0.4823711   3.401588    3.0774803
 -0.45947683 -0.42555502] 0 5
train:	 Loss = 1.0614,	 Acc = 0.6545,	 Loss Con1 = 0.0743,	 Loss Con2 = 0.0724
3159 0.155
3144 0.786
2601 0.86
1321 0.864
891 0.842
761 0.863
71 0.915
20 0.9
0.8334657736405948
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0792,	 Acc = 0.6523,	 Loss Con1 = 0.0723,	 Loss Con2 = 0.0725
745 0.217
668 0.722
714 0.864
562 0.811
190 0.716
103 0.854
11 0.909
7 0.857
0.7960088691796009
0.8119733924611974

 ===== Epoch 69	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 0
train:	 Loss = 1.0554,	 Acc = 0.6550,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0708
3162 0.156
3146 0.79
2596 0.86
1320 0.862
892 0.841
761 0.867
71 0.887
20 0.9
0.834317510788099
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0838,	 Acc = 0.6497,	 Loss Con1 = 0.0726,	 Loss Con2 = 0.0703
745 0.213
668 0.699
714 0.861
562 0.824
190 0.747
103 0.835
11 1.0
7 0.857
0.7937915742793792
0.8119733924611974

 ===== Epoch 70	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.51218367  1.3873185
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.5144963   1.4337559
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 4
train:	 Loss = 1.0606,	 Acc = 0.6543,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0709
3161 0.156
3146 0.787
2597 0.859
1323 0.865
890 0.843
760 0.864
71 0.887
20 0.85
0.8333144089928466
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0944,	 Acc = 0.6463,	 Loss Con1 = 0.0728,	 Loss Con2 = 0.0710
745 0.215
668 0.699
714 0.868
562 0.813
190 0.684
103 0.845
11 1.0
7 1.0
0.7889135254988914
0.8119733924611974

 ===== Epoch 71	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0598,	 Acc = 0.6542,	 Loss Con1 = 0.0744,	 Loss Con2 = 0.0718
3163 0.155
3145 0.789
2594 0.86
1321 0.864
892 0.84
762 0.862
71 0.873
20 0.85
0.8336172629187961
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1003,	 Acc = 0.6450,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0708
745 0.215
668 0.699
714 0.854
562 0.811
190 0.732
103 0.825
11 1.0
7 1.0
0.7871396895787139
0.8119733924611974

 ===== Epoch 72	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  1.1205639   2.057806
 -0.43886673 -0.47319013  0.3082753   0.92771816 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  1.1462708   2.045683
 -0.4389609  -0.47327355  0.34423232  0.9610952  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0585,	 Acc = 0.6533,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0700
3161 0.155
3147 0.79
2601 0.854
1318 0.865
891 0.841
759 0.866
71 0.873
20 0.75
0.8321789485636426
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0787,	 Acc = 0.6543,	 Loss Con1 = 0.0719,	 Loss Con2 = 0.0679
745 0.219
668 0.72
714 0.86
562 0.82
190 0.732
103 0.854
11 1.0
7 0.857
0.7982261640798226
0.8119733924611974

 ===== Epoch 73	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 0
train:	 Loss = 1.0580,	 Acc = 0.6536,	 Loss Con1 = 0.0743,	 Loss Con2 = 0.0703
3164 0.155
3141 0.783
2596 0.861
1323 0.865
892 0.842
761 0.871
71 0.901
20 0.8
0.8328032712403453
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 3
val:	 Loss = 1.0997,	 Acc = 0.6557,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0706
745 0.219
668 0.723
714 0.856
562 0.826
190 0.742
103 0.845
11 1.0
7 1.0
0.8
0.8119733924611974

 ===== Epoch 74	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.20601939  0.82685256 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.18941867  0.55353695 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0573,	 Acc = 0.6530,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0693
3168 0.156
3138 0.781
2595 0.86
1324 0.868
892 0.841
760 0.867
71 0.915
20 0.85
0.8320454545454545
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.0880,	 Acc = 0.6523,	 Loss Con1 = 0.0725,	 Loss Con2 = 0.0686
745 0.216
668 0.692
714 0.867
562 0.833
190 0.758
103 0.835
11 1.0
7 0.857
0.7964523281596453
0.8119733924611974

 ===== Epoch 75	 =====
[ 1.6765342   1.536015   -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013  2.8673635   2.935996    1.0671118   0.45322022
  2.5979693   1.978671  ] [ 1.67652     1.544046   -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355  2.871675    2.9400077   1.0636601   0.4607799
  2.5983872   1.983279  ] 3 4
train:	 Loss = 1.0558,	 Acc = 0.6547,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0702
3163 0.155
3140 0.786
2600 0.863
1322 0.865
891 0.843
761 0.866
71 0.901
20 0.9
0.834412265758092
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0876,	 Acc = 0.6467,	 Loss Con1 = 0.0719,	 Loss Con2 = 0.0714
745 0.215
668 0.689
714 0.86
562 0.82
190 0.747
103 0.845
11 0.909
7 0.857
0.7893569844789357
0.8119733924611974

 ===== Epoch 76	 =====
[-0.4557189  -0.49292567  1.6687448   1.7277441   0.4645546   0.06584893
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.668498    1.7281069   0.4646764   0.06590021
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0543,	 Acc = 0.6547,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0692
3164 0.155
3142 0.792
2596 0.858
1324 0.866
892 0.841
759 0.866
71 0.887
20 0.8
0.8345070422535211
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0824,	 Acc = 0.6480,	 Loss Con1 = 0.0734,	 Loss Con2 = 0.0742
745 0.213
668 0.698
714 0.864
562 0.82
190 0.721
103 0.835
11 1.0
7 1.0
0.7915742793791575
0.8119733924611974

 ===== Epoch 77	 =====
[ 0.5468873   2.111685   -0.5993768  -0.57551634  1.5076082   2.15497
 -0.43886673 -0.47319013  1.5019662   1.1510489  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 0.5873445   2.0890615  -0.59937984 -0.57549053  1.5327239   2.1438763
 -0.4389609  -0.47327355  1.538982    1.1604689  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0533,	 Acc = 0.6547,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0703
3163 0.156
3143 0.788
2595 0.864
1323 0.859
893 0.843
761 0.858
70 0.9
20 0.85
0.8339579784213516
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.0881,	 Acc = 0.6563,	 Loss Con1 = 0.0727,	 Loss Con2 = 0.0758
745 0.215
668 0.716
714 0.871
562 0.831
190 0.737
103 0.835
11 0.909
7 0.857
0.8022172949002218
0.8119733924611974

 ===== Epoch 78	 =====
[ 3.6837435   2.412594   -0.5993768  -0.57551634  2.5996258   2.0284986
 -0.43886673 -0.47319013  2.6630461   1.692618   -0.4178274  -0.43225467
  1.7825347   0.41165665] [ 3.6837435   2.412594   -0.59937984 -0.57549053  2.599795    2.0285232
 -0.4389609  -0.47327355  2.6630461   1.692618   -0.4178274  -0.43225467
  1.7825347   0.41165665] 0 0
train:	 Loss = 1.0557,	 Acc = 0.6544,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0702
3158 0.154
3145 0.787
2598 0.865
1323 0.863
893 0.837
761 0.859
70 0.9
20 0.8
0.8337116912599319
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.0849,	 Acc = 0.6493,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0723
745 0.213
668 0.69
714 0.859
562 0.827
190 0.784
103 0.825
11 0.909
7 0.857
0.7933481152993348
0.8119733924611974

 ===== Epoch 79	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.10833302  0.84448177
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.08025753  0.86884
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0539,	 Acc = 0.6556,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0694
3160 0.154
3146 0.79
2597 0.864
1324 0.868
890 0.834
760 0.862
71 0.93
20 0.9
0.8354904632152589
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0916,	 Acc = 0.6550,	 Loss Con1 = 0.0722,	 Loss Con2 = 0.0721
745 0.216
668 0.71
714 0.864
562 0.835
190 0.732
103 0.845
11 1.0
7 1.0
0.8
0.8119733924611974

 ===== Epoch 80	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 0
train:	 Loss = 1.0548,	 Acc = 0.6547,	 Loss Con1 = 0.0743,	 Loss Con2 = 0.0708
3166 0.155
3136 0.787
2597 0.864
1325 0.865
892 0.841
761 0.862
71 0.901
20 0.8
0.8343558282208589
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0882,	 Acc = 0.6480,	 Loss Con1 = 0.0719,	 Loss Con2 = 0.0666
745 0.217
668 0.692
714 0.864
562 0.82
190 0.726
103 0.845
11 0.909
7 1.0
0.7902439024390244
0.8119733924611974

 ===== Epoch 81	 =====
[-0.4557189  -0.49292567  0.69844383  2.1189585   1.8983008   0.84787494
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  0.72206163  2.099609    1.9257503   0.8523851
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0586,	 Acc = 0.6542,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0696
3164 0.155
3143 0.791
2597 0.856
1321 0.862
889 0.839
763 0.864
71 0.915
20 0.85
0.8333711949114039
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0908,	 Acc = 0.6460,	 Loss Con1 = 0.0721,	 Loss Con2 = 0.0679
745 0.219
668 0.689
714 0.857
562 0.815
190 0.737
103 0.854
11 0.909
7 1.0
0.7871396895787139
0.8119733924611974

 ===== Epoch 82	 =====
[-0.4557189  -0.49292567  0.17614709  1.5316556   1.601936   -0.033074
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  0.1760607   1.703476    1.6020831   0.15811685
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0519,	 Acc = 0.6544,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0704
3164 0.154
3145 0.786
2594 0.865
1323 0.863
893 0.842
758 0.858
71 0.901
20 0.9
0.834166288050886
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0843,	 Acc = 0.6513,	 Loss Con1 = 0.0727,	 Loss Con2 = 0.0698
745 0.219
668 0.708
714 0.857
562 0.824
190 0.732
103 0.845
11 0.909
7 1.0
0.7942350332594235
0.8119733924611974

 ===== Epoch 83	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  2.30707    -0.06722458 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0593,	 Acc = 0.6537,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0703
3166 0.156
3141 0.783
2595 0.861
1322 0.869
892 0.84
761 0.866
71 0.873
20 0.8
0.8327652806180413
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0926,	 Acc = 0.6570,	 Loss Con1 = 0.0731,	 Loss Con2 = 0.0702
745 0.216
668 0.734
714 0.864
562 0.822
190 0.726
103 0.845
11 0.909
7 0.857
0.802660753880266
0.8119733924611974

 ===== Epoch 84	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 0
train:	 Loss = 1.0571,	 Acc = 0.6542,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0687
3166 0.155
3145 0.784
2595 0.864
1321 0.866
891 0.844
759 0.858
71 0.915
20 0.9
0.8337877755055669
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0832,	 Acc = 0.6553,	 Loss Con1 = 0.0725,	 Loss Con2 = 0.0687
745 0.219
668 0.726
714 0.854
562 0.829
190 0.726
103 0.854
11 0.909
7 0.857
0.7995565410199557
0.8119733924611974

 ===== Epoch 85	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 0
train:	 Loss = 1.0535,	 Acc = 0.6559,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0688
3162 0.156
3144 0.79
2594 0.864
1324 0.863
893 0.843
761 0.862
70 0.914
20 0.9
0.8355666590960709
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.0785,	 Acc = 0.6507,	 Loss Con1 = 0.0747,	 Loss Con2 = 0.0734
745 0.215
668 0.702
714 0.861
562 0.824
190 0.753
103 0.835
11 0.909
7 0.857
0.7946784922394678
0.8119733924611974

 ===== Epoch 86	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  1.4924657   2.4975176
 -0.43886673 -0.47319013  2.211061    1.5552564  -0.4178274  -0.43225467
  2.5274832   0.5228127 ] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  1.5103266   2.4471524
 -0.4389609  -0.47327355  2.2414355   1.5134145  -0.4178274  -0.43225467
  2.5485673   0.48781052] 2 2
train:	 Loss = 1.0525,	 Acc = 0.6549,	 Loss Con1 = 0.0744,	 Loss Con2 = 0.0707
3161 0.155
3147 0.787
2598 0.864
1320 0.864
892 0.839
759 0.863
71 0.915
20 0.85
0.8342227773362099
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0760,	 Acc = 0.6540,	 Loss Con1 = 0.0726,	 Loss Con2 = 0.0686
745 0.219
668 0.711
714 0.864
562 0.836
190 0.7
103 0.845
11 1.0
7 0.857
0.7977827050997782
0.8119733924611974

 ===== Epoch 87	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.8624829   1.3958987
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.86261344  1.2047938
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 5
train:	 Loss = 1.0580,	 Acc = 0.6531,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0689
3166 0.155
3140 0.787
2596 0.861
1322 0.862
891 0.832
762 0.857
71 0.915
20 0.9
0.8320836173596909
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0851,	 Acc = 0.6550,	 Loss Con1 = 0.0723,	 Loss Con2 = 0.0699
745 0.219
668 0.728
714 0.861
562 0.831
190 0.689
103 0.835
11 0.909
7 1.0
0.7991130820399113
0.8119733924611974

 ===== Epoch 88	 =====
[ 3.5497818   2.1559663   2.1791131   0.8839535   0.2603809   0.9904075
  3.7725527   2.2310383  -0.46656546 -0.4823711   3.9047105   3.1887622
 -0.45947683 -0.42555502] [ 3.537536    2.1354933   2.1831234   0.8670328   0.26485944  0.9316116
  3.7604663   2.213284   -0.46656546 -0.4823711   3.8864086   3.1761498
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0484,	 Acc = 0.6563,	 Loss Con1 = 0.0744,	 Loss Con2 = 0.0693
3163 0.155
3141 0.793
2598 0.861
1322 0.866
892 0.84
761 0.871
71 0.887
20 0.9
0.8364565587734242
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0943,	 Acc = 0.6513,	 Loss Con1 = 0.0748,	 Loss Con2 = 0.0718
745 0.217
668 0.731
714 0.866
562 0.817
190 0.642
103 0.845
11 1.0
7 1.0
0.7946784922394678
0.8119733924611974

 ===== Epoch 89	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
  1.1011792   0.23823702 -0.46656546 -0.4823711   0.99520373  3.0409534
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
  1.0872637   0.2624806  -0.46656546 -0.4823711   1.0052981   3.0649457
 -0.45947683 -0.42555502] 4 4
train:	 Loss = 1.0568,	 Acc = 0.6537,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0689
3168 0.155
3140 0.788
2596 0.86
1323 0.866
890 0.84
761 0.857
70 0.886
20 0.85
0.8330681818181818
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1077,	 Acc = 0.6500,	 Loss Con1 = 0.0743,	 Loss Con2 = 0.0738
745 0.216
668 0.696
714 0.864
562 0.831
190 0.721
103 0.835
11 0.909
7 1.0
0.7933481152993348
0.8119733924611974

 ===== Epoch 90	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.0798005   2.004428
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.0816108   1.8034148
 -0.45947683 -0.42555502] 3 5
train:	 Loss = 1.0506,	 Acc = 0.6568,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0693
3165 0.155
3142 0.794
2594 0.865
1323 0.864
890 0.839
763 0.862
71 0.887
20 0.9
0.8372145859366125
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0928,	 Acc = 0.6567,	 Loss Con1 = 0.0717,	 Loss Con2 = 0.0675
745 0.215
668 0.732
714 0.867
562 0.829
190 0.7
103 0.835
11 0.909
7 1.0
0.802660753880266
0.8119733924611974

 ===== Epoch 91	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711   0.3544063   0.20749584
  1.6695157   3.2308445 ] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711   0.35360622  0.21016295
  1.6702442   3.231923  ] 0 0
train:	 Loss = 1.0517,	 Acc = 0.6555,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0694
3164 0.155
3140 0.788
2598 0.863
1323 0.872
891 0.842
761 0.863
71 0.873
20 0.8
0.8355293048614266
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1135,	 Acc = 0.6493,	 Loss Con1 = 0.0725,	 Loss Con2 = 0.0702
745 0.219
668 0.678
714 0.86
562 0.831
190 0.768
103 0.854
11 0.909
7 1.0
0.7915742793791575
0.8119733924611974

 ===== Epoch 92	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 0
train:	 Loss = 1.0592,	 Acc = 0.6542,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0694
3166 0.155
3143 0.788
2593 0.862
1324 0.863
891 0.838
760 0.861
71 0.901
20 0.85
0.8336741649625086
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0845,	 Acc = 0.6537,	 Loss Con1 = 0.0727,	 Loss Con2 = 0.0701
745 0.217
668 0.731
714 0.861
562 0.819
190 0.726
103 0.835
11 1.0
7 0.143
0.7977827050997782
0.8119733924611974

 ===== Epoch 93	 =====
[ 2.819836    1.9231158   1.874766    0.5743835  -0.6348712  -0.6508424
  3.1017683   2.042511   -0.46656546 -0.4823711   3.2967408   3.1448872
 -0.45947683 -0.42555502] [ 2.819836    1.9231158   1.874497    0.5745775  -0.6347739  -0.6507814
  3.1014953   2.0423744  -0.46656546 -0.4823711   3.2967408   3.1448872
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0472,	 Acc = 0.6578,	 Loss Con1 = 0.0744,	 Loss Con2 = 0.0700
3157 0.155
3146 0.789
2596 0.868
1324 0.868
892 0.845
762 0.866
71 0.915
20 0.9
0.8379298604017705
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0954,	 Acc = 0.6533,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0720
745 0.219
668 0.701
714 0.863
562 0.831
190 0.742
103 0.845
11 1.0
7 1.0
0.7968957871396896
0.8119733924611974

 ===== Epoch 94	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.51614475 -0.05936957
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.49867743 -0.02296649
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 1
train:	 Loss = 1.0463,	 Acc = 0.6572,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0687
3162 0.156
3148 0.792
2595 0.864
1323 0.867
889 0.843
761 0.865
70 0.943
20 0.9
0.8371564842153078
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1008,	 Acc = 0.6533,	 Loss Con1 = 0.0714,	 Loss Con2 = 0.0716
745 0.217
668 0.722
714 0.868
562 0.829
190 0.705
103 0.835
11 0.818
7 0.143
0.797339246119734
0.8119733924611974

 ===== Epoch 95	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 0
train:	 Loss = 1.0542,	 Acc = 0.6583,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0702
3167 0.155
3140 0.798
2598 0.866
1323 0.865
890 0.842
760 0.863
71 0.915
19 0.895
0.8393364390410181
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0732,	 Acc = 0.6553,	 Loss Con1 = 0.0746,	 Loss Con2 = 0.0731
745 0.219
668 0.704
714 0.871
562 0.833
190 0.732
103 0.835
11 1.0
7 1.0
0.7995565410199557
0.8119733924611974

 ===== Epoch 96	 =====
[-0.4557189  -0.49292567  2.1281059   1.8781446   1.1953781   0.6386069
 -0.43886673 -0.47319013  0.14554818  1.4573774  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  2.1024916   1.8860486   1.1691722   0.62940997
 -0.4389609  -0.47327355  0.10788446  1.4454137  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.0465,	 Acc = 0.6568,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0684
3162 0.156
3144 0.789
2599 0.864
1320 0.866
892 0.844
760 0.87
71 0.93
20 0.9
0.836588689529866
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0718,	 Acc = 0.6583,	 Loss Con1 = 0.0729,	 Loss Con2 = 0.0681
745 0.216
668 0.735
714 0.871
562 0.822
190 0.716
103 0.835
11 0.909
7 1.0
0.8044345898004435
0.8119733924611974

 ===== Epoch 97	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 0
train:	 Loss = 1.0461,	 Acc = 0.6570,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0692
3162 0.156
3141 0.792
2595 0.863
1326 0.865
892 0.843
761 0.874
71 0.901
20 0.85
0.8370429252782194
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1012,	 Acc = 0.6493,	 Loss Con1 = 0.0718,	 Loss Con2 = 0.0719
745 0.215
668 0.704
714 0.852
562 0.833
190 0.737
103 0.825
11 1.0
7 0.857
0.7929046563192904
0.8119733924611974

 ===== Epoch 98	 =====
[-0.4557189  -0.49292567  0.2394248  -0.15270072 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  0.25883198 -0.19367991 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0497,	 Acc = 0.6551,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0691
3160 0.155
3149 0.79
2596 0.862
1322 0.868
891 0.832
759 0.859
71 0.944
20 0.85
0.8344686648501363
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1127,	 Acc = 0.6493,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0708
745 0.215
668 0.699
714 0.863
562 0.827
190 0.726
103 0.825
11 0.909
7 1.0
0.7929046563192904
0.8119733924611974

 ===== Epoch 99	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 0
train:	 Loss = 1.0530,	 Acc = 0.6547,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0690
3161 0.156
3141 0.791
2600 0.86
1322 0.865
890 0.836
763 0.856
71 0.93
20 0.9
0.8336550471216078
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.1082,	 Acc = 0.6507,	 Loss Con1 = 0.0728,	 Loss Con2 = 0.0702
745 0.217
668 0.692
714 0.857
562 0.833
190 0.763
103 0.835
11 0.909
7 1.0
0.7937915742793792
0.8119733924611974

 ===== Epoch 100	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.98953474  2.6848352
 -0.43886673 -0.47319013  0.7435796   1.0342147  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355  0.744176    1.2452667  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0527,	 Acc = 0.6569,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0691
3164 0.154
3138 0.79
2603 0.866
1319 0.867
891 0.843
762 0.87
71 0.915
20 0.9
0.8375738300772376
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.0969,	 Acc = 0.6510,	 Loss Con1 = 0.0749,	 Loss Con2 = 0.0711
745 0.216
668 0.702
714 0.856
562 0.833
190 0.753
103 0.806
11 1.0
7 1.0
0.7946784922394678
0.8119733924611974

 ===== Epoch 101	 =====
[ 0.30821517  2.634662   -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013  1.480648    2.9720368  -0.4178274  -0.43225467
  2.0612502   1.7786386 ] [ 0.3082128   2.6346657  -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355  1.480646    2.9720385  -0.4178274  -0.43225467
  2.061248    1.7786386 ] 0 0
train:	 Loss = 1.0496,	 Acc = 0.6572,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0688
3160 0.156
3145 0.789
2596 0.869
1323 0.864
892 0.844
762 0.867
70 0.9
20 0.9
0.8370799273387829
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0703,	 Acc = 0.6577,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0701
745 0.219
668 0.734
714 0.871
562 0.819
190 0.711
103 0.835
11 0.909
7 1.0
0.802660753880266
0.8119733924611974

 ===== Epoch 102	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.05790965  0.40976676
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.07014479  0.33827212
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0464,	 Acc = 0.6559,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0691
3165 0.155
3144 0.788
2594 0.865
1324 0.868
891 0.844
759 0.866
71 0.887
20 0.9
0.8360786095649211
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0813,	 Acc = 0.6547,	 Loss Con1 = 0.0727,	 Loss Con2 = 0.0672
745 0.219
668 0.699
714 0.871
562 0.836
190 0.737
103 0.825
11 0.909
7 1.0
0.798669623059867
0.8119733924611974

 ===== Epoch 103	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 0
train:	 Loss = 1.0497,	 Acc = 0.6562,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0686
3163 0.155
3138 0.788
2597 0.867
1324 0.868
893 0.84
762 0.866
71 0.873
20 0.9
0.836342986939239
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1119,	 Acc = 0.6537,	 Loss Con1 = 0.0722,	 Loss Con2 = 0.0690
745 0.216
668 0.705
714 0.861
562 0.836
190 0.737
103 0.845
11 0.909
7 1.0
0.7982261640798226
0.8119733924611974

 ===== Epoch 104	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 0
train:	 Loss = 1.0476,	 Acc = 0.6566,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0687
3165 0.155
3142 0.792
2601 0.865
1318 0.86
891 0.838
760 0.874
71 0.901
20 0.9
0.8367601953879359
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.0862,	 Acc = 0.6520,	 Loss Con1 = 0.0723,	 Loss Con2 = 0.0690
745 0.216
668 0.723
714 0.86
562 0.82
190 0.747
103 0.806
11 1.0
7 0.143
0.7960088691796009
0.8119733924611974

 ===== Epoch 105	 =====
[-0.4557189  -0.49292567  1.8190377   1.6327037   0.657287    0.1318045
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.8111454   1.6139282   0.67321694  0.09826104
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0485,	 Acc = 0.6562,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0697
3162 0.156
3142 0.787
2596 0.866
1324 0.869
892 0.841
761 0.865
71 0.901
20 0.85
0.8359073359073359
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0876,	 Acc = 0.6467,	 Loss Con1 = 0.0742,	 Loss Con2 = 0.0707
745 0.217
668 0.699
714 0.859
562 0.836
190 0.668
103 0.816
11 0.909
7 1.0
0.788470066518847
0.8119733924611974

 ===== Epoch 106	 =====
[-0.05491513  1.4908607  -0.5993768  -0.57551634 -0.6348712  -0.6508424
  1.8158147   0.03327088 -0.46656546 -0.4823711   2.1192486   1.5317962
 -0.45947683 -0.42555502] [-0.05167621  1.2797422  -0.59937984 -0.57549053 -0.6347739  -0.6507814
  1.8415487   0.00844059 -0.46656546 -0.4823711   2.1227634   1.5054955
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0506,	 Acc = 0.6557,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0687
3165 0.155
3144 0.787
2597 0.864
1323 0.868
888 0.843
760 0.864
71 0.915
20 0.9
0.8356242190162445
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0841,	 Acc = 0.6497,	 Loss Con1 = 0.0730,	 Loss Con2 = 0.0719
745 0.217
668 0.681
714 0.859
562 0.831
190 0.779
103 0.835
11 1.0
7 1.0
0.7924611973392461
0.8119733924611974

 ===== Epoch 107	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.18483599  0.9104418
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.1846879   0.9095464
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0515,	 Acc = 0.6557,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0691
3170 0.156
3144 0.788
2592 0.864
1319 0.869
889 0.845
763 0.86
71 0.915
20 0.9
0.8358717890429643
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0840,	 Acc = 0.6507,	 Loss Con1 = 0.0732,	 Loss Con2 = 0.0713
745 0.216
668 0.731
714 0.863
562 0.817
190 0.663
103 0.816
11 1.0
7 1.0
0.7942350332594235
0.8119733924611974

 ===== Epoch 108	 =====
[-0.4557189  -0.49292567  1.1689351   0.24207321 -0.6348712  -0.6508424
  0.46101096  2.2073672  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.1687421   0.07073236 -0.6347739  -0.6507814
  0.46087137  2.002281   -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 5
train:	 Loss = 1.0507,	 Acc = 0.6573,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0682
3162 0.155
3141 0.793
2598 0.864
1325 0.866
890 0.844
761 0.867
71 0.915
20 0.9
0.8376107199636611
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0843,	 Acc = 0.6470,	 Loss Con1 = 0.0729,	 Loss Con2 = 0.0689
745 0.216
668 0.696
714 0.861
562 0.815
190 0.726
103 0.835
11 1.0
7 1.0
0.7893569844789357
0.8119733924611974

 ===== Epoch 109	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.18288381  0.3444909
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.15851104  0.31370887
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.0435,	 Acc = 0.6579,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0700
3163 0.155
3140 0.79
2597 0.869
1325 0.869
891 0.853
761 0.858
71 0.887
20 0.9
0.8385008517887564
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1055,	 Acc = 0.6457,	 Loss Con1 = 0.0726,	 Loss Con2 = 0.0701
745 0.216
668 0.674
714 0.861
562 0.822
190 0.768
103 0.835
11 0.909
7 1.0
0.7875831485587583
0.8119733924611974

 ===== Epoch 110	 =====
[ 0.9704338   1.4512616  -0.5993768  -0.57551634 -0.6348712  -0.6508424
  2.1422272   1.0917943  -0.46656546 -0.4823711   2.6114545   2.325999
 -0.45947683 -0.42555502] [ 0.9704324   1.6549062  -0.59937984 -0.57549053 -0.6347739  -0.6507814
  2.142001    1.2966251  -0.46656546 -0.4823711   2.611454    2.5466013
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0447,	 Acc = 0.6577,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0685
3163 0.156
3145 0.789
2600 0.866
1319 0.875
888 0.842
762 0.867
71 0.915
20 0.9
0.8379329926178308
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0738,	 Acc = 0.6487,	 Loss Con1 = 0.0730,	 Loss Con2 = 0.0722
745 0.219
668 0.713
714 0.863
562 0.808
190 0.7
103 0.845
11 0.909
7 1.0
0.7906873614190687
0.8119733924611974

 ===== Epoch 111	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  1.3206444   1.6190729
 -0.43886673 -0.47319013  0.34649447  2.6982641  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  1.3261868   1.6458704
 -0.4389609  -0.47327355  0.3650827   2.784547   -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 4
train:	 Loss = 1.0469,	 Acc = 0.6570,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0697
3158 0.155
3147 0.788
2597 0.867
1323 0.869
891 0.84
761 0.871
71 0.873
20 0.85
0.8367763904653802
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0887,	 Acc = 0.6517,	 Loss Con1 = 0.0719,	 Loss Con2 = 0.0696
745 0.217
668 0.698
714 0.861
562 0.842
190 0.742
103 0.835
11 1.0
7 0.143
0.7951219512195122
0.8119733924611974

 ===== Epoch 112	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
  1.0821787   0.27210942 -0.46656546 -0.4823711   1.0092461   3.074131
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
  1.0819718   0.27207616 -0.46656546 -0.4823711   1.0092734   3.0741942
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0452,	 Acc = 0.6562,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0679
3166 0.155
3144 0.787
2591 0.868
1324 0.866
891 0.84
762 0.871
70 0.9
20 0.85
0.8365144285389684
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0815,	 Acc = 0.6567,	 Loss Con1 = 0.0748,	 Loss Con2 = 0.0740
745 0.216
668 0.719
714 0.863
562 0.833
190 0.747
103 0.825
11 1.0
7 1.0
0.8022172949002218
0.8119733924611974

 ===== Epoch 113	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711   0.9438131   3.325539
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0486,	 Acc = 0.6545,	 Loss Con1 = 0.0742,	 Loss Con2 = 0.0694
3163 0.155
3142 0.779
2597 0.868
1326 0.869
891 0.843
758 0.868
71 0.887
20 0.9
0.8339579784213516
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0895,	 Acc = 0.6520,	 Loss Con1 = 0.0730,	 Loss Con2 = 0.0684
745 0.219
668 0.726
714 0.867
562 0.82
190 0.658
103 0.835
11 0.909
7 1.0
0.7951219512195122
0.8119733924611974

 ===== Epoch 114	 =====
[ 2.141922    0.96834767 -0.5993768  -0.57551634 -0.3209199   0.47035053
 -0.43886673 -0.47319013  1.8389622   1.4196582   3.610242    0.42528906
  2.9994333   1.6532766 ] [ 2.101609    0.95901966 -0.59937984 -0.57549053 -0.34617168  0.39582112
 -0.4389609  -0.47327355  1.801164    1.4157667   3.585144    0.4155777
  2.9682517   1.6516623 ] 1 1
train:	 Loss = 1.0454,	 Acc = 0.6573,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0691
3162 0.156
3140 0.788
2598 0.863
1325 0.875
890 0.848
763 0.873
70 0.871
20 0.9
0.8374971610265728
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1028,	 Acc = 0.6473,	 Loss Con1 = 0.0728,	 Loss Con2 = 0.0700
745 0.217
668 0.675
714 0.866
562 0.829
190 0.747
103 0.825
11 1.0
7 1.0
0.7893569844789357
0.8119733924611974

 ===== Epoch 115	 =====
[ 3.6938322   2.3531594   2.1516564   1.0577306   0.26476544  1.5880915
  3.9070134   2.4013271  -0.46656546 -0.4823711   4.095167    3.3090026
 -0.45947683 -0.42555502] [ 3.6776052   2.3342302   2.1526566   1.0405723   0.26039892  1.5296915
  3.8918295   2.3847747  -0.46656546 -0.4823711   4.0755186   3.2975593
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0442,	 Acc = 0.6597,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0699
3162 0.156
3149 0.791
2594 0.871
1324 0.872
888 0.846
760 0.875
71 0.901
20 0.9
0.8404496933908698
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0779,	 Acc = 0.6457,	 Loss Con1 = 0.0726,	 Loss Con2 = 0.0712
745 0.217
668 0.665
714 0.873
562 0.815
190 0.768
103 0.835
11 1.0
7 1.0
0.7871396895787139
0.8119733924611974

 ===== Epoch 116	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 0
train:	 Loss = 1.0477,	 Acc = 0.6559,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0708
3165 0.155
3143 0.786
2592 0.867
1324 0.868
891 0.845
762 0.866
71 0.901
20 0.85
0.8360786095649211
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0738,	 Acc = 0.6537,	 Loss Con1 = 0.0726,	 Loss Con2 = 0.0679
745 0.216
668 0.708
714 0.868
562 0.827
190 0.732
103 0.825
11 1.0
7 1.0
0.7982261640798226
0.8119733924611974

 ===== Epoch 117	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711   0.82824165  3.3287027
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711   0.84687054  3.256505
 -0.45947683 -0.42555502] 2 3
train:	 Loss = 1.0432,	 Acc = 0.6560,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0692
3159 0.156
3143 0.787
2598 0.86
1325 0.869
890 0.845
762 0.87
71 0.915
20 0.85
0.8351685775911
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0772,	 Acc = 0.6490,	 Loss Con1 = 0.0731,	 Loss Con2 = 0.0677
745 0.216
668 0.716
714 0.86
562 0.824
190 0.679
103 0.816
11 1.0
7 1.0
0.7920177383592018
0.8119733924611974

 ===== Epoch 118	 =====
[-0.4557189  -0.49292567  1.7389157   0.04190265 -0.6348712  -0.6508424
  1.2427913   1.3429428  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.7553364   0.02559587 -0.6347739  -0.6507814
  1.2470936   1.2971355  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0460,	 Acc = 0.6573,	 Loss Con1 = 0.0742,	 Loss Con2 = 0.0698
3164 0.155
3140 0.789
2597 0.868
1323 0.869
891 0.842
762 0.866
71 0.915
20 0.85
0.8376874148114494
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1221,	 Acc = 0.6443,	 Loss Con1 = 0.0718,	 Loss Con2 = 0.0714
745 0.213
668 0.66
714 0.859
562 0.831
190 0.789
103 0.825
11 1.0
7 1.0
0.7866962305986697
0.8119733924611974

 ===== Epoch 119	 =====
[ 0.97042656  1.2476364  -0.5993768  -0.57551634 -0.6348712  -0.6508424
  2.1422188   0.8868508  -0.46656546 -0.4823711   2.6114516   2.1054049
 -0.45947683 -0.42555502] [ 0.9704338   1.4512616  -0.59937984 -0.57549053 -0.6347739  -0.6507814
  2.1420026   1.0916777  -0.46656546 -0.4823711   2.6114545   2.325999
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0492,	 Acc = 0.6549,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0698
3164 0.156
3139 0.786
2599 0.868
1323 0.864
891 0.836
761 0.861
71 0.873
20 0.9
0.8342798727850976
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0858,	 Acc = 0.6550,	 Loss Con1 = 0.0727,	 Loss Con2 = 0.0695
745 0.219
668 0.705
714 0.868
562 0.831
190 0.732
103 0.845
11 1.0
7 1.0
0.7991130820399113
0.8119733924611974

 ===== Epoch 120	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.2910406   1.6761609
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.2638992   1.6890217
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.0515,	 Acc = 0.6535,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0693
3164 0.156
3143 0.779
2598 0.865
1323 0.87
890 0.84
760 0.862
70 0.9
20 0.85
0.8323489323034984
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1027,	 Acc = 0.6463,	 Loss Con1 = 0.0744,	 Loss Con2 = 0.0716
745 0.217
668 0.699
714 0.859
562 0.831
190 0.679
103 0.806
11 1.0
7 1.0
0.7880266075388027
0.8119733924611974

 ===== Epoch 121	 =====
[ 0.4247236   0.17165276  1.6860224   0.35022646 -0.6348712  -0.6508424
  0.7622843   0.893161   -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 0.4347733   0.1007153   1.6877058   0.33417007 -0.6347739  -0.6507814
  0.76124686  0.8430094  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 3
train:	 Loss = 1.0481,	 Acc = 0.6569,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0695
3163 0.155
3140 0.792
2596 0.864
1323 0.867
893 0.842
762 0.869
71 0.915
20 0.85
0.8373651334469052
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1212,	 Acc = 0.6473,	 Loss Con1 = 0.0732,	 Loss Con2 = 0.0703
745 0.216
668 0.687
714 0.863
562 0.822
190 0.742
103 0.825
11 1.0
7 1.0
0.78980044345898
0.8119733924611974

 ===== Epoch 122	 =====
[-0.4557189  -0.49292567  1.5047929   2.031624   -0.32546112  0.9151048
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.4846737   2.0298197  -0.3383525   0.81952107
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.0481,	 Acc = 0.6549,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0702
3167 0.155
3142 0.784
2597 0.863
1319 0.867
892 0.846
760 0.872
71 0.915
20 0.85
0.8349051244176798
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0835,	 Acc = 0.6497,	 Loss Con1 = 0.0727,	 Loss Con2 = 0.0690
745 0.213
668 0.716
714 0.861
562 0.822
190 0.695
103 0.835
11 0.909
7 1.0
0.7937915742793792
0.8119733924611974

 ===== Epoch 123	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013  1.8090248   0.24251324 -0.4178274  -0.43225467
  2.9707384   0.46257764] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355  1.8325545   0.21460849 -0.4178274  -0.43225467
  2.988663    0.44575167] 3 3
train:	 Loss = 1.0465,	 Acc = 0.6579,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0692
3161 0.154
3143 0.793
2599 0.87
1324 0.861
890 0.843
760 0.87
71 0.915
20 0.85
0.8386510730101056
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0916,	 Acc = 0.6513,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0707
745 0.219
668 0.729
714 0.861
562 0.829
190 0.668
103 0.816
11 1.0
7 0.143
0.7942350332594235
0.8119733924611974

 ===== Epoch 124	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 0
train:	 Loss = 1.0453,	 Acc = 0.6566,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0690
3164 0.154
3148 0.788
2596 0.867
1321 0.871
890 0.84
760 0.867
69 0.913
20 0.9
0.8372330758746025
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0886,	 Acc = 0.6433,	 Loss Con1 = 0.0726,	 Loss Con2 = 0.0703
745 0.217
668 0.696
714 0.856
562 0.824
190 0.684
103 0.796
11 0.909
7 1.0
0.7840354767184036
0.8119733924611974

 ===== Epoch 125	 =====
[ 1.3892201   2.2734234  -0.5993768  -0.57551634  1.0696414   1.814706
 -0.43886673 -0.47319013  0.9017489   0.21961193 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 1.3892298   2.0697715  -0.59937984 -0.57549053  1.0697836   1.6235887
 -0.4389609  -0.47327355  0.90176064  0.00618235 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 5
train:	 Loss = 1.0460,	 Acc = 0.6551,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0694
3166 0.155
3145 0.782
2594 0.867
1320 0.873
892 0.84
760 0.867
71 0.887
20 0.9
0.8349238809361509
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0988,	 Acc = 0.6443,	 Loss Con1 = 0.0755,	 Loss Con2 = 0.0765
745 0.217
668 0.722
714 0.857
562 0.806
190 0.674
103 0.806
11 1.0
7 0.286
0.7853658536585366
0.8119733924611974

 ===== Epoch 126	 =====
[-0.4557189  -0.49292567  1.8425046   2.0297654   0.68781936  0.597531
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.8422393   1.858686    0.68794614  0.4064368
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 5
train:	 Loss = 1.0445,	 Acc = 0.6557,	 Loss Con1 = 0.0746,	 Loss Con2 = 0.0714
3160 0.155
3143 0.787
2600 0.864
1321 0.865
892 0.842
761 0.873
71 0.887
20 0.9
0.8354904632152589
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1188,	 Acc = 0.6447,	 Loss Con1 = 0.0728,	 Loss Con2 = 0.0708
745 0.213
668 0.707
714 0.86
562 0.819
190 0.668
103 0.825
11 0.909
7 1.0
0.7871396895787139
0.8119733924611974

 ===== Epoch 127	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 0
train:	 Loss = 1.0465,	 Acc = 0.6557,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0693
3160 0.156
3142 0.785
2595 0.864
1326 0.872
893 0.843
761 0.866
71 0.873
20 0.9
0.8350363306085377
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.0779,	 Acc = 0.6560,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0684
745 0.219
668 0.717
714 0.864
562 0.819
190 0.774
103 0.825
11 1.0
7 0.857
0.8004434589800443
0.8119733924611974

 ===== Epoch 128	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.39651135  0.8866219
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.39663142  1.0777998
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0470,	 Acc = 0.6564,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0695
3163 0.156
3145 0.787
2595 0.868
1320 0.868
892 0.841
762 0.865
71 0.887
20 0.85
0.836229415105054
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0711,	 Acc = 0.6543,	 Loss Con1 = 0.0727,	 Loss Con2 = 0.0687
745 0.219
668 0.716
714 0.867
562 0.822
190 0.716
103 0.854
11 0.909
7 1.0
0.7982261640798226
0.8119733924611974

 ===== Epoch 129	 =====
[-0.4557189  -0.49292567  1.289907    1.8211716  -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.2627506   1.8319958  -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.0427,	 Acc = 0.6569,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0684
3165 0.155
3142 0.788
2594 0.868
1322 0.871
891 0.84
763 0.864
71 0.915
20 0.9
0.8372145859366125
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0856,	 Acc = 0.6493,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0719
745 0.219
668 0.695
714 0.864
562 0.82
190 0.747
103 0.816
11 0.909
7 1.0
0.7915742793791575
0.8119733924611974

 ===== Epoch 130	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 0
train:	 Loss = 1.0439,	 Acc = 0.6576,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0680
3160 0.156
3148 0.787
2594 0.868
1323 0.869
890 0.845
762 0.873
71 0.901
20 0.9
0.8376475930971844
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0942,	 Acc = 0.6430,	 Loss Con1 = 0.0747,	 Loss Con2 = 0.0775
745 0.217
668 0.69
714 0.866
562 0.811
190 0.684
103 0.825
11 0.909
7 1.0
0.7835920177383592
0.8119733924611974

 ===== Epoch 131	 =====
[ 2.7320273   1.8169336  -0.5993768  -0.57551634 -0.6348712  -0.6508424
  2.3049302   1.0421813  -0.46656546 -0.4823711   2.7006335   2.2518122
 -0.45947683 -0.42555502] [ 2.6903927   1.8205763  -0.59937984 -0.57549053 -0.6347739  -0.6507814
  2.2679968   1.0346487  -0.46656546 -0.4823711   2.6706533   2.2565296
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.0410,	 Acc = 0.6569,	 Loss Con1 = 0.0744,	 Loss Con2 = 0.0707
3168 0.155
3140 0.789
2594 0.865
1323 0.871
892 0.841
760 0.87
71 0.93
20 0.9
0.8375
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1069,	 Acc = 0.6513,	 Loss Con1 = 0.0723,	 Loss Con2 = 0.0713
745 0.219
668 0.719
714 0.856
562 0.826
190 0.705
103 0.825
11 0.909
7 1.0
0.7942350332594235
0.8119733924611974

 ===== Epoch 132	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  1.1498393   2.2681932
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  1.1360861   2.2421398
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 1
train:	 Loss = 1.0434,	 Acc = 0.6572,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0686
3161 0.156
3144 0.79
2594 0.864
1325 0.871
890 0.847
763 0.862
71 0.901
20 0.9
0.8371749744521404
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1076,	 Acc = 0.6510,	 Loss Con1 = 0.0728,	 Loss Con2 = 0.0702
745 0.219
668 0.705
714 0.867
562 0.819
190 0.721
103 0.835
11 0.909
7 1.0
0.7937915742793792
0.8119733924611974

 ===== Epoch 133	 =====
[ 1.0833253   1.3117329  -0.5993768  -0.57551634 -0.6348712  -0.6508424
  0.1902481   0.47349945  2.1958468   3.1775365   1.6245111   0.45352882
  2.516626    2.2324834 ] [ 1.0833253   1.1080915  -0.59937984 -0.57549053 -0.6347739  -0.6507814
  0.19012217  0.26844993  2.1958468   2.9641025   1.6245111   0.2329278
  2.516626    2.0069067 ] 5 5
train:	 Loss = 1.0399,	 Acc = 0.6573,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0688
3160 0.156
3145 0.786
2599 0.868
1322 0.873
889 0.841
762 0.865
71 0.915
20 0.9
0.8371934604904632
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1022,	 Acc = 0.6427,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0697
745 0.217
668 0.687
714 0.86
562 0.806
190 0.726
103 0.825
11 0.909
7 1.0
0.7831485587583149
0.8119733924611974

 ===== Epoch 134	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
  1.3587637   2.1074946 ] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
  1.3587637   2.3330712 ] 6 6
train:	 Loss = 1.0452,	 Acc = 0.6557,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0692
3163 0.156
3143 0.784
2594 0.865
1322 0.866
893 0.847
762 0.869
71 0.915
20 0.9
0.835320840431573
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0945,	 Acc = 0.6493,	 Loss Con1 = 0.0734,	 Loss Con2 = 0.0732
745 0.219
668 0.71
714 0.853
562 0.826
190 0.711
103 0.835
11 0.909
7 1.0
0.7915742793791575
0.8119733924611974

 ===== Epoch 135	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013  0.20739907  0.14405623 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 3
train:	 Loss = 1.0461,	 Acc = 0.6580,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0697
3160 0.156
3146 0.794
2596 0.867
1325 0.869
889 0.837
761 0.863
71 0.887
20 0.9
0.8382152588555858
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.0946,	 Acc = 0.6453,	 Loss Con1 = 0.0723,	 Loss Con2 = 0.0679
745 0.219
668 0.692
714 0.873
562 0.811
190 0.684
103 0.816
11 1.0
7 1.0
0.7862527716186253
0.8119733924611974

 ===== Epoch 136	 =====
[-0.4557189  -0.49292567  1.6758901   1.1461924  -0.6348712  -0.6508424
  1.975649    2.9522908  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.6759342   1.1676844  -0.6347739  -0.6507814
  1.9992476   2.9771497  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 4
train:	 Loss = 1.0438,	 Acc = 0.6564,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0693
3159 0.157
3144 0.788
2601 0.865
1323 0.868
892 0.837
760 0.868
70 0.871
19 0.842
0.8356226586445681
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0787,	 Acc = 0.6517,	 Loss Con1 = 0.0743,	 Loss Con2 = 0.0745
745 0.219
668 0.713
714 0.867
562 0.815
190 0.705
103 0.845
11 1.0
7 1.0
0.7946784922394678
0.8119733924611974

 ===== Epoch 137	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.93678176  2.327596
 -0.43886673 -0.47319013  0.83478445  0.54962105 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.93511915  2.3517768
 -0.4389609  -0.47327355  0.80983585  0.567285   -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 4
train:	 Loss = 1.0402,	 Acc = 0.6568,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0692
3161 0.156
3142 0.788
2601 0.869
1323 0.864
891 0.842
759 0.864
71 0.93
20 0.85
0.8366072442375383
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.0960,	 Acc = 0.6480,	 Loss Con1 = 0.0723,	 Loss Con2 = 0.0714
745 0.213
668 0.711
714 0.854
562 0.819
190 0.726
103 0.816
11 1.0
7 1.0
0.7915742793791575
0.8119733924611974

 ===== Epoch 138	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  1.1265202   2.035353
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  1.1521424   2.0234923
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0447,	 Acc = 0.6565,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0701
3162 0.155
3145 0.788
2598 0.867
1323 0.868
890 0.842
759 0.864
71 0.915
20 0.9
0.836588689529866
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0801,	 Acc = 0.6580,	 Loss Con1 = 0.0734,	 Loss Con2 = 0.0737
745 0.215
668 0.741
714 0.864
562 0.826
190 0.716
103 0.825
11 0.909
7 1.0
0.8044345898004435
0.8119733924611974

 ===== Epoch 139	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  1.2369459   1.8187491
 -0.43886673 -0.47319013  1.0020334   0.49593458 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  1.245786    1.8470408
 -0.4389609  -0.47327355  0.98218876  0.54607517 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 4
train:	 Loss = 1.0430,	 Acc = 0.6560,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0700
3169 0.156
3141 0.789
2594 0.865
1322 0.867
892 0.84
759 0.866
71 0.915
20 0.9
0.8361177406523469
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.1027,	 Acc = 0.6383,	 Loss Con1 = 0.0729,	 Loss Con2 = 0.0709
745 0.212
668 0.662
714 0.863
562 0.813
190 0.721
103 0.845
11 1.0
7 1.0
0.7791574279379158
0.8119733924611974

 ===== Epoch 140	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  1.80166     1.664236
 -0.43886673 -0.47319013  1.2782897   1.1454443  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 0.56590515  0.01805402 -0.59937984 -0.57549053  1.8018067   1.8554388
 -0.4389609  -0.47327355  1.2782575   1.3589418  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0435,	 Acc = 0.6558,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0700
3162 0.156
3140 0.786
2597 0.865
1326 0.871
893 0.842
759 0.859
71 0.93
20 0.85
0.8354531001589826
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1024,	 Acc = 0.6540,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0744
745 0.219
668 0.71
714 0.861
562 0.829
190 0.742
103 0.825
11 1.0
7 1.0
0.7977827050997782
0.8119733924611974

 ===== Epoch 141	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
  1.246746    1.4553007 ] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
  1.2776117   1.4620266 ] 2 2
train:	 Loss = 1.0455,	 Acc = 0.6562,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0690
3160 0.156
3143 0.787
2599 0.866
1324 0.866
890 0.842
761 0.87
71 0.887
20 0.8
0.8357175295186194
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0915,	 Acc = 0.6483,	 Loss Con1 = 0.0722,	 Loss Con2 = 0.0685
745 0.219
668 0.702
714 0.863
562 0.813
190 0.721
103 0.825
11 1.0
7 1.0
0.7902439024390244
0.8119733924611974

 ===== Epoch 142	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013  0.70694697  0.29015326 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355  0.73766184  0.3297832  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0465,	 Acc = 0.6557,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0680
3158 0.155
3147 0.782
2597 0.868
1323 0.87
890 0.845
762 0.866
71 0.887
20 0.85
0.8350737797956868
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0910,	 Acc = 0.6517,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0716
745 0.219
668 0.699
714 0.864
562 0.826
190 0.742
103 0.825
11 1.0
7 1.0
0.7946784922394678
0.8119733924611974

 ===== Epoch 143	 =====
[-0.4557189  -0.49292567  0.2394248  -0.15270072 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  0.25883198 -0.19367991 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0420,	 Acc = 0.6573,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0686
3162 0.156
3140 0.79
2601 0.866
1325 0.869
889 0.847
761 0.861
70 0.914
20 0.85
0.8373836020894845
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0887,	 Acc = 0.6507,	 Loss Con1 = 0.0727,	 Loss Con2 = 0.0680
745 0.216
668 0.704
714 0.87
562 0.826
190 0.705
103 0.825
11 0.909
7 1.0
0.7942350332594235
0.8119733924611974

 ===== Epoch 144	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711   0.89217806  1.1407024
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711   0.90109473  1.0917858
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0407,	 Acc = 0.6567,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0696
3164 0.156
3147 0.789
2594 0.869
1321 0.865
890 0.84
761 0.859
71 0.915
20 0.9
0.8366651522035439
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1066,	 Acc = 0.6493,	 Loss Con1 = 0.0720,	 Loss Con2 = 0.0692
745 0.219
668 0.708
714 0.861
562 0.826
190 0.679
103 0.835
11 1.0
7 1.0
0.7915742793791575
0.8119733924611974

 ===== Epoch 145	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
  1.1179476   1.7080145 ] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
  1.0866556   1.7055285 ] 1 1
train:	 Loss = 1.0451,	 Acc = 0.6545,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0693
3166 0.155
3142 0.785
2596 0.865
1322 0.871
890 0.834
761 0.867
71 0.873
20 0.85
0.8342422176778005
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0875,	 Acc = 0.6553,	 Loss Con1 = 0.0731,	 Loss Con2 = 0.0702
745 0.219
668 0.71
714 0.864
562 0.835
190 0.742
103 0.816
11 1.0
7 1.0
0.7995565410199557
0.8119733924611974

 ===== Epoch 146	 =====
[-0.4557189  -0.49292567  0.42708352  2.4582875  -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 6
train:	 Loss = 1.0439,	 Acc = 0.6547,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0700
3164 0.156
3146 0.785
2594 0.862
1321 0.868
892 0.846
760 0.862
71 0.915
20 0.9
0.8340527033166742
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1173,	 Acc = 0.6440,	 Loss Con1 = 0.0721,	 Loss Con2 = 0.0716
745 0.219
668 0.723
714 0.85
562 0.801
190 0.679
103 0.796
11 1.0
7 1.0
0.7844789356984478
0.8119733924611974

 ===== Epoch 147	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0379,	 Acc = 0.6576,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0694
3160 0.155
3142 0.791
2598 0.866
1324 0.872
891 0.84
762 0.866
71 0.93
20 0.8
0.8377611262488647
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0776,	 Acc = 0.6513,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0685
745 0.215
668 0.705
714 0.87
562 0.827
190 0.7
103 0.835
11 1.0
7 1.0
0.7955654101995565
0.8119733924611974

 ===== Epoch 148	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.40689906  2.090223
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.41698915  1.8681248
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 5
train:	 Loss = 1.0405,	 Acc = 0.6578,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0699
3163 0.155
3142 0.79
2595 0.869
1325 0.868
890 0.843
763 0.873
70 0.857
20 0.9
0.8385008517887564
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0875,	 Acc = 0.6593,	 Loss Con1 = 0.0722,	 Loss Con2 = 0.0695
745 0.219
668 0.731
714 0.86
562 0.833
190 0.742
103 0.835
11 1.0
7 1.0
0.8048780487804879
0.8119733924611974

 ===== Epoch 149	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 0
train:	 Loss = 1.0421,	 Acc = 0.6573,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0688
3163 0.156
3144 0.789
2598 0.87
1323 0.866
889 0.841
760 0.864
71 0.901
20 0.8
0.8374787052810903
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0958,	 Acc = 0.6523,	 Loss Con1 = 0.0726,	 Loss Con2 = 0.0678
745 0.215
668 0.714
714 0.867
562 0.817
190 0.737
103 0.825
11 0.909
7 1.0
0.7968957871396896
0.8119733924611974

 ===== Epoch 150	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 0
train:	 Loss = 1.0452,	 Acc = 0.6545,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0685
3163 0.157
3143 0.784
2593 0.865
1322 0.86
893 0.841
763 0.869
71 0.873
20 0.85
0.8332765474162408
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1077,	 Acc = 0.6453,	 Loss Con1 = 0.0794,	 Loss Con2 = 0.0874
745 0.215
668 0.702
714 0.864
562 0.806
190 0.705
103 0.835
11 0.909
7 1.0
0.7875831485587583
0.8119733924611974

 ===== Epoch 151	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
  0.71555036  0.9045721  -0.46656546 -0.4823711   1.3480877   3.3751502
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
  0.7528351   0.9243309  -0.46656546 -0.4823711   1.3712578   3.3484468
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0437,	 Acc = 0.6583,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0720
3165 0.155
3144 0.784
2593 0.872
1324 0.878
888 0.848
763 0.865
71 0.93
20 0.9
0.8392593434056571
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1052,	 Acc = 0.6583,	 Loss Con1 = 0.0721,	 Loss Con2 = 0.0688
745 0.215
668 0.737
714 0.857
562 0.829
190 0.753
103 0.825
11 0.909
7 1.0
0.8048780487804879
0.8119733924611974

 ===== Epoch 152	 =====
[-0.4557189  -0.49292567  0.8027578   2.3491814   0.79534334 -0.14789137
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  0.80263335  2.3496768   0.7954425  -0.14779298
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0423,	 Acc = 0.6573,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0688
3159 0.156
3145 0.79
2600 0.867
1323 0.872
890 0.839
760 0.864
71 0.901
20 0.85
0.8372119423317063
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0904,	 Acc = 0.6560,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0742
745 0.217
668 0.737
714 0.868
562 0.817
190 0.7
103 0.825
11 0.909
7 1.0
0.8008869179600887
0.8119733924611974

 ===== Epoch 153	 =====
[ 3.6776052   2.3342302   2.152955    1.0403101   0.26028165  1.5296601
  3.8921423   2.3849187  -0.46656546 -0.4823711   4.0755186   3.2975593
 -0.45947683 -0.42555502] [ 3.6619086   2.3149574   2.1544569   1.0230489   0.25693837  1.4702467
  3.8773901   2.3680835  -0.46656546 -0.4823711   4.056023    3.285861
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0428,	 Acc = 0.6567,	 Loss Con1 = 0.0742,	 Loss Con2 = 0.0698
3163 0.156
3144 0.787
2597 0.868
1321 0.867
890 0.842
762 0.865
71 0.93
20 0.85
0.8365701306076093
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0871,	 Acc = 0.6503,	 Loss Con1 = 0.0712,	 Loss Con2 = 0.0701
745 0.217
668 0.728
714 0.867
562 0.802
190 0.684
103 0.835
11 0.909
7 1.0
0.7933481152993348
0.8119733924611974

 ===== Epoch 154	 =====
[ 0.48699656  1.2520574  -0.5993768  -0.57551634 -0.6348712  -0.6508424
  2.3156986   0.45803142  0.06686668  2.7389603   2.507658    1.7665206
  1.5249434   3.566097  ] [ 0.52827024  1.264378   -0.59937984 -0.57549053 -0.6347739  -0.6507814
  2.3477583   0.4723229   0.10011219  2.6694992   2.5381176   1.7665952
  1.5473528   3.5418081 ] 2 2
train:	 Loss = 1.0430,	 Acc = 0.6578,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0697
3161 0.156
3144 0.789
2595 0.868
1326 0.867
891 0.846
761 0.87
70 0.9
20 0.9
0.8380833427955036
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0936,	 Acc = 0.6443,	 Loss Con1 = 0.0726,	 Loss Con2 = 0.0718
745 0.217
668 0.681
714 0.856
562 0.819
190 0.753
103 0.825
11 0.909
7 1.0
0.7853658536585366
0.8119733924611974

 ===== Epoch 155	 =====
[-0.4557189  -0.49292567  1.4142401   0.5351045  -0.29710895  2.650204
  3.1179395   1.9934019  -0.46656546 -0.4823711   3.6327112   2.8626652
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.4239078   0.5128996  -0.31487936  2.5250494
  3.110191    1.9717709  -0.46656546 -0.4823711   3.6182632   2.8478835
 -0.45947683 -0.42555502] 3 1
train:	 Loss = 1.0421,	 Acc = 0.6568,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0701
3165 0.155
3142 0.789
2597 0.868
1322 0.87
889 0.843
762 0.864
71 0.887
20 0.85
0.8373281835737817
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0690,	 Acc = 0.6557,	 Loss Con1 = 0.0718,	 Loss Con2 = 0.0689
745 0.217
668 0.711
714 0.864
562 0.833
190 0.753
103 0.825
11 0.909
7 1.0
0.8004434589800443
0.8119733924611974

 ===== Epoch 156	 =====
[-0.4557189  -0.49292567  2.0914025   1.3364362   1.7891237   0.0607971
  1.7200475   2.696987   -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  2.0911102   1.508228    1.7892749   0.25198665
  1.7198442   2.9017823  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0430,	 Acc = 0.6581,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0699
3167 0.156
3137 0.789
2598 0.868
1322 0.873
891 0.841
762 0.873
71 0.958
20 0.85
0.8388819452334962
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0893,	 Acc = 0.6460,	 Loss Con1 = 0.0725,	 Loss Con2 = 0.0765
745 0.219
668 0.704
714 0.867
562 0.811
190 0.668
103 0.835
11 0.909
7 1.0
0.7871396895787139
0.8119733924611974

 ===== Epoch 157	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
  1.0445992   1.0561666  -0.46656546 -0.4823711   1.5634413   3.1693192
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
  1.081245    1.0689248  -0.46656546 -0.4823711   1.5882869   3.1493444
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0423,	 Acc = 0.6553,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0716
3163 0.156
3143 0.787
2596 0.865
1324 0.867
890 0.838
761 0.867
71 0.873
20 0.85
0.8347529812606473
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1126,	 Acc = 0.6363,	 Loss Con1 = 0.0729,	 Loss Con2 = 0.0708
745 0.219
668 0.659
714 0.861
562 0.822
190 0.674
103 0.816
11 0.909
7 1.0
0.774279379157428
0.8119733924611974

 ===== Epoch 158	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.45027477  1.6141738
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.44475093  1.6161978
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.0440,	 Acc = 0.6570,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0716
3161 0.157
3139 0.791
2598 0.862
1325 0.869
892 0.84
762 0.87
71 0.915
20 0.85
0.8366072442375383
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0905,	 Acc = 0.6543,	 Loss Con1 = 0.0717,	 Loss Con2 = 0.0685
745 0.217
668 0.702
714 0.867
562 0.833
190 0.742
103 0.835
11 1.0
7 1.0
0.798669623059867
0.8119733924611974

 ===== Epoch 159	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 0
train:	 Loss = 1.0392,	 Acc = 0.6575,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0697
3165 0.156
3143 0.792
2598 0.87
1320 0.869
890 0.842
761 0.857
71 0.859
20 0.85
0.8377825741224583
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1024,	 Acc = 0.6493,	 Loss Con1 = 0.0719,	 Loss Con2 = 0.0694
745 0.217
668 0.692
714 0.861
562 0.831
190 0.737
103 0.816
11 1.0
7 1.0
0.7920177383592018
0.8119733924611974

 ===== Epoch 160	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0430,	 Acc = 0.6577,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0710
3166 0.156
3141 0.791
2597 0.869
1323 0.865
889 0.845
761 0.865
71 0.901
20 0.85
0.8381049761417859
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0992,	 Acc = 0.6460,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0713
745 0.216
668 0.689
714 0.861
562 0.815
190 0.753
103 0.806
11 1.0
7 1.0
0.7880266075388027
0.8119733924611974

 ===== Epoch 161	 =====
[ 0.31314617  1.790154    1.9362613   1.1246797  -0.6348712  -0.6508424
  2.161332    2.7527943  -0.1082581   0.06271521 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 0.3092092   1.6788533   1.9363787   1.1059139  -0.6347739  -0.6507814
  2.1406682   2.7272766  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0455,	 Acc = 0.6564,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0692
3162 0.155
3142 0.789
2598 0.868
1322 0.868
891 0.843
762 0.86
71 0.901
20 0.85
0.836588689529866
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1052,	 Acc = 0.6550,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0722
745 0.217
668 0.707
714 0.868
562 0.831
190 0.737
103 0.835
11 1.0
7 1.0
0.7995565410199557
0.8119733924611974

 ===== Epoch 162	 =====
[-0.4557189  -0.49292567  1.1145233   2.3074334  -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.114336    2.4793673  -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0412,	 Acc = 0.6573,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0700
3162 0.155
3147 0.785
2597 0.871
1319 0.869
892 0.845
760 0.868
71 0.915
20 0.9
0.8376107199636611
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0861,	 Acc = 0.6447,	 Loss Con1 = 0.0724,	 Loss Con2 = 0.0698
745 0.215
668 0.696
714 0.86
562 0.822
190 0.689
103 0.825
11 1.0
7 0.857
0.7866962305986697
0.8119733924611974

 ===== Epoch 163	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.39663878  0.12230956
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.39660582  0.31319648
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0392,	 Acc = 0.6570,	 Loss Con1 = 0.0742,	 Loss Con2 = 0.0704
3166 0.155
3143 0.789
2595 0.866
1321 0.874
890 0.846
762 0.861
71 0.873
20 0.9
0.8374233128834356
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0955,	 Acc = 0.6507,	 Loss Con1 = 0.0723,	 Loss Con2 = 0.0713
745 0.215
668 0.713
714 0.864
562 0.819
190 0.716
103 0.825
11 1.0
7 1.0
0.7946784922394678
0.8119733924611974

 ===== Epoch 164	 =====
[ 1.2495841   3.0942883   1.8184863   1.2389219  -0.6348712  -0.6508424
  1.5652857   2.850899   -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 1.2197294   3.0558114   1.8166972   1.2184643  -0.6347739  -0.6507814
  1.5423262   2.8174944  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0375,	 Acc = 0.6588,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0702
3157 0.155
3146 0.789
2597 0.873
1326 0.871
890 0.843
761 0.873
71 0.873
20 0.9
0.8394052888434911
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1028,	 Acc = 0.6470,	 Loss Con1 = 0.0723,	 Loss Con2 = 0.0691
745 0.217
668 0.698
714 0.854
562 0.82
190 0.753
103 0.835
11 1.0
7 0.286
0.7889135254988914
0.8119733924611974

 ===== Epoch 165	 =====
[ 0.9605333   0.9763649  -0.5993768  -0.57551634  0.75090855  0.3892054
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 0.9605359   0.976366   -0.59937984 -0.57549053  0.7510383   0.38925338
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0415,	 Acc = 0.6565,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0698
3164 0.155
3143 0.788
2595 0.866
1321 0.869
891 0.846
763 0.862
71 0.901
20 0.85
0.8365515674693321
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0857,	 Acc = 0.6460,	 Loss Con1 = 0.0726,	 Loss Con2 = 0.0692
745 0.219
668 0.69
714 0.863
562 0.82
190 0.705
103 0.825
11 1.0
7 1.0
0.7871396895787139
0.8119733924611974

 ===== Epoch 166	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.053515    0.29782838
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.02896139  0.40619656
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0425,	 Acc = 0.6578,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0702
3160 0.156
3141 0.792
2600 0.869
1322 0.868
891 0.845
763 0.861
71 0.859
20 0.8
0.837874659400545
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1002,	 Acc = 0.6497,	 Loss Con1 = 0.0721,	 Loss Con2 = 0.0701
745 0.217
668 0.693
714 0.868
562 0.835
190 0.689
103 0.835
11 1.0
7 1.0
0.7924611973392461
0.8119733924611974

 ===== Epoch 167	 =====
[ 0.94202274  1.3814543   2.0431721   1.1752874   2.4300158   0.05907449
  1.2481731   1.8458929  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 0.94203544  1.1778064   2.0428934   1.0040805   2.4301898  -0.1320112
  1.2480042   1.6408064  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 5
train:	 Loss = 1.0403,	 Acc = 0.6576,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0715
3162 0.155
3146 0.79
2595 0.87
1322 0.864
891 0.85
761 0.867
71 0.901
20 0.75
0.8380649557120146
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1093,	 Acc = 0.6473,	 Loss Con1 = 0.0724,	 Loss Con2 = 0.0705
745 0.219
668 0.713
714 0.867
562 0.811
190 0.663
103 0.816
11 1.0
7 1.0
0.7889135254988914
0.8119733924611974

 ===== Epoch 168	 =====
[-0.4557189  -0.49292567  1.4033413   2.3964775  -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.4239522   2.3810916  -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0393,	 Acc = 0.6583,	 Loss Con1 = 0.0742,	 Loss Con2 = 0.0706
3163 0.156
3140 0.789
2595 0.874
1326 0.87
892 0.839
761 0.866
71 0.887
20 0.9
0.8388415672913118
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0855,	 Acc = 0.6523,	 Loss Con1 = 0.0721,	 Loss Con2 = 0.0688
745 0.219
668 0.711
714 0.867
562 0.81
190 0.747
103 0.825
11 1.0
7 1.0
0.7955654101995565
0.8119733924611974

 ===== Epoch 169	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.6621973   1.2381073
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.6343882   1.237648
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.0439,	 Acc = 0.6587,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0696
3163 0.157
3144 0.788
2595 0.871
1324 0.872
889 0.849
762 0.865
71 0.915
20 0.85
0.8388415672913118
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0985,	 Acc = 0.6453,	 Loss Con1 = 0.0727,	 Loss Con2 = 0.0720
745 0.217
668 0.692
714 0.866
562 0.817
190 0.689
103 0.835
11 1.0
7 1.0
0.7866962305986697
0.8119733924611974

 ===== Epoch 170	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 0
train:	 Loss = 1.0433,	 Acc = 0.6564,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0704
3162 0.156
3143 0.787
2600 0.868
1324 0.867
889 0.843
759 0.866
71 0.873
20 0.8
0.8361344537815126
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0848,	 Acc = 0.6517,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0772
745 0.217
668 0.716
714 0.853
562 0.824
190 0.732
103 0.835
11 1.0
7 1.0
0.7951219512195122
0.8119733924611974

 ===== Epoch 171	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.18144561  1.3075013
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.15363252  1.3092008
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.0403,	 Acc = 0.6557,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0707
3158 0.155
3145 0.783
2599 0.866
1322 0.87
890 0.839
763 0.872
71 0.887
20 0.9
0.8350737797956868
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1111,	 Acc = 0.6427,	 Loss Con1 = 0.0732,	 Loss Con2 = 0.0724
745 0.215
668 0.69
714 0.857
562 0.819
190 0.7
103 0.816
11 1.0
7 1.0
0.7840354767184036
0.8119733924611974

 ===== Epoch 172	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 0
train:	 Loss = 1.0402,	 Acc = 0.6576,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0694
3163 0.156
3145 0.791
2595 0.869
1323 0.867
890 0.845
761 0.858
71 0.915
20 0.9
0.8379329926178308
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0887,	 Acc = 0.6460,	 Loss Con1 = 0.0722,	 Loss Con2 = 0.0706
745 0.217
668 0.684
714 0.863
562 0.82
190 0.732
103 0.825
11 1.0
7 1.0
0.7875831485587583
0.8119733924611974

 ===== Epoch 173	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  1.3318295   1.6724557
 -0.43886673 -0.47319013  0.384967    2.8669226  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  1.3381331   1.6989387
 -0.4389609  -0.47327355  0.40605915  2.945423   -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 4
train:	 Loss = 1.0367,	 Acc = 0.6589,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0700
3163 0.156
3141 0.789
2597 0.872
1325 0.875
891 0.844
761 0.869
70 0.886
20 0.9
0.8397501419647927
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1069,	 Acc = 0.6417,	 Loss Con1 = 0.0729,	 Loss Con2 = 0.0708
745 0.217
668 0.69
714 0.866
562 0.811
190 0.674
103 0.806
11 0.909
7 1.0
0.7818181818181819
0.8119733924611974

 ===== Epoch 174	 =====
[-0.4557189  -0.49292567  1.7650888   1.3151529  -0.6348712  -0.6508424
  2.2584977   3.0905     -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.7926775   1.3135206  -0.6347739  -0.6507814
  2.2864633   3.0713332  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0407,	 Acc = 0.6556,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0700
3165 0.155
3140 0.788
2595 0.867
1325 0.869
891 0.838
761 0.855
71 0.887
20 0.9
0.8353970237419062
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1093,	 Acc = 0.6453,	 Loss Con1 = 0.0729,	 Loss Con2 = 0.0710
745 0.217
668 0.686
714 0.864
562 0.833
190 0.668
103 0.835
11 1.0
7 1.0
0.7866962305986697
0.8119733924611974

 ===== Epoch 175	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
  1.2750715   1.5095536 ] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
  1.2709162   1.5499574 ] 4 4
train:	 Loss = 1.0408,	 Acc = 0.6567,	 Loss Con1 = 0.0731,	 Loss Con2 = 0.0694
3164 0.155
3142 0.789
2595 0.866
1324 0.867
891 0.845
762 0.862
70 0.943
20 0.9
0.8368923216719673
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1174,	 Acc = 0.6410,	 Loss Con1 = 0.0714,	 Loss Con2 = 0.0681
745 0.219
668 0.678
714 0.847
562 0.822
190 0.711
103 0.854
11 0.909
7 1.0
0.7804878048780488
0.8119733924611974

 ===== Epoch 176	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  1.1156318   2.0208027
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  1.1157681   2.0208273
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0390,	 Acc = 0.6585,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0694
3161 0.156
3143 0.792
2599 0.869
1324 0.868
890 0.842
761 0.87
70 0.886
20 0.9
0.838764619053026
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1047,	 Acc = 0.6437,	 Loss Con1 = 0.0729,	 Loss Con2 = 0.0728
745 0.216
668 0.692
714 0.863
562 0.802
190 0.737
103 0.806
11 1.0
7 1.0
0.7849223946784922
0.8119733924611974

 ===== Epoch 177	 =====
[ 1.6934673   1.4844037  -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013  0.4646621   2.3508818   2.4910612   0.3586777
  1.850005    2.135123  ] [ 1.6934673   1.6880451  -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355  0.4646621   2.5643163   2.4910612   0.5792787
  1.850005    2.3606997 ] 6 6
train:	 Loss = 1.0434,	 Acc = 0.6547,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0696
3163 0.156
3143 0.784
2597 0.863
1322 0.868
891 0.84
761 0.867
71 0.915
20 0.9
0.8338444065871664
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0908,	 Acc = 0.6507,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0738
745 0.215
668 0.711
714 0.859
562 0.824
190 0.721
103 0.835
11 1.0
7 1.0
0.7946784922394678
0.8119733924611974

 ===== Epoch 178	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 0
train:	 Loss = 1.0398,	 Acc = 0.6578,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0698
3163 0.155
3141 0.79
2599 0.868
1322 0.868
890 0.846
763 0.87
70 0.914
20 0.85
0.8385008517887564
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0931,	 Acc = 0.6453,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0711
745 0.217
668 0.692
714 0.864
562 0.815
190 0.705
103 0.825
11 1.0
7 1.0
0.7866962305986697
0.8119733924611974

 ===== Epoch 179	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.56123847 -0.18677995
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.58180785 -0.15655068
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0381,	 Acc = 0.6593,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0704
3162 0.156
3144 0.791
2595 0.871
1324 0.876
892 0.843
760 0.868
71 0.859
20 0.9
0.8402225755166932
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1001,	 Acc = 0.6487,	 Loss Con1 = 0.0727,	 Loss Con2 = 0.0729
745 0.219
668 0.69
714 0.856
562 0.831
190 0.737
103 0.835
11 1.0
7 1.0
0.7906873614190687
0.8119733924611974

 ===== Epoch 180	 =====
[-0.4557189  -0.49292567  1.8425046   1.000998   -0.6348712  -0.6508424
  2.3371534   2.6694167  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.8422393   0.8297682  -0.6347739  -0.6507814
  2.3369193   2.4643202  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 5
train:	 Loss = 1.0397,	 Acc = 0.6585,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0702
3163 0.156
3145 0.793
2595 0.87
1322 0.867
890 0.843
762 0.865
71 0.887
20 0.85
0.839068710959682
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0957,	 Acc = 0.6463,	 Loss Con1 = 0.0730,	 Loss Con2 = 0.0726
745 0.217
668 0.698
714 0.866
562 0.824
190 0.679
103 0.816
11 0.909
7 1.0
0.7880266075388027
0.8119733924611974

 ===== Epoch 181	 =====
[ 0.77019745  1.5641421  -0.5993768  -0.57551634 -0.6348712  -0.6508424
  2.5394013   0.79624265  0.30288798  2.6434393   2.7162495   2.0317235
 -0.45947683 -0.42555502] [ 0.76852685  1.7674767  -0.59937984 -0.57549053 -0.6347739  -0.6507814
  2.5378234   1.0005759   0.301456    2.858304    2.7150211   2.2523217
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0383,	 Acc = 0.6581,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0699
3165 0.155
3139 0.791
2599 0.87
1322 0.871
890 0.842
762 0.873
71 0.873
20 0.9
0.839145745768488
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0987,	 Acc = 0.6550,	 Loss Con1 = 0.0730,	 Loss Con2 = 0.0709
745 0.217
668 0.713
714 0.866
562 0.836
190 0.711
103 0.835
11 1.0
7 1.0
0.7995565410199557
0.8119733924611974

 ===== Epoch 182	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 0
train:	 Loss = 1.0370,	 Acc = 0.6590,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0699
3162 0.157
3143 0.792
2596 0.87
1325 0.871
891 0.843
760 0.867
71 0.859
20 0.9
0.839200545082898
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0975,	 Acc = 0.6447,	 Loss Con1 = 0.0716,	 Loss Con2 = 0.0718
745 0.219
668 0.711
714 0.864
562 0.804
190 0.658
103 0.816
11 1.0
7 1.0
0.7853658536585366
0.8119733924611974

 ===== Epoch 183	 =====
[-0.4557189  -0.49292567  1.5480413   1.4943008   2.2960365   0.34402785
  0.5748226   1.7200885  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.5478076   1.3231431   2.296199    0.15293714
  0.5746773   1.5150124  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 5
train:	 Loss = 1.0373,	 Acc = 0.6589,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0708
3162 0.155
3145 0.791
2597 0.874
1323 0.869
889 0.847
762 0.86
71 0.901
19 0.842
0.8398818987054281
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0882,	 Acc = 0.6520,	 Loss Con1 = 0.0719,	 Loss Con2 = 0.0687
745 0.219
668 0.726
714 0.86
562 0.824
190 0.679
103 0.825
11 0.909
7 1.0
0.7951219512195122
0.8119733924611974

 ===== Epoch 184	 =====
[-0.4557189  -0.49292567  1.4224168   2.031666    0.352008    0.01041207
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.4223629   1.8604579   0.3523301  -0.18049194
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 5
train:	 Loss = 1.0356,	 Acc = 0.6593,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0703
3164 0.156
3144 0.792
2596 0.872
1324 0.873
887 0.842
763 0.866
70 0.9
20 0.8
0.8401862789641072
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0957,	 Acc = 0.6433,	 Loss Con1 = 0.0721,	 Loss Con2 = 0.0767
745 0.219
668 0.672
714 0.868
562 0.831
190 0.695
103 0.835
11 1.0
7 0.286
0.7835920177383592
0.8119733924611974

 ===== Epoch 185	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 0
train:	 Loss = 1.0392,	 Acc = 0.6583,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0698
3166 0.155
3144 0.788
2592 0.872
1322 0.873
890 0.844
763 0.866
71 0.915
20 0.85
0.8392410815723699
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0851,	 Acc = 0.6517,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0704
745 0.217
668 0.726
714 0.864
562 0.819
190 0.674
103 0.825
11 1.0
7 1.0
0.7951219512195122
0.8119733924611974

 ===== Epoch 186	 =====
[ 1.928372    0.9668508   1.1689316   2.2996144   1.4308264   0.62964106
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 1.9283854   0.7632079   1.1687427   2.1285665   1.4309787   0.43854567
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 5
train:	 Loss = 1.0398,	 Acc = 0.6580,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0698
3164 0.155
3143 0.789
2596 0.866
1320 0.873
893 0.844
761 0.88
71 0.887
20 0.85
0.8387096774193549
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0964,	 Acc = 0.6457,	 Loss Con1 = 0.0719,	 Loss Con2 = 0.0760
745 0.217
668 0.68
714 0.859
562 0.831
190 0.721
103 0.835
11 1.0
7 1.0
0.7871396895787139
0.8119733924611974

 ===== Epoch 187	 =====
[-0.4557189  -0.49292567  0.77351093  1.2945479  -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  0.7733604   1.123361   -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 5
train:	 Loss = 1.0381,	 Acc = 0.6593,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0694
3158 0.157
3148 0.792
2593 0.869
1323 0.868
893 0.851
762 0.864
71 0.901
20 0.9
0.8392735527809307
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0918,	 Acc = 0.6517,	 Loss Con1 = 0.0734,	 Loss Con2 = 0.0724
745 0.217
668 0.704
714 0.868
562 0.827
190 0.711
103 0.835
11 0.909
7 1.0
0.7951219512195122
0.8119733924611974

 ===== Epoch 188	 =====
[ 3.6837435   2.412594   -0.5993768  -0.57551634  2.5996258   2.0284986
 -0.43886673 -0.47319013  2.6630461   1.692618   -0.4178274  -0.43225467
  1.7825347   0.41165665] [ 3.6768146   2.4050522  -0.59937984 -0.57549053  2.5954416   2.0224357
 -0.4389609  -0.47327355  2.662793    1.682238   -0.4178274  -0.43225467
  1.7899193   0.40150186] 3 3
train:	 Loss = 1.0385,	 Acc = 0.6585,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0694
3164 0.155
3142 0.793
2597 0.87
1323 0.869
891 0.844
761 0.867
71 0.887
19 0.842
0.8396183552930486
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0958,	 Acc = 0.6530,	 Loss Con1 = 0.0732,	 Loss Con2 = 0.0702
745 0.217
668 0.705
714 0.863
562 0.829
190 0.737
103 0.835
11 1.0
7 1.0
0.7968957871396896
0.8119733924611974

 ===== Epoch 189	 =====
[-0.4557189  -0.49292567  0.9299266   2.3519936   2.2542827   1.4437085
  0.50384957  0.6384352   3.011442    0.77925324 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  0.9297592   2.2495556   2.2544444   1.3290583
  0.5037078   0.51536053  3.011442    0.6511926  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
train:	 Loss = 1.0386,	 Acc = 0.6577,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0692
3158 0.155
3140 0.79
2601 0.869
1326 0.868
889 0.839
763 0.87
71 0.873
20 0.9
0.8377979568671964
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0798,	 Acc = 0.6543,	 Loss Con1 = 0.0734,	 Loss Con2 = 0.0714
745 0.216
668 0.72
714 0.867
562 0.817
190 0.732
103 0.835
11 1.0
7 1.0
0.7991130820399113
0.8119733924611974

 ===== Epoch 190	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.88345647  1.9648468
 -0.43886673 -0.47319013 -0.12322165  0.31243682 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.87959856  2.066389
 -0.4389609  -0.47327355 -0.11407078  0.3656394  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 4
train:	 Loss = 1.0389,	 Acc = 0.6572,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0687
3165 0.154
3142 0.788
2598 0.869
1319 0.872
892 0.842
761 0.866
71 0.901
20 0.9
0.8380097693967965
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0946,	 Acc = 0.6497,	 Loss Con1 = 0.0746,	 Loss Con2 = 0.0759
745 0.217
668 0.719
714 0.866
562 0.815
190 0.684
103 0.806
11 1.0
7 1.0
0.7924611973392461
0.8119733924611974

 ===== Epoch 191	 =====
[-0.4557189  -0.49292567  0.17614709  1.0172719  -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  0.1760607   1.189017   -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0418,	 Acc = 0.6598,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0696
3165 0.157
3142 0.79
2596 0.874
1321 0.87
890 0.845
763 0.873
71 0.915
20 0.85
0.8405089174145178
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1247,	 Acc = 0.6363,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0716
745 0.219
668 0.726
714 0.833
562 0.786
190 0.663
103 0.786
11 0.909
7 1.0
0.774279379157428
0.8119733924611974

 ===== Epoch 192	 =====
[-0.4557189  -0.49292567  1.0745342   2.308461   -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0922334   2.3310707  -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 4
train:	 Loss = 1.0434,	 Acc = 0.6576,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0693
3164 0.156
3144 0.786
2598 0.87
1325 0.876
886 0.844
761 0.862
70 0.9
20 0.9
0.8379145842798728
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1041,	 Acc = 0.6523,	 Loss Con1 = 0.0722,	 Loss Con2 = 0.0709
745 0.216
668 0.716
714 0.861
562 0.82
190 0.726
103 0.845
11 0.909
7 1.0
0.7964523281596453
0.8119733924611974

 ===== Epoch 193	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 0
train:	 Loss = 1.0381,	 Acc = 0.6573,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0693
3163 0.156
3144 0.79
2597 0.869
1324 0.869
889 0.848
760 0.855
71 0.887
20 0.85
0.8375922771152754
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1172,	 Acc = 0.6457,	 Loss Con1 = 0.0730,	 Loss Con2 = 0.0745
745 0.217
668 0.698
714 0.866
562 0.826
190 0.663
103 0.806
11 1.0
7 1.0
0.7871396895787139
0.8119733924611974

 ===== Epoch 194	 =====
[-0.4557189  -0.49292567  1.1242661   1.9494749  -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.1318227   1.9647683  -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 4
train:	 Loss = 1.0407,	 Acc = 0.6583,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0694
3165 0.156
3143 0.79
2593 0.871
1324 0.869
892 0.842
760 0.868
71 0.873
20 0.9
0.8388049528569805
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0966,	 Acc = 0.6500,	 Loss Con1 = 0.0734,	 Loss Con2 = 0.0723
745 0.217
668 0.704
714 0.87
562 0.82
190 0.705
103 0.816
11 1.0
7 1.0
0.7929046563192904
0.8119733924611974

 ===== Epoch 195	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
  0.6904877   1.7454503  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
  0.6527765   1.7512282  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.0394,	 Acc = 0.6584,	 Loss Con1 = 0.0734,	 Loss Con2 = 0.0684
3163 0.155
3145 0.788
2599 0.871
1323 0.871
889 0.847
758 0.875
71 0.915
20 0.9
0.8394094264622374
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1118,	 Acc = 0.6480,	 Loss Con1 = 0.0725,	 Loss Con2 = 0.0689
745 0.219
668 0.708
714 0.857
562 0.826
190 0.674
103 0.835
11 1.0
7 1.0
0.78980044345898
0.8119733924611974

 ===== Epoch 196	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 0
train:	 Loss = 1.0347,	 Acc = 0.6571,	 Loss Con1 = 0.0734,	 Loss Con2 = 0.0688
3161 0.155
3143 0.786
2598 0.868
1323 0.87
892 0.844
761 0.869
71 0.915
19 0.895
0.8371749744521404
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1137,	 Acc = 0.6480,	 Loss Con1 = 0.0722,	 Loss Con2 = 0.0708
745 0.217
668 0.698
714 0.866
562 0.829
190 0.674
103 0.835
11 1.0
7 1.0
0.7902439024390244
0.8119733924611974

 ===== Epoch 197	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 0
train:	 Loss = 1.0389,	 Acc = 0.6590,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0700
3163 0.156
3146 0.79
2596 0.871
1323 0.872
887 0.851
762 0.862
71 0.901
20 0.9
0.8398637137989778
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0986,	 Acc = 0.6543,	 Loss Con1 = 0.0730,	 Loss Con2 = 0.0710
745 0.219
668 0.719
714 0.863
562 0.831
190 0.7
103 0.845
11 0.909
7 1.0
0.7982261640798226
0.8119733924611974

 ===== Epoch 198	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0460,	 Acc = 0.6560,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0695
3164 0.155
3146 0.785
2596 0.866
1322 0.865
890 0.846
761 0.871
69 0.913
20 0.9
0.8358700590640618
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1226,	 Acc = 0.6523,	 Loss Con1 = 0.0722,	 Loss Con2 = 0.0706
745 0.219
668 0.711
714 0.864
562 0.827
190 0.705
103 0.835
11 0.909
7 1.0
0.7955654101995565
0.8119733924611974

 ===== Epoch 199	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 0
train:	 Loss = 1.0408,	 Acc = 0.6594,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0696
3163 0.156
3146 0.793
2593 0.868
1323 0.875
891 0.848
761 0.865
71 0.901
20 0.9
0.8402044293015333
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1127,	 Acc = 0.6487,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0711
745 0.219
668 0.692
714 0.861
562 0.822
190 0.753
103 0.816
11 0.909
7 1.0
0.7906873614190687
0.8119733924611974

 ===== Epoch 200	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  1.6446462   1.5971398
 -0.43886673 -0.47319013  0.76794803  2.4111211  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  1.6393242   1.5979773
 -0.4389609  -0.47327355  0.760856    2.4156744  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.0376,	 Acc = 0.6566,	 Loss Con1 = 0.0731,	 Loss Con2 = 0.0682
3165 0.156
3145 0.79
2593 0.863
1323 0.87
892 0.843
760 0.867
70 0.9
20 0.9
0.8366465977507668
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1053,	 Acc = 0.6480,	 Loss Con1 = 0.0716,	 Loss Con2 = 0.0709
745 0.217
668 0.701
714 0.864
562 0.822
190 0.689
103 0.835
11 1.0
7 1.0
0.7902439024390244
0.8119733924611974

 ===== Epoch 201	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.59755164  2.0448449
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.5976764   2.0448694
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0405,	 Acc = 0.6583,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0694
3162 0.156
3140 0.79
2597 0.869
1325 0.872
892 0.845
761 0.866
71 0.915
20 0.85
0.8387463093345446
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1104,	 Acc = 0.6420,	 Loss Con1 = 0.0750,	 Loss Con2 = 0.0718
745 0.217
668 0.69
714 0.86
562 0.813
190 0.689
103 0.806
11 1.0
7 1.0
0.7822616407982261
0.8119733924611974

 ===== Epoch 202	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 0
train:	 Loss = 1.0368,	 Acc = 0.6579,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0689
3165 0.155
3145 0.789
2595 0.871
1321 0.87
889 0.845
762 0.866
71 0.915
20 0.9
0.8388049528569805
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1151,	 Acc = 0.6513,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0718
745 0.217
668 0.705
714 0.864
562 0.835
190 0.695
103 0.825
11 1.0
7 1.0
0.7946784922394678
0.8119733924611974

 ===== Epoch 203	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013  0.74407643  2.3128357  -0.4178274  -0.43225467
  1.4310352   0.33120868] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355  0.74407655  2.5262697  -0.4178274  -0.43225467
  1.4310352   0.5567852 ] 6 6
train:	 Loss = 1.0341,	 Acc = 0.6593,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0689
3163 0.155
3145 0.794
2595 0.873
1320 0.865
891 0.846
763 0.868
71 0.901
20 0.9
0.8406587166382737
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1080,	 Acc = 0.6433,	 Loss Con1 = 0.0727,	 Loss Con2 = 0.0679
745 0.217
668 0.678
714 0.86
562 0.831
190 0.689
103 0.835
11 0.909
7 1.0
0.7840354767184036
0.8119733924611974

 ===== Epoch 204	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  2.0098698   1.5988699
 -0.43886673 -0.47319013  2.0464282   0.9096841  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  2.0375314   1.5953809
 -0.4389609  -0.47327355  2.082223    0.9205458  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0388,	 Acc = 0.6576,	 Loss Con1 = 0.0732,	 Loss Con2 = 0.0694
3160 0.156
3144 0.791
2598 0.867
1322 0.866
893 0.84
760 0.871
71 0.901
20 0.85
0.8375340599455041
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1334,	 Acc = 0.6483,	 Loss Con1 = 0.0717,	 Loss Con2 = 0.0710
745 0.219
668 0.711
714 0.854
562 0.822
190 0.689
103 0.835
11 1.0
7 1.0
0.7902439024390244
0.8119733924611974

 ===== Epoch 205	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 0
train:	 Loss = 1.0396,	 Acc = 0.6573,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0696
3162 0.156
3141 0.79
2597 0.867
1325 0.866
891 0.844
761 0.867
71 0.887
20 0.9
0.8372700431523961
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1204,	 Acc = 0.6487,	 Loss Con1 = 0.0722,	 Loss Con2 = 0.0693
745 0.217
668 0.692
714 0.864
562 0.817
190 0.753
103 0.825
11 1.0
7 1.0
0.7911308203991131
0.8119733924611974

 ===== Epoch 206	 =====
[ 3.9890141   0.875707    2.3702574   1.4876633   2.7880745   0.5501208
  1.6733235   2.066953    2.7095141   0.19632311 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 4.0288134   0.8818541   2.3975058   1.4847383   2.8142927   0.55578995
  1.7100598   2.0582173   2.739134    0.21229416 -0.18474396  3.3870451
 -0.45947683 -0.42555502] 2 5
train:	 Loss = 1.0363,	 Acc = 0.6570,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0694
3163 0.156
3144 0.786
2596 0.867
1323 0.869
891 0.841
761 0.875
70 0.929
20 0.85
0.8370244179443498
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1135,	 Acc = 0.6457,	 Loss Con1 = 0.0723,	 Loss Con2 = 0.0705
745 0.216
668 0.719
714 0.856
562 0.817
190 0.663
103 0.796
11 1.0
7 1.0
0.7875831485587583
0.8119733924611974

 ===== Epoch 207	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0354,	 Acc = 0.6603,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0692
3158 0.155
3143 0.796
2602 0.87
1322 0.871
892 0.842
760 0.871
71 0.901
20 0.9
0.841316685584563
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1012,	 Acc = 0.6513,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0745
745 0.217
668 0.699
714 0.867
562 0.827
190 0.726
103 0.825
11 1.0
7 1.0
0.7946784922394678
0.8119733924611974

 ===== Epoch 208	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 0
train:	 Loss = 1.0383,	 Acc = 0.6582,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0709
3164 0.155
3144 0.789
2597 0.869
1325 0.871
887 0.847
760 0.874
71 0.887
20 0.85
0.8388232621535665
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0952,	 Acc = 0.6477,	 Loss Con1 = 0.0732,	 Loss Con2 = 0.0700
745 0.217
668 0.716
714 0.852
562 0.82
190 0.689
103 0.835
11 0.909
7 1.0
0.78980044345898
0.8119733924611974

 ===== Epoch 209	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 0
train:	 Loss = 1.0371,	 Acc = 0.6583,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0693
3162 0.155
3144 0.791
2597 0.871
1324 0.867
891 0.843
759 0.87
71 0.901
20 0.85
0.838859868271633
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1061,	 Acc = 0.6503,	 Loss Con1 = 0.0730,	 Loss Con2 = 0.0734
745 0.217
668 0.714
714 0.874
562 0.811
190 0.679
103 0.835
11 0.909
7 1.0
0.7933481152993348
0.8119733924611974

 ===== Epoch 210	 =====
[ 3.1292844   1.9745431  -0.5993768  -0.57551634 -0.6348712  -0.6508424
  2.5536692   1.2934548  -0.46656546 -0.4823711   3.0034728   2.3670168
 -0.45947683 -0.42555502] [ 3.1206846   1.9511492  -0.59937984 -0.57549053 -0.6347739  -0.6507814
  2.5588782   1.2675948  -0.46656546 -0.4823711   2.9954376   2.347885
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0394,	 Acc = 0.6587,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0697
3160 0.157
3144 0.789
2596 0.871
1323 0.868
892 0.844
763 0.873
70 0.871
20 0.85
0.8387829246139873
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0976,	 Acc = 0.6493,	 Loss Con1 = 0.0721,	 Loss Con2 = 0.0698
745 0.217
668 0.695
714 0.866
562 0.827
190 0.716
103 0.835
11 0.909
7 1.0
0.7920177383592018
0.8119733924611974

 ===== Epoch 211	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 0
train:	 Loss = 1.0405,	 Acc = 0.6578,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0691
3162 0.156
3143 0.786
2600 0.868
1322 0.868
889 0.849
761 0.873
71 0.944
20 0.9
0.8379513967749261
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1028,	 Acc = 0.6410,	 Loss Con1 = 0.0725,	 Loss Con2 = 0.0732
745 0.217
668 0.684
714 0.86
562 0.815
190 0.674
103 0.835
11 1.0
7 1.0
0.7809312638580931
0.8119733924611974

 ===== Epoch 212	 =====
[-0.4557189  -0.49292567  1.3775482   2.4167502  -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.3773328   2.4172137  -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0366,	 Acc = 0.6596,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0695
3162 0.157
3142 0.792
2597 0.872
1324 0.873
891 0.844
761 0.861
71 0.915
20 0.85
0.8401090165796048
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0867,	 Acc = 0.6490,	 Loss Con1 = 0.0731,	 Loss Con2 = 0.0715
745 0.217
668 0.702
714 0.861
562 0.835
190 0.674
103 0.835
11 1.0
7 1.0
0.7915742793791575
0.8119733924611974

 ===== Epoch 213	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  1.1601006   2.4270341
 -0.43886673 -0.47319013  0.35920858  1.4187326  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  1.1653664   2.4493077
 -0.4389609  -0.47327355  0.34595343  1.4870012  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 4
train:	 Loss = 1.0365,	 Acc = 0.6599,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0710
3161 0.155
3145 0.797
2599 0.868
1320 0.87
891 0.848
761 0.869
71 0.873
20 0.9
0.8410355399114341
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0955,	 Acc = 0.6503,	 Loss Con1 = 0.0727,	 Loss Con2 = 0.0733
745 0.22
668 0.711
714 0.863
562 0.826
190 0.684
103 0.816
11 1.0
7 1.0
0.7924611973392461
0.8119733924611974

 ===== Epoch 214	 =====
[ 0.8040038   1.9507123   1.8615855   0.80269885 -0.6348712  -0.6508424
  1.2233024   1.9856068  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 0.79633534  1.8836466   1.8669591   0.7837247  -0.6347739  -0.6507814
  1.2160051   1.9393066  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0376,	 Acc = 0.6591,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0705
3163 0.155
3141 0.79
2594 0.872
1326 0.871
892 0.85
761 0.866
71 0.915
20 0.85
0.8400908574673481
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0939,	 Acc = 0.6513,	 Loss Con1 = 0.0713,	 Loss Con2 = 0.0674
745 0.219
668 0.705
714 0.864
562 0.827
190 0.7
103 0.845
11 1.0
7 1.0
0.7942350332594235
0.8119733924611974

 ===== Epoch 215	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013  1.6519595   0.7229974  -0.4178274  -0.43225467
  2.8321116   1.0550739 ] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355  1.6865118   0.73890615 -0.4178274  -0.43225467
  2.8615882   1.0622362 ] 2 2
train:	 Loss = 1.0353,	 Acc = 0.6607,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0686
3162 0.155
3147 0.795
2595 0.872
1324 0.872
891 0.848
758 0.871
71 0.915
20 0.9
0.8421530774471951
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0983,	 Acc = 0.6433,	 Loss Con1 = 0.0717,	 Loss Con2 = 0.0675
745 0.216
668 0.687
714 0.861
562 0.826
190 0.684
103 0.806
11 1.0
7 1.0
0.7844789356984478
0.8119733924611974

 ===== Epoch 216	 =====
[-0.4557189  -0.49292567  0.01616145  0.8119401  -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  0.04374949  0.8264264  -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0435,	 Acc = 0.6573,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0694
3164 0.155
3144 0.788
2597 0.87
1320 0.866
890 0.849
762 0.862
71 0.93
20 0.85
0.8376874148114494
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1095,	 Acc = 0.6433,	 Loss Con1 = 0.0721,	 Loss Con2 = 0.0685
745 0.217
668 0.692
714 0.867
562 0.806
190 0.689
103 0.825
11 1.0
7 1.0
0.7840354767184036
0.8119733924611974

 ===== Epoch 217	 =====
[ 2.3391953   1.8445044  -0.5993768  -0.57551634 -0.6348712  -0.6508424
  1.3715417   3.1628952   3.769395    2.7278233   1.1624695   1.1522068
  3.0776794   1.9537941 ] [ 2.3333158   1.8140932  -0.59937984 -0.57549053 -0.6347739  -0.6507814
  1.3449596   3.131438    3.7511315   2.7109337   1.1713011   1.11117
  3.076108    1.9338228 ] 3 3
train:	 Loss = 1.0391,	 Acc = 0.6604,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0701
3161 0.157
3148 0.794
2593 0.874
1323 0.867
892 0.845
760 0.866
71 0.944
20 0.9
0.8411490859543544
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1202,	 Acc = 0.6490,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0721
745 0.217
668 0.692
714 0.863
562 0.82
190 0.747
103 0.845
11 0.909
7 1.0
0.7915742793791575
0.8119733924611974

 ===== Epoch 218	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.39648554  0.31314856
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.39663652  0.5043951
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0375,	 Acc = 0.6585,	 Loss Con1 = 0.0734,	 Loss Con2 = 0.0689
3168 0.155
3143 0.786
2598 0.875
1319 0.871
890 0.846
759 0.872
71 0.915
20 0.85
0.8397727272727272
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1084,	 Acc = 0.6377,	 Loss Con1 = 0.0757,	 Loss Con2 = 0.0743
745 0.219
668 0.662
714 0.859
562 0.822
190 0.7
103 0.806
11 0.909
7 1.0
0.7760532150776053
0.8119733924611974

 ===== Epoch 219	 =====
[-0.4557189  -0.49292567  1.1024078   2.1409965   1.0541576   0.14367156
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.1210468   2.1290321   1.0729789   0.15752874
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0379,	 Acc = 0.6574,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0712
3160 0.156
3145 0.787
2600 0.869
1322 0.872
890 0.84
761 0.865
70 0.914
20 0.9
0.8373069936421436
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1060,	 Acc = 0.6433,	 Loss Con1 = 0.0722,	 Loss Con2 = 0.0675
745 0.217
668 0.692
714 0.861
562 0.819
190 0.689
103 0.806
11 0.909
7 1.0
0.7840354767184036
0.8119733924611974

 ===== Epoch 220	 =====
[ 0.3405091   0.9547474   1.947064    0.9804195  -0.6348712  -0.6508424
  2.0165052   2.5499134  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 0.33369222  1.0172042   1.9452828   0.9920086  -0.6347739  -0.6507814
  2.0267992   2.5666277  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 4
train:	 Loss = 1.0364,	 Acc = 0.6595,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0695
3162 0.156
3141 0.793
2598 0.872
1322 0.865
893 0.849
762 0.869
70 0.871
20 0.9
0.8402225755166932
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1427,	 Acc = 0.6427,	 Loss Con1 = 0.0723,	 Loss Con2 = 0.0693
745 0.219
668 0.705
714 0.85
562 0.819
190 0.658
103 0.816
11 1.0
7 1.0
0.7827050997782705
0.8119733924611974

 ===== Epoch 221	 =====
[ 0.04610348  3.0956688   2.1896763   1.6031938   1.5385927   0.37046275
  2.126368    3.1121264   0.60233057  0.40792763 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 0.07727348  2.9844644   2.2164953   1.5989509   1.5637338   0.381413
  2.154083    3.091497    0.63428545  0.44854632 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0360,	 Acc = 0.6598,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0700
3162 0.155
3142 0.796
2597 0.867
1323 0.87
891 0.852
762 0.871
71 0.873
20 0.9
0.8410174880763116
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1212,	 Acc = 0.6390,	 Loss Con1 = 0.0728,	 Loss Con2 = 0.0688
745 0.217
668 0.689
714 0.845
562 0.829
190 0.663
103 0.796
11 1.0
7 1.0
0.7782705099778271
0.8119733924611974

 ===== Epoch 222	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 0
train:	 Loss = 1.0360,	 Acc = 0.6583,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0698
3166 0.156
3143 0.791
2596 0.87
1323 0.868
888 0.843
761 0.866
71 0.915
20 0.9
0.8387866394001363
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1327,	 Acc = 0.6447,	 Loss Con1 = 0.0725,	 Loss Con2 = 0.0688
745 0.219
668 0.725
714 0.845
562 0.808
190 0.684
103 0.796
11 1.0
7 1.0
0.7853658536585366
0.8119733924611974

 ===== Epoch 223	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711   0.9545621   1.1387886
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711   0.9545636   1.3593873
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0384,	 Acc = 0.6610,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0700
3159 0.155
3147 0.795
2596 0.872
1324 0.873
889 0.845
763 0.869
70 0.914
20 0.9
0.8423203541832217
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1039,	 Acc = 0.6480,	 Loss Con1 = 0.0714,	 Loss Con2 = 0.0675
745 0.216
668 0.695
714 0.864
562 0.815
190 0.742
103 0.825
11 1.0
7 1.0
0.7906873614190687
0.8119733924611974

 ===== Epoch 224	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  1.7979432   1.1128225
 -0.2946521   1.728489    2.1721504   0.18223245 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  1.7968863   1.135478
 -0.2856251   2.2593548   2.1483188   0.20754325 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 6
train:	 Loss = 1.0375,	 Acc = 0.6580,	 Loss Con1 = 0.0734,	 Loss Con2 = 0.0695
3160 0.155
3144 0.79
2597 0.863
1323 0.871
891 0.854
762 0.874
71 0.915
20 0.85
0.8384423251589465
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1189,	 Acc = 0.6507,	 Loss Con1 = 0.0727,	 Loss Con2 = 0.0690
745 0.217
668 0.708
714 0.866
562 0.817
190 0.716
103 0.835
11 1.0
7 1.0
0.7937915742793792
0.8119733924611974

 ===== Epoch 225	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.252983    2.1919408
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.26651937  2.2443755
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 4
train:	 Loss = 1.0335,	 Acc = 0.6597,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0691
3163 0.156
3143 0.792
2595 0.868
1323 0.873
892 0.849
761 0.874
71 0.901
20 0.9
0.8406587166382737
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1202,	 Acc = 0.6463,	 Loss Con1 = 0.0727,	 Loss Con2 = 0.0714
745 0.219
668 0.719
714 0.853
562 0.817
190 0.684
103 0.777
11 1.0
7 1.0
0.7875831485587583
0.8119733924611974

 ===== Epoch 226	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 0
train:	 Loss = 1.0376,	 Acc = 0.6596,	 Loss Con1 = 0.0734,	 Loss Con2 = 0.0701
3162 0.156
3147 0.791
2599 0.871
1321 0.871
890 0.848
758 0.871
71 0.901
20 0.85
0.8404496933908698
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1143,	 Acc = 0.6533,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0691
745 0.219
668 0.714
714 0.864
562 0.826
190 0.716
103 0.825
11 1.0
7 1.0
0.7968957871396896
0.8119733924611974

 ===== Epoch 227	 =====
[-0.4557189  -0.49292567  0.8187712   2.0800729   1.2524389   0.07232681
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  0.8186158   2.2519734   1.2525784   0.26351634
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0341,	 Acc = 0.6593,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0696
3162 0.156
3143 0.793
2596 0.872
1323 0.87
890 0.844
763 0.866
71 0.887
20 0.85
0.8402225755166932
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1009,	 Acc = 0.6477,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0710
745 0.217
668 0.689
714 0.857
562 0.824
190 0.753
103 0.825
11 1.0
7 1.0
0.78980044345898
0.8119733924611974

 ===== Epoch 228	 =====
[-0.4557189  -0.49292567  0.7218318   1.5470383  -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  0.7490549   1.538933   -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0343,	 Acc = 0.6577,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0699
3165 0.155
3142 0.793
2600 0.869
1323 0.862
889 0.844
759 0.866
70 0.914
20 0.9
0.838350562308304
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1177,	 Acc = 0.6507,	 Loss Con1 = 0.0747,	 Loss Con2 = 0.0727
745 0.219
668 0.714
714 0.863
562 0.831
190 0.658
103 0.835
11 1.0
7 1.0
0.7933481152993348
0.8119733924611974

 ===== Epoch 229	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.99100447  0.89690137
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.99113065  1.0880736
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0371,	 Acc = 0.6604,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0710
3160 0.156
3144 0.795
2597 0.867
1322 0.877
891 0.851
763 0.864
71 0.901
20 0.9
0.8412806539509536
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1358,	 Acc = 0.6463,	 Loss Con1 = 0.0721,	 Loss Con2 = 0.0705
745 0.217
668 0.696
714 0.854
562 0.829
190 0.695
103 0.835
11 1.0
7 1.0
0.7880266075388027
0.8119733924611974

 ===== Epoch 230	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 0
train:	 Loss = 1.0325,	 Acc = 0.6593,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0699
3167 0.155
3139 0.794
2596 0.869
1324 0.869
890 0.846
762 0.874
71 0.901
19 0.895
0.8406999204635837
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0990,	 Acc = 0.6497,	 Loss Con1 = 0.0755,	 Loss Con2 = 0.0746
745 0.217
668 0.705
714 0.864
562 0.815
190 0.726
103 0.825
11 1.0
7 1.0
0.7924611973392461
0.8119733924611974

 ===== Epoch 231	 =====
[ 2.7804465   2.6633587   1.9330503   1.220234    0.19760863  0.2764873
  3.0554824   2.8141913  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 2.7804465   2.5411737   1.932775    1.1176307   0.19772449  0.16185275
  3.055212    2.6910703  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 5
train:	 Loss = 1.0348,	 Acc = 0.6568,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0691
3164 0.155
3145 0.788
2595 0.867
1322 0.87
889 0.838
762 0.874
71 0.859
20 0.9
0.837005906406179
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0969,	 Acc = 0.6493,	 Loss Con1 = 0.0729,	 Loss Con2 = 0.0708
745 0.217
668 0.714
714 0.857
562 0.829
190 0.668
103 0.835
11 1.0
7 1.0
0.7920177383592018
0.8119733924611974

 ===== Epoch 232	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 0
train:	 Loss = 1.0365,	 Acc = 0.6591,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0694
3161 0.157
3143 0.79
2599 0.87
1319 0.871
892 0.84
763 0.873
71 0.901
20 0.9
0.839332349267628
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1049,	 Acc = 0.6490,	 Loss Con1 = 0.0718,	 Loss Con2 = 0.0703
745 0.217
668 0.692
714 0.87
562 0.831
190 0.689
103 0.835
11 1.0
7 1.0
0.7915742793791575
0.8119733924611974

 ===== Epoch 233	 =====
[-0.4557189  -0.49292567  1.1358262   2.4575431   0.77070194  0.3170987
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.1155206   2.4775941   0.7462909   0.2988119
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.0342,	 Acc = 0.6585,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0705
3163 0.156
3141 0.786
2594 0.87
1326 0.878
891 0.848
762 0.87
71 0.873
20 0.9
0.839068710959682
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1022,	 Acc = 0.6533,	 Loss Con1 = 0.0721,	 Loss Con2 = 0.0693
745 0.219
668 0.71
714 0.859
562 0.826
190 0.742
103 0.845
11 1.0
7 1.0
0.7968957871396896
0.8119733924611974

 ===== Epoch 234	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 0
train:	 Loss = 1.0306,	 Acc = 0.6600,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0703
3166 0.156
3139 0.794
2598 0.869
1322 0.877
890 0.845
763 0.873
70 0.871
20 0.9
0.8413996818904794
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1351,	 Acc = 0.6503,	 Loss Con1 = 0.0760,	 Loss Con2 = 0.0728
745 0.217
668 0.704
714 0.864
562 0.822
190 0.726
103 0.816
11 1.0
7 1.0
0.7933481152993348
0.8119733924611974

 ===== Epoch 235	 =====
[-0.4557189  -0.49292567  1.1863703   0.515294   -0.6348712  -0.6508424
  1.1465952   2.6889348  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.1861753   0.5497766  -0.6347739  -0.6507814
  1.1464212   2.7297738  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 4
train:	 Loss = 1.0367,	 Acc = 0.6579,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0694
3159 0.155
3147 0.788
2595 0.868
1324 0.873
890 0.845
762 0.869
71 0.901
20 0.9
0.8382336247020094
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1086,	 Acc = 0.6483,	 Loss Con1 = 0.0725,	 Loss Con2 = 0.0725
745 0.217
668 0.692
714 0.863
562 0.829
190 0.716
103 0.825
11 1.0
7 1.0
0.7906873614190687
0.8119733924611974

 ===== Epoch 236	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 0
train:	 Loss = 1.0287,	 Acc = 0.6598,	 Loss Con1 = 0.0734,	 Loss Con2 = 0.0695
3163 0.156
3142 0.789
2596 0.874
1322 0.87
892 0.845
763 0.877
71 0.915
19 0.842
0.8405451448040886
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0951,	 Acc = 0.6483,	 Loss Con1 = 0.0727,	 Loss Con2 = 0.0685
745 0.217
668 0.702
714 0.864
562 0.815
190 0.711
103 0.835
11 1.0
7 1.0
0.7906873614190687
0.8119733924611974

 ===== Epoch 237	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.18724433  1.9428813
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.21320158  1.9872738
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.0337,	 Acc = 0.6578,	 Loss Con1 = 0.0732,	 Loss Con2 = 0.0695
3163 0.156
3144 0.789
2596 0.865
1324 0.872
890 0.848
760 0.872
71 0.873
20 0.9
0.8379329926178308
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1086,	 Acc = 0.6507,	 Loss Con1 = 0.0749,	 Loss Con2 = 0.0830
745 0.217
668 0.693
714 0.863
562 0.819
190 0.784
103 0.816
11 1.0
7 1.0
0.7937915742793792
0.8119733924611974

 ===== Epoch 238	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.30629945 -0.2398726
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 5
train:	 Loss = 1.0356,	 Acc = 0.6605,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0709
3163 0.155
3145 0.797
2596 0.87
1321 0.871
891 0.852
762 0.867
70 0.871
20 0.85
0.8421351504826803
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1008,	 Acc = 0.6467,	 Loss Con1 = 0.0721,	 Loss Con2 = 0.0694
745 0.217
668 0.689
714 0.864
562 0.827
190 0.711
103 0.806
11 1.0
7 1.0
0.788470066518847
0.8119733924611974

 ===== Epoch 239	 =====
[-0.4557189  -0.49292567  1.8425046   0.5209067  -0.6348712  -0.6508424
  2.3371534   2.0955553  -0.19880703  3.0822582  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.8422393   0.52109283 -0.6347739  -0.6507814
  2.3369193   2.0954175  -0.19880703  3.0822582  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0326,	 Acc = 0.6602,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0696
3163 0.156
3143 0.79
2595 0.87
1323 0.877
891 0.855
763 0.874
70 0.871
20 0.85
0.8413401476433845
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1269,	 Acc = 0.6440,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0704
745 0.219
668 0.723
714 0.842
562 0.811
190 0.658
103 0.835
11 1.0
7 1.0
0.7844789356984478
0.8119733924611974

 ===== Epoch 240	 =====
[-0.4557189  -0.49292567  1.3912212   1.5602473   1.5792899  -0.01914961
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.4125203   1.562985    1.5903208  -0.00308675
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 2
train:	 Loss = 1.0315,	 Acc = 0.6590,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0689
3162 0.155
3145 0.793
2593 0.869
1323 0.872
891 0.846
763 0.87
71 0.873
20 0.9
0.8401090165796048
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0878,	 Acc = 0.6510,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0730
745 0.217
668 0.704
714 0.866
562 0.826
190 0.726
103 0.806
11 1.0
7 1.0
0.7942350332594235
0.8119733924611974

 ===== Epoch 241	 =====
[ 0.5489292   0.1678929  -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711   2.2890816   1.190203
  1.7082583   3.1356745 ] [ 0.57572454  0.10305429 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711   2.2972715   1.166113
  1.6913042   3.108188  ] 3 3
train:	 Loss = 1.0338,	 Acc = 0.6581,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0701
3164 0.155
3145 0.787
2595 0.868
1321 0.875
892 0.849
760 0.867
71 0.944
20 0.9
0.8387096774193549
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1038,	 Acc = 0.6483,	 Loss Con1 = 0.0745,	 Loss Con2 = 0.0716
745 0.216
668 0.704
714 0.861
562 0.822
190 0.721
103 0.806
11 0.909
7 1.0
0.7911308203991131
0.8119733924611974

 ===== Epoch 242	 =====
[-0.4557189  -0.49292567  2.5061333   0.19999559 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  2.5057733   0.20015597 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0318,	 Acc = 0.6615,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0689
3164 0.156
3145 0.795
2594 0.873
1320 0.872
892 0.852
762 0.873
71 0.915
20 0.9
0.8430258973194003
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0930,	 Acc = 0.6470,	 Loss Con1 = 0.0758,	 Loss Con2 = 0.0777
745 0.215
668 0.687
714 0.863
562 0.835
190 0.705
103 0.825
11 1.0
7 1.0
0.78980044345898
0.8119733924611974

 ===== Epoch 243	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.87741     2.4477847  -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 5
train:	 Loss = 1.0333,	 Acc = 0.6607,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0708
3164 0.156
3141 0.796
2597 0.868
1325 0.876
891 0.845
759 0.876
71 0.901
20 0.9
0.8420036347114948
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1122,	 Acc = 0.6443,	 Loss Con1 = 0.0720,	 Loss Con2 = 0.0695
745 0.217
668 0.696
714 0.866
562 0.81
190 0.684
103 0.825
11 1.0
7 1.0
0.7853658536585366
0.8119733924611974

 ===== Epoch 244	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
  1.5501934   0.14420517] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 5
train:	 Loss = 1.0322,	 Acc = 0.6593,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0705
3163 0.155
3146 0.791
2593 0.871
1319 0.875
893 0.849
763 0.868
71 0.887
20 0.9
0.8406587166382737
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0957,	 Acc = 0.6460,	 Loss Con1 = 0.0721,	 Loss Con2 = 0.0727
745 0.216
668 0.684
714 0.87
562 0.824
190 0.716
103 0.796
11 1.0
7 1.0
0.7880266075388027
0.8119733924611974

 ===== Epoch 245	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0313,	 Acc = 0.6601,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0700
3163 0.156
3141 0.791
2600 0.871
1323 0.877
892 0.844
761 0.874
68 0.882
20 0.9
0.8412265758091994
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1206,	 Acc = 0.6470,	 Loss Con1 = 0.0730,	 Loss Con2 = 0.0721
745 0.217
668 0.702
714 0.853
562 0.81
190 0.747
103 0.835
11 1.0
7 1.0
0.7889135254988914
0.8119733924611974

 ===== Epoch 246	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
  1.9895895   1.1637044  -0.46656546 -0.4823711   2.3754427   2.5624964
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
  1.9892498   0.9599195  -0.46656546 -0.4823711   2.3760076   2.3427572
 -0.45947683 -0.42555502] 5 5
train:	 Loss = 1.0291,	 Acc = 0.6590,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0700
3162 0.156
3147 0.789
2596 0.871
1322 0.868
888 0.849
762 0.871
71 0.901
20 0.9
0.8396547808312514
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.0879,	 Acc = 0.6437,	 Loss Con1 = 0.0727,	 Loss Con2 = 0.0711
745 0.217
668 0.695
714 0.854
562 0.817
190 0.716
103 0.796
11 1.0
7 1.0
0.7844789356984478
0.8119733924611974

 ===== Epoch 247	 =====
[ 3.597713    0.88191026  2.1519885   1.5749307   2.5277865   0.5481955
  1.3917537   2.2910306   2.375575    0.11188768 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 3.5844965   0.9019895   2.158902    1.5922139   2.517888    0.564021
  1.4048992   2.330618    2.3505905   0.13353577 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 4
train:	 Loss = 1.0291,	 Acc = 0.6626,	 Loss Con1 = 0.0732,	 Loss Con2 = 0.0701
3161 0.156
3146 0.798
2595 0.876
1326 0.872
889 0.844
760 0.879
71 0.915
20 0.9
0.8445554672419666
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1006,	 Acc = 0.6513,	 Loss Con1 = 0.0726,	 Loss Con2 = 0.0710
745 0.215
668 0.705
714 0.866
562 0.835
190 0.689
103 0.845
11 1.0
7 1.0
0.7955654101995565
0.8119733924611974

 ===== Epoch 248	 =====
[-0.4557189  -0.49292567  1.7880526   1.8795016   0.96529084  0.36242136
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.8133845   1.8715107   0.9903843   0.37735572
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0290,	 Acc = 0.6595,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0700
3164 0.155
3142 0.793
2601 0.869
1317 0.872
892 0.85
761 0.87
71 0.901
20 0.9
0.8407542026351659
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.0962,	 Acc = 0.6460,	 Loss Con1 = 0.0730,	 Loss Con2 = 0.0739
745 0.217
668 0.693
714 0.859
562 0.81
190 0.758
103 0.806
11 1.0
7 1.0
0.7875831485587583
0.8119733924611974

 ===== Epoch 249	 =====
[ 1.0266436   0.87899446 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711   1.8193408   1.3338898
 -0.45947683 -0.42555502] [ 1.0266436   0.79753786 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711   1.8193408   1.2456496
  1.6595411   3.51477   ] 5 5
train:	 Loss = 1.0291,	 Acc = 0.6599,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0714
3160 0.155
3145 0.79
2596 0.872
1324 0.868
891 0.855
761 0.873
71 0.901
20 0.9
0.8409400544959128
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.1133,	 Acc = 0.6477,	 Loss Con1 = 0.0723,	 Loss Con2 = 0.0717
745 0.216
668 0.714
714 0.861
562 0.806
190 0.711
103 0.816
11 1.0
7 1.0
0.7902439024390244
0.8119733924611974

 ===== Epoch 250	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 0
train:	 Loss = 1.0338,	 Acc = 0.6589,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0711
3163 0.156
3148 0.791
2595 0.87
1321 0.873
891 0.845
759 0.87
71 0.845
20 0.9
0.8394094264622374
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1054,	 Acc = 0.6457,	 Loss Con1 = 0.0719,	 Loss Con2 = 0.0682
745 0.217
668 0.708
714 0.852
562 0.806
190 0.721
103 0.835
11 1.0
7 1.0
0.7871396895787139
0.8119733924611974

 ===== Epoch 251	 =====
[ 0.5489292   0.1678929  -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711   2.2890816   1.190203
  1.7082583   3.1356745 ] [ 0.57572454  0.10305429 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711   2.2972715   1.166113
  1.6913042   3.108188  ] 3 3
train:	 Loss = 1.0289,	 Acc = 0.6605,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0703
3161 0.156
3146 0.795
2596 0.872
1321 0.868
892 0.845
761 0.871
71 0.901
20 0.9
0.8417168161689565
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0999,	 Acc = 0.6473,	 Loss Con1 = 0.0732,	 Loss Con2 = 0.0706
745 0.216
668 0.701
714 0.859
562 0.82
190 0.726
103 0.806
11 1.0
7 1.0
0.78980044345898
0.8119733924611974

 ===== Epoch 252	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 0
train:	 Loss = 1.0331,	 Acc = 0.6600,	 Loss Con1 = 0.0734,	 Loss Con2 = 0.0692
3164 0.156
3144 0.794
2594 0.87
1322 0.874
891 0.847
763 0.87
70 0.871
20 0.9
0.8412085415720127
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0858,	 Acc = 0.6467,	 Loss Con1 = 0.0729,	 Loss Con2 = 0.0733
745 0.217
668 0.692
714 0.863
562 0.815
190 0.742
103 0.806
11 1.0
7 1.0
0.788470066518847
0.8119733924611974

 ===== Epoch 253	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 0
train:	 Loss = 1.0306,	 Acc = 0.6578,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0709
3166 0.155
3143 0.789
2599 0.869
1321 0.871
890 0.847
758 0.867
71 0.859
20 0.9
0.8384458077709611
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1129,	 Acc = 0.6447,	 Loss Con1 = 0.0716,	 Loss Con2 = 0.0698
745 0.219
668 0.684
714 0.861
562 0.824
190 0.7
103 0.825
11 1.0
7 1.0
0.7853658536585366
0.8119733924611974

 ===== Epoch 254	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013  0.44327155  0.16037305 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355  0.46819788  0.09377849 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0319,	 Acc = 0.6609,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0702
3161 0.156
3144 0.794
2598 0.875
1322 0.873
892 0.841
760 0.875
71 0.859
20 0.9
0.8420574542977177
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0840,	 Acc = 0.6467,	 Loss Con1 = 0.0727,	 Loss Con2 = 0.0705
745 0.217
668 0.671
714 0.867
562 0.813
190 0.795
103 0.825
11 1.0
7 1.0
0.788470066518847
0.8119733924611974

 ===== Epoch 255	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
  1.1011792   0.23823714 -0.46656546 -0.4823711   0.99520373  3.0409534
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
  1.1056361   0.23012133 -0.46656546 -0.4823711   0.9918763   3.0328798
 -0.45947683 -0.42555502] 4 3
train:	 Loss = 1.0290,	 Acc = 0.6592,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0697
3165 0.156
3142 0.791
2595 0.869
1322 0.878
890 0.843
763 0.87
71 0.873
20 0.9
0.8401681245030104
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.0968,	 Acc = 0.6470,	 Loss Con1 = 0.0719,	 Loss Con2 = 0.0685
745 0.219
668 0.714
714 0.85
562 0.81
190 0.726
103 0.806
11 1.0
7 1.0
0.788470066518847
0.8119733924611974

 ===== Epoch 256	 =====
[ 3.5519423   2.255819    2.1228924   0.95813465  0.21110167  1.2564728
  3.7772155   2.3174326  -0.46656546 -0.4823711   3.9529405   3.2573793
 -0.45947683 -0.42555502] [ 3.566542    2.2758045   2.1197836   0.97603834  0.21162628  1.3196632
  3.7905076   2.3345134  -0.46656546 -0.4823711   3.972136    3.2694468
 -0.45947683 -0.42555502] 4 4
train:	 Loss = 1.0334,	 Acc = 0.6584,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0712
3166 0.156
3143 0.793
2597 0.868
1325 0.869
888 0.848
758 0.868
71 0.873
20 0.85
0.8392410815723699
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0992,	 Acc = 0.6450,	 Loss Con1 = 0.0728,	 Loss Con2 = 0.0694
745 0.217
668 0.692
714 0.857
562 0.82
190 0.711
103 0.825
11 1.0
7 1.0
0.7862527716186253
0.8119733924611974

 ===== Epoch 257	 =====
[-0.4557189  -0.49292567  0.9507172   2.1893458   2.038528    1.0061278
  0.05954548  0.65306294  2.5523438   0.1953279  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  0.9668985   2.215004    2.035121    1.0259969
  0.04409696  0.79860526  2.5284977   0.21637286 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 4
train:	 Loss = 1.0300,	 Acc = 0.6603,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0708
3160 0.156
3141 0.793
2601 0.871
1322 0.872
892 0.848
761 0.873
71 0.873
20 0.9
0.8413941871026339
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0845,	 Acc = 0.6483,	 Loss Con1 = 0.0720,	 Loss Con2 = 0.0705
745 0.217
668 0.704
714 0.86
562 0.815
190 0.737
103 0.806
11 1.0
7 1.0
0.7906873614190687
0.8119733924611974

 ===== Epoch 258	 =====
[ 3.0751648   1.7902114  -0.5993768  -0.57551634 -0.6348712  -0.6508424
  2.6083305   1.0964388   0.7405402   3.1651726   2.9479678   2.216173
 -0.45947683 -0.42555502] [ 3.0751648   1.7902112  -0.59937984 -0.57549053 -0.6347739  -0.6507814
  2.6080825   1.0963217   0.7405399   3.165172    2.9479678   2.2161727
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0280,	 Acc = 0.6593,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0696
3165 0.155
3144 0.791
2598 0.869
1323 0.878
886 0.845
762 0.873
70 0.886
20 0.9
0.8405089174145178
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.1400,	 Acc = 0.6393,	 Loss Con1 = 0.0728,	 Loss Con2 = 0.0700
745 0.217
668 0.714
714 0.846
562 0.799
190 0.679
103 0.777
11 0.909
7 1.0
0.7787139689578714
0.8119733924611974

 ===== Epoch 259	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.14782184  0.12963463 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0276,	 Acc = 0.6613,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0706
3163 0.156
3144 0.794
2595 0.872
1324 0.875
891 0.851
760 0.874
71 0.887
20 0.9
0.8429301533219762
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.1363,	 Acc = 0.6440,	 Loss Con1 = 0.0731,	 Loss Con2 = 0.0731
745 0.219
668 0.671
714 0.866
562 0.82
190 0.742
103 0.806
11 1.0
7 1.0
0.7844789356984478
0.8119733924611974

 ===== Epoch 260	 =====
[ 2.309052    1.5741546  -0.5993768  -0.57551634 -0.6348712  -0.6508424
  1.1557622   2.8540874   3.618234    2.5744653   1.2578562   0.8088652
  3.0733256   1.7779891 ] [ 2.3091915   1.5803463  -0.59937984 -0.57549053 -0.6347739  -0.6507814
  1.1600369   2.8618486   3.6214268   2.5780733   1.2552644   0.8162046
  3.073186    1.7819852 ] 4 4
train:	 Loss = 1.0282,	 Acc = 0.6598,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0710
3164 0.155
3141 0.793
2598 0.87
1323 0.872
891 0.851
760 0.87
71 0.901
20 0.9
0.8409813721035893
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1188,	 Acc = 0.6523,	 Loss Con1 = 0.0722,	 Loss Con2 = 0.0696
745 0.217
668 0.705
714 0.864
562 0.826
190 0.732
103 0.835
11 1.0
7 1.0
0.7960088691796009
0.8119733924611974

 ===== Epoch 261	 =====
[-0.4557189  -0.49292567  1.5396281   2.4063847   0.14524308  0.663695
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.5393953   2.2353604   0.14535777  0.47259992
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 5
train:	 Loss = 1.0313,	 Acc = 0.6593,	 Loss Con1 = 0.0732,	 Loss Con2 = 0.0698
3160 0.155
3146 0.789
2599 0.872
1322 0.873
891 0.847
759 0.87
71 0.901
20 0.9
0.8400317892824705
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1210,	 Acc = 0.6470,	 Loss Con1 = 0.0716,	 Loss Con2 = 0.0711
745 0.219
668 0.722
714 0.852
562 0.815
190 0.679
103 0.806
11 1.0
7 1.0
0.788470066518847
0.8119733924611974

 ===== Epoch 262	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 0
train:	 Loss = 1.0328,	 Acc = 0.6613,	 Loss Con1 = 0.0734,	 Loss Con2 = 0.0712
3167 0.155
3143 0.8
2591 0.872
1323 0.872
893 0.843
760 0.87
71 0.915
20 0.9
0.8435405067605953
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1135,	 Acc = 0.6460,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0743
745 0.219
668 0.687
714 0.86
562 0.833
190 0.695
103 0.825
11 0.909
7 1.0
0.7871396895787139
0.8119733924611974

 ===== Epoch 263	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 0
train:	 Loss = 1.0283,	 Acc = 0.6596,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0716
3163 0.155
3143 0.789
2597 0.872
1320 0.881
892 0.844
762 0.873
71 0.859
20 0.9
0.8409994321408291
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0946,	 Acc = 0.6460,	 Loss Con1 = 0.0722,	 Loss Con2 = 0.0697
745 0.217
668 0.677
714 0.864
562 0.831
190 0.711
103 0.845
11 1.0
7 1.0
0.7875831485587583
0.8119733924611974

 ===== Epoch 264	 =====
[-0.4557189  -0.49292567  1.0179015   2.2009912   0.9702848   0.07679077
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.040731    2.1843252   0.9932546   0.09589898
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0287,	 Acc = 0.6586,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0705
3161 0.154
3143 0.787
2595 0.873
1324 0.875
893 0.847
761 0.871
71 0.873
20 0.9
0.8395594413534688
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1018,	 Acc = 0.6450,	 Loss Con1 = 0.0717,	 Loss Con2 = 0.0690
745 0.217
668 0.705
714 0.853
562 0.813
190 0.711
103 0.816
11 0.909
7 1.0
0.7862527716186253
0.8119733924611974

 ===== Epoch 265	 =====
[ 2.5875432   1.5758967  -0.5993768  -0.57551634 -0.6348712  -0.6508424
  2.3148503   0.7751793   0.20020667  3.2053545   2.5689166   2.0656729
 -0.45947683 -0.42555502] [ 2.5875432   1.5758985  -0.59937984 -0.57549053 -0.6347739  -0.6507814
  2.3146162   0.7750711   0.20020829  3.2053604   2.5689168   2.0656743
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0280,	 Acc = 0.6621,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0697
3163 0.156
3143 0.796
2594 0.874
1324 0.875
893 0.852
760 0.868
71 0.887
20 0.9
0.8438387279954571
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1426,	 Acc = 0.6340,	 Loss Con1 = 0.0728,	 Loss Con2 = 0.0723
745 0.217
668 0.668
714 0.852
562 0.797
190 0.716
103 0.816
11 1.0
7 1.0
0.7716186252771619
0.8119733924611974

 ===== Epoch 266	 =====
[-0.4557189  -0.49292567  1.1770707   2.0818853  -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.1768768   2.0823     -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0323,	 Acc = 0.6584,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0706
3163 0.153
3142 0.789
2598 0.872
1320 0.872
892 0.843
763 0.875
70 0.871
20 0.9
0.8398637137989778
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0999,	 Acc = 0.6440,	 Loss Con1 = 0.0723,	 Loss Con2 = 0.0698
745 0.215
668 0.675
714 0.861
562 0.831
190 0.716
103 0.825
11 1.0
7 1.0
0.7858093126385809
0.8119733924611974

 ===== Epoch 267	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 0
train:	 Loss = 1.0314,	 Acc = 0.6613,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0712
3161 0.155
3143 0.792
2597 0.875
1324 0.874
891 0.852
761 0.875
71 0.887
20 0.9
0.8430793686840014
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1094,	 Acc = 0.6440,	 Loss Con1 = 0.0732,	 Loss Con2 = 0.0732
745 0.217
668 0.69
714 0.856
562 0.808
190 0.737
103 0.835
11 1.0
7 1.0
0.7849223946784922
0.8119733924611974

 ===== Epoch 268	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711   0.22412787  0.8441162
  1.8208423   3.42839   ] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711   0.23783919  0.74588853
  1.799804    3.4037068 ] 3 3
train:	 Loss = 1.0262,	 Acc = 0.6618,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0706
3160 0.155
3145 0.799
2595 0.873
1321 0.873
893 0.847
763 0.869
71 0.859
20 0.9
0.8434377838328792
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0958,	 Acc = 0.6463,	 Loss Con1 = 0.0716,	 Loss Con2 = 0.0713
745 0.217
668 0.678
714 0.86
562 0.824
190 0.753
103 0.835
11 1.0
7 1.0
0.7880266075388027
0.8119733924611974

 ===== Epoch 269	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 0
train:	 Loss = 1.0282,	 Acc = 0.6599,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0708
3168 0.155
3143 0.793
2595 0.873
1321 0.871
887 0.849
763 0.872
71 0.901
20 0.9
0.8418181818181818
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1115,	 Acc = 0.6467,	 Loss Con1 = 0.0763,	 Loss Con2 = 0.0765
745 0.217
668 0.692
714 0.863
562 0.827
190 0.7
103 0.825
11 0.909
7 1.0
0.788470066518847
0.8119733924611974

 ===== Epoch 270	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 0
train:	 Loss = 1.0274,	 Acc = 0.6596,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0714
3167 0.155
3144 0.79
2591 0.873
1324 0.874
891 0.851
760 0.872
71 0.887
20 0.9
0.841268037722986
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1090,	 Acc = 0.6487,	 Loss Con1 = 0.0750,	 Loss Con2 = 0.0739
745 0.219
668 0.708
714 0.861
562 0.81
190 0.721
103 0.825
11 1.0
7 1.0
0.7906873614190687
0.8119733924611974

 ===== Epoch 271	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.29993907  0.18321261
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.32309145  0.09141891
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 1
train:	 Loss = 1.0266,	 Acc = 0.6611,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0700
3163 0.155
3141 0.795
2598 0.874
1323 0.877
889 0.846
763 0.862
71 0.901
20 0.9
0.842816581487791
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 1
val:	 Loss = 1.0958,	 Acc = 0.6437,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0741
745 0.217
668 0.701
714 0.854
562 0.802
190 0.721
103 0.825
11 1.0
7 1.0
0.7844789356984478
0.8119733924611974

 ===== Epoch 272	 =====
[ 1.3632824   0.4895569  -0.5993768  -0.57551634  2.483561    2.0730152
  0.65331817  2.7599876   2.8940709   1.5997384  -0.4178274  -0.43225467
  2.3655243   0.49554324] [ 1.3428652   0.53093565 -0.59937984 -0.57549053  2.4953518   2.0885859
  0.67437255  2.8185196   2.8933556   1.6239047  -0.4178274  -0.43225467
  2.348193    0.5164166 ] 4 4
train:	 Loss = 1.0285,	 Acc = 0.6618,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0704
3162 0.155
3141 0.796
2598 0.873
1323 0.872
893 0.852
760 0.876
71 0.901
20 0.9
0.8438564615035203
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1169,	 Acc = 0.6497,	 Loss Con1 = 0.0756,	 Loss Con2 = 0.0749
745 0.217
668 0.729
714 0.852
562 0.815
190 0.695
103 0.816
11 1.0
7 1.0
0.7924611973392461
0.8119733924611974

 ===== Epoch 273	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 0
train:	 Loss = 1.0280,	 Acc = 0.6597,	 Loss Con1 = 0.0734,	 Loss Con2 = 0.0700
3161 0.154
3141 0.794
2596 0.871
1324 0.869
892 0.849
763 0.866
71 0.915
20 0.9
0.8410355399114341
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1059,	 Acc = 0.6490,	 Loss Con1 = 0.0731,	 Loss Con2 = 0.0755
745 0.217
668 0.705
714 0.86
562 0.819
190 0.721
103 0.835
11 0.909
7 1.0
0.7915742793791575
0.8119733924611974

 ===== Epoch 274	 =====
[ 1.5509781   0.19184537 -0.5993768  -0.57551634  2.3982434   1.9445711
  0.5217614   2.2092228   2.9152343   1.4074043  -0.4178274  -0.43225467
  2.5124075   0.3376618 ] [ 1.5253706   0.22589044 -0.59937984 -0.57549053  2.4083056   1.961037
  0.5338425   2.2854683   2.9110968   1.4312917  -0.4178274  -0.43225467
  2.4932873   0.3565264 ] 4 4
train:	 Loss = 1.0280,	 Acc = 0.6608,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0707
3163 0.155
3142 0.795
2596 0.87
1325 0.875
891 0.851
760 0.876
71 0.873
20 0.9
0.8427030096536059
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.1125,	 Acc = 0.6483,	 Loss Con1 = 0.0716,	 Loss Con2 = 0.0686
745 0.216
668 0.699
714 0.863
562 0.817
190 0.747
103 0.806
11 0.909
7 1.0
0.7911308203991131
0.8119733924611974

 ===== Epoch 275	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.04671075  0.02805486
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.06399456  0.08313069
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 4
train:	 Loss = 1.0327,	 Acc = 0.6569,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0722
3165 0.155
3144 0.788
2596 0.869
1322 0.867
891 0.846
759 0.864
71 0.887
20 0.9
0.8374417812109508
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1095,	 Acc = 0.6467,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0722
745 0.217
668 0.68
714 0.864
562 0.826
190 0.747
103 0.816
11 0.909
7 1.0
0.788470066518847
0.8119733924611974

 ===== Epoch 276	 =====
[-0.4557189  -0.49292567  1.2513744   1.6992844   1.7261314   0.18886508
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.2495886   1.8318219   1.7294438   0.33809736
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0273,	 Acc = 0.6603,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0711
3167 0.156
3139 0.795
2595 0.871
1324 0.871
890 0.849
762 0.87
71 0.887
20 0.9
0.8418361549823884
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.1164,	 Acc = 0.6417,	 Loss Con1 = 0.0743,	 Loss Con2 = 0.0733
745 0.217
668 0.702
714 0.85
562 0.802
190 0.711
103 0.806
11 1.0
7 1.0
0.7818181818181819
0.8119733924611974

 ===== Epoch 277	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 0
train:	 Loss = 1.0292,	 Acc = 0.6610,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0709
3163 0.156
3145 0.795
2595 0.872
1320 0.874
892 0.851
762 0.87
71 0.845
20 0.9
0.8423622941510506
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0881,	 Acc = 0.6493,	 Loss Con1 = 0.0715,	 Loss Con2 = 0.0681
745 0.219
668 0.68
714 0.866
562 0.836
190 0.737
103 0.825
11 1.0
7 1.0
0.7915742793791575
0.8119733924611974

 ===== Epoch 278	 =====
[ 0.64111984  2.3664079  -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711   0.6559111   0.5586716
  1.8086526   3.2023287 ] [ 0.61019725  2.431797   -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711   0.63521564  0.5754261
  1.7880378   3.2615829 ] 1 1
train:	 Loss = 1.0287,	 Acc = 0.6601,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0708
3164 0.154
3143 0.792
2595 0.873
1322 0.877
893 0.848
760 0.87
71 0.887
20 0.85
0.8420036347114948
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.0975,	 Acc = 0.6477,	 Loss Con1 = 0.0728,	 Loss Con2 = 0.0691
745 0.217
668 0.708
714 0.856
562 0.82
190 0.705
103 0.816
11 1.0
7 1.0
0.78980044345898
0.8119733924611974

 ===== Epoch 279	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
  1.2411792   2.8188407 ] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
  1.2546864   2.8561373 ] 4 4
train:	 Loss = 1.0315,	 Acc = 0.6593,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0701
3163 0.155
3146 0.793
2593 0.866
1324 0.873
889 0.847
762 0.882
71 0.873
20 0.9
0.8406587166382737
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.0939,	 Acc = 0.6473,	 Loss Con1 = 0.0749,	 Loss Con2 = 0.0787
745 0.219
668 0.702
714 0.85
562 0.817
190 0.758
103 0.806
11 0.909
7 1.0
0.7889135254988914
0.8119733924611974

 ===== Epoch 280	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 0
train:	 Loss = 1.0258,	 Acc = 0.6608,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0707
3157 0.155
3145 0.796
2597 0.87
1325 0.875
891 0.844
763 0.872
70 0.886
20 0.9
0.8420156622403814
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.1069,	 Acc = 0.6463,	 Loss Con1 = 0.0720,	 Loss Con2 = 0.0700
745 0.217
668 0.707
714 0.86
562 0.819
190 0.689
103 0.806
11 0.909
7 1.0
0.7880266075388027
0.8119733924611974

 ===== Epoch 281	 =====
[-0.4557189  -0.49292567  1.0759892   1.8467361  -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0647173   1.820532   -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0289,	 Acc = 0.6605,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0707
3165 0.155
3145 0.794
2595 0.871
1322 0.874
891 0.852
759 0.872
71 0.901
20 0.9
0.8424400772463932
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1079,	 Acc = 0.6477,	 Loss Con1 = 0.0718,	 Loss Con2 = 0.0694
745 0.219
668 0.69
714 0.864
562 0.813
190 0.747
103 0.825
11 1.0
7 1.0
0.7893569844789357
0.8119733924611974

 ===== Epoch 282	 =====
[-0.4557189  -0.49292567  1.6331627   0.18509755 -0.6348712  -0.6508424
  1.2621074   1.6996366  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.6566337   0.19657962 -0.6347739  -0.6507814
  1.2996458   1.6970986  -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0261,	 Acc = 0.6612,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0706
3168 0.154
3141 0.797
2593 0.874
1324 0.875
889 0.849
762 0.866
71 0.887
20 0.9
0.8436363636363636
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0956,	 Acc = 0.6530,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0745
745 0.217
668 0.698
714 0.871
562 0.819
190 0.763
103 0.835
11 1.0
7 1.0
0.7968957871396896
0.8119733924611974

 ===== Epoch 283	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  1.9548876   1.6061333
 -0.43886673 -0.47319013  1.9750422   0.8870062  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  1.9825296   1.6024939
 -0.4389609  -0.47327355  2.0107002   0.8985086  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 2 2
train:	 Loss = 1.0276,	 Acc = 0.6600,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0717
3162 0.155
3146 0.791
2597 0.873
1323 0.875
892 0.848
757 0.872
71 0.901
20 0.9
0.841471723824665
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1114,	 Acc = 0.6477,	 Loss Con1 = 0.0732,	 Loss Con2 = 0.0748
745 0.219
668 0.704
714 0.859
562 0.811
190 0.716
103 0.845
11 1.0
7 1.0
0.7893569844789357
0.8119733924611974

 ===== Epoch 284	 =====
[-0.4557189  -0.49292567  1.4127395   1.5626464   1.5901741  -0.00313897
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.4283042   1.573518    1.5902834   0.01403584
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 4
train:	 Loss = 1.0279,	 Acc = 0.6616,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0710
3160 0.156
3143 0.794
2597 0.872
1323 0.877
892 0.851
762 0.874
71 0.873
20 0.9
0.842983651226158
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0889,	 Acc = 0.6483,	 Loss Con1 = 0.0728,	 Loss Con2 = 0.0711
745 0.219
668 0.692
714 0.863
562 0.831
190 0.711
103 0.816
11 1.0
7 1.0
0.7902439024390244
0.8119733924611974

 ===== Epoch 285	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 0
train:	 Loss = 1.0260,	 Acc = 0.6588,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0708
3162 0.155
3144 0.788
2595 0.872
1324 0.872
890 0.846
762 0.875
71 0.873
20 0.9
0.8397683397683398
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.0916,	 Acc = 0.6500,	 Loss Con1 = 0.0741,	 Loss Con2 = 0.0761
745 0.219
668 0.701
714 0.864
562 0.82
190 0.726
103 0.825
11 1.0
7 1.0
0.7924611973392461
0.8119733924611974

 ===== Epoch 286	 =====
[-0.02103439  0.7312053  -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711   2.1344657   1.432551
  1.2910453   3.5698376 ] [-0.02103443  0.73120576 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711   2.1344657   1.4325511
  1.2910453   3.5698376 ] 0 0
train:	 Loss = 1.0233,	 Acc = 0.6608,	 Loss Con1 = 0.0732,	 Loss Con2 = 0.0705
3164 0.155
3143 0.793
2596 0.874
1320 0.875
893 0.844
761 0.878
71 0.859
20 0.9
0.8424579736483416
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.0956,	 Acc = 0.6497,	 Loss Con1 = 0.0728,	 Loss Con2 = 0.0720
745 0.217
668 0.684
714 0.866
562 0.836
190 0.732
103 0.825
11 1.0
7 1.0
0.7924611973392461
0.8119733924611974

 ===== Epoch 287	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 0
train:	 Loss = 1.0261,	 Acc = 0.6618,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0701
3165 0.155
3145 0.796
2594 0.874
1320 0.878
891 0.85
762 0.871
71 0.859
20 0.9
0.8438032488924231
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 1
val:	 Loss = 1.1303,	 Acc = 0.6530,	 Loss Con1 = 0.0731,	 Loss Con2 = 0.0714
745 0.219
668 0.71
714 0.861
562 0.836
190 0.705
103 0.825
11 1.0
7 1.0
0.7964523281596453
0.8119733924611974

 ===== Epoch 288	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711   1.1561894   3.2266018
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711   1.1751662   3.260256
 -0.45947683 -0.42555502] 4 4
train:	 Loss = 1.0268,	 Acc = 0.6603,	 Loss Con1 = 0.0734,	 Loss Con2 = 0.0699
3162 0.156
3143 0.79
2599 0.876
1325 0.872
890 0.848
759 0.868
70 0.886
20 0.9
0.8413581648875766
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.0972,	 Acc = 0.6473,	 Loss Con1 = 0.0734,	 Loss Con2 = 0.0728
745 0.219
668 0.69
714 0.859
562 0.827
190 0.726
103 0.816
11 1.0
7 1.0
0.7889135254988914
0.8119733924611974

 ===== Epoch 289	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013  0.6720348   1.8939583   2.6941078   0.25562796
  2.0361915   1.8953806 ] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355  0.66451687  1.7254066   2.6892145   0.07651391
  2.0299485   1.7153097 ] 5 5
train:	 Loss = 1.0275,	 Acc = 0.6599,	 Loss Con1 = 0.0739,	 Loss Con2 = 0.0705
3161 0.154
3146 0.792
2595 0.873
1321 0.873
892 0.849
762 0.871
71 0.873
20 0.9
0.8416032701260361
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1373,	 Acc = 0.6373,	 Loss Con1 = 0.0723,	 Loss Con2 = 0.0729
745 0.217
668 0.702
714 0.843
562 0.795
190 0.668
103 0.845
11 1.0
7 1.0
0.7760532150776053
0.8119733924611974

 ===== Epoch 290	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.04802858  1.7760063
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.04791819  1.7760345
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0261,	 Acc = 0.6593,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0706
3162 0.154
3145 0.791
2594 0.875
1326 0.87
892 0.85
759 0.864
70 0.871
20 0.9
0.8406768112650466
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0892,	 Acc = 0.6470,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0708
745 0.219
668 0.698
714 0.856
562 0.815
190 0.737
103 0.825
11 1.0
7 1.0
0.788470066518847
0.8119733924611974

 ===== Epoch 291	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 1 0
train:	 Loss = 1.0275,	 Acc = 0.6595,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0725
3165 0.155
3142 0.792
2601 0.871
1320 0.87
891 0.847
758 0.879
71 0.873
20 0.9
0.8409633079631944
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0954,	 Acc = 0.6530,	 Loss Con1 = 0.0723,	 Loss Con2 = 0.0738
745 0.217
668 0.725
714 0.859
562 0.817
190 0.737
103 0.806
11 1.0
7 1.0
0.7968957871396896
0.8119733924611974

 ===== Epoch 292	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
  0.96305186  0.5307684  -0.46656546 -0.4823711   1.1147965   3.2865036
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
  0.9818309   0.48277923 -0.46656546 -0.4823711   1.095539    3.2518375
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0256,	 Acc = 0.6597,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0714
3165 0.156
3141 0.793
2597 0.869
1322 0.871
891 0.846
762 0.874
71 0.873
19 0.947
0.8408497103260252
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0884,	 Acc = 0.6550,	 Loss Con1 = 0.0724,	 Loss Con2 = 0.0766
745 0.217
668 0.714
714 0.871
562 0.817
190 0.747
103 0.825
11 1.0
7 1.0
0.7995565410199557
0.8119733924611974

 ===== Epoch 293	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.13415961  0.2258597
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.13427405  0.41704714
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0275,	 Acc = 0.6589,	 Loss Con1 = 0.0740,	 Loss Con2 = 0.0710
3165 0.154
3145 0.791
2593 0.872
1322 0.876
890 0.843
762 0.87
71 0.859
20 0.85
0.8403953197773486
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 5
val:	 Loss = 1.1079,	 Acc = 0.6460,	 Loss Con1 = 0.0729,	 Loss Con2 = 0.0711
745 0.215
668 0.696
714 0.857
562 0.822
190 0.716
103 0.825
11 1.0
7 1.0
0.788470066518847
0.8119733924611974

 ===== Epoch 294	 =====
[ 0.3769832   2.686855   -0.5993768  -0.57551634  0.40670082  2.3118775
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 0.40009508  2.7716506  -0.59937984 -0.57549053  0.42169294  2.3550303
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 4 4
train:	 Loss = 1.0273,	 Acc = 0.6615,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0701
3165 0.155
3144 0.795
2599 0.874
1322 0.874
888 0.845
759 0.876
71 0.901
20 0.9
0.8434624559809156
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0945,	 Acc = 0.6460,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0712
745 0.217
668 0.687
714 0.859
562 0.829
190 0.711
103 0.825
11 1.0
7 1.0
0.7875831485587583
0.8119733924611974

 ===== Epoch 295	 =====
[ 3.671095    1.3488986   2.1172707   1.9652398   2.5825484   1.0021726
  1.3317885   2.6488688   2.5093482   0.60133386 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [ 3.6710954   1.1452575   2.1169758   1.7941508   2.5827174   0.8110731
  1.3316056   2.4437735   2.5093482   0.3878999  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 5
train:	 Loss = 1.0268,	 Acc = 0.6612,	 Loss Con1 = 0.0742,	 Loss Con2 = 0.0713
3163 0.154
3143 0.797
2592 0.873
1325 0.871
892 0.846
762 0.874
71 0.901
20 0.9
0.8433844406587166
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.1134,	 Acc = 0.6403,	 Loss Con1 = 0.0715,	 Loss Con2 = 0.0679
745 0.217
668 0.668
714 0.856
562 0.811
190 0.763
103 0.806
11 1.0
7 1.0
0.7800443458980044
0.8119733924611974

 ===== Epoch 296	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.40980765 -0.23924583
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 6 6
train:	 Loss = 1.0263,	 Acc = 0.6600,	 Loss Con1 = 0.0735,	 Loss Con2 = 0.0708
3167 0.156
3144 0.794
2595 0.873
1321 0.871
890 0.842
760 0.875
71 0.859
20 0.9
0.8414952846267469
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1032,	 Acc = 0.6443,	 Loss Con1 = 0.0722,	 Loss Con2 = 0.0734
745 0.216
668 0.674
714 0.864
562 0.815
190 0.763
103 0.825
11 0.909
7 1.0
0.7858093126385809
0.8119733924611974

 ===== Epoch 297	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.17225553  1.8268851
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.17943947  1.7153206
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 3 3
train:	 Loss = 1.0269,	 Acc = 0.6616,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0706
3162 0.155
3144 0.798
2594 0.873
1325 0.875
890 0.846
762 0.87
71 0.873
20 0.9
0.8435157846922553
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.1116,	 Acc = 0.6433,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0787
745 0.217
668 0.707
714 0.846
562 0.808
190 0.716
103 0.816
11 1.0
7 1.0
0.7840354767184036
0.8119733924611974

 ===== Epoch 298	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053 -0.6347739  -0.6507814
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 5 0
train:	 Loss = 1.0250,	 Acc = 0.6611,	 Loss Con1 = 0.0737,	 Loss Con2 = 0.0708
3163 0.155
3144 0.792
2596 0.876
1320 0.871
891 0.854
763 0.872
71 0.887
20 0.9
0.842816581487791
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0928,	 Acc = 0.6487,	 Loss Con1 = 0.0717,	 Loss Con2 = 0.0675
745 0.217
668 0.708
714 0.861
562 0.82
190 0.7
103 0.816
11 1.0
7 1.0
0.7911308203991131
0.8119733924611974

 ===== Epoch 299	 =====
[ 1.9759319   1.9464259  -0.5993768  -0.57551634 -0.6348712  -0.6508424
 -0.43886673 -0.47319013  3.6041536   2.698311    0.76373935  1.1848553
  2.7582555   1.8540045 ] [ 1.9759319   1.7427846  -0.59937984 -0.57549053  3.042925    2.7114375
 -0.4389609  -0.47327355  3.6041536   2.4848769   0.76373935  0.9642545
  2.7582555   1.6284277 ] 5 5
train:	 Loss = 1.0257,	 Acc = 0.6611,	 Loss Con1 = 0.0738,	 Loss Con2 = 0.0705
3161 0.154
3143 0.795
2593 0.875
1325 0.872
893 0.847
762 0.873
71 0.901
20 0.9
0.8430793686840014
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 4
val:	 Loss = 1.1343,	 Acc = 0.6510,	 Loss Con1 = 0.0733,	 Loss Con2 = 0.0704
745 0.217
668 0.714
714 0.861
562 0.829
190 0.7
103 0.806
11 0.909
7 1.0
0.7942350332594235
0.8119733924611974

 ===== Epoch 300	 =====
[-0.4557189  -0.49292567 -0.5993768  -0.57551634  0.4660816   2.7473166
 -0.43886673 -0.47319013 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567 -0.59937984 -0.57549053  0.46620968  2.7473426
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 0
train:	 Loss = 1.0250,	 Acc = 0.6616,	 Loss Con1 = 0.0736,	 Loss Con2 = 0.0712
3158 0.154
3143 0.797
2601 0.873
1323 0.872
890 0.847
763 0.877
71 0.887
19 0.895
0.8435868331441544
0.8119733924611974
[ 3.4365578   0.97634107  1.8313969   1.7354822   2.4356868   0.67944026
  0.9434046   2.2458694   2.4668605   0.12151366 -0.4178274  -0.43225467
 -0.45947683 -0.42555502] [-0.4557189  -0.49292567  1.0928433   2.1477163   1.044983    0.1367033
 -0.4389609  -0.47327355 -0.46656546 -0.4823711  -0.4178274  -0.43225467
 -0.45947683 -0.42555502] 0 6
val:	 Loss = 1.0880,	 Acc = 0.6413,	 Loss Con1 = 0.0720,	 Loss Con2 = 0.0693
745 0.217
668 0.668
714 0.864
562 0.819
190 0.716
103 0.825
11 1.0
7 1.0
0.7813747228381375
0.8119733924611974
